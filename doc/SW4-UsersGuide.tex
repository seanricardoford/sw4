%-*-LaTeX-*-
\documentclass[11pt]{report}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Use the approved methods for setting lengths
%\oddsidemargin  0.0in
%\evensidemargin 0.0in
%\textwidth      6.5in
%\textheight     9.0in
\setlength{\oddsidemargin}{0.0in}
\setlength{\evensidemargin}{0.0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.7in}
% Based on document style, and taller text body height, set
% weird LaTex margin/header (box heights).  This fixes
% the disappearing page numbers (which never disappeared; they
% just got printed beyond the borders of the physical paper)
\setlength{\voffset}{0pt}
\setlength{\topmargin}{0pt}
\setlength{\headheight}{10pt}
\setlength{\headsep}{25pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{color}
\usepackage{textpos}
%\usepackage{html}
\usepackage{makeidx}
%\usepackage{times}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{graphicx}
%\usepackage{eufrak}
\usepackage{amsmath}

\makeindex

\tolerance=600

\newcommand{\Fb}{{\bf F}}
\newcommand{\Lb}{{\bf L}}
\newcommand{\gb}{{\bf g}}
\newcommand{\nb}{{\bf n}}
\newcommand{\ub}{{\bf u}}
\newcommand{\xb}{{\bf x}}
\newcommand{\p}{\partial}
\renewcommand{\div}{{\rm div}}
\renewcommand{\arraystretch}{1.3}

\markboth{}{N. A. PETERSSON AND B. SJOGREEN; USER'S GUIDE TO SW4, v-2.0}

\begin{document}

%LINE 1%
{
\renewcommand{\familydefault}{\sfdefault}
\definecolor{dark_grey}{gray}{0.3}

\pagenumbering{gobble}
\begin{center}
\resizebox{\textwidth}{!}{\textcolor{dark_grey}{\fontfamily{\sfdefault}\selectfont
COMPUTATIONAL INFRASTRUCTURE FOR GEODYNAMICS (CIG)
}}

\hrule

%LINE 2%
\color{dark_grey}
\rule{\textwidth}{2pt}

%LINE 3%
\color{dark_grey}
% FILL: additional organizations
% e.g.: {Organization 1\\Organization 2}
{\Large Lawrence Livermore National Laboratory}
\end{center}

%COLOR AND CODENAME BLOCK%
\begin{center}
\resizebox{0.3\textwidth}{!}{\colorbox
% FILL: color of code name text box
% e.g. blue
{blue}{\fontfamily{\rmdefault}\selectfont \textcolor{white} {
% FILL: name of the code
% You may want to add \hspace to both sides of the codename to better center it, such as:
% \newcommand{\codename}{\hspace{0.1in}CodeName\hspace{0.1in}}
\hspace{0.01in}SW4\hspace{0.0in}
}}}
\end{center}

%MAIN PICTURE%
%\begin{textblock*}{0in}(0.6in,-0.05in)
% FILL: image height
% e.g. height=6.5in
\begin{center}
\vspace{.1in}
\includegraphics[width=0.6\linewidth]{figures/hayward-pgv.png}
% FILL: image file name
% e.g. cover_image.png
\end{center}
%\end{textblock*}

%USER MANUAL%
\color{dark_grey}
\hfill{\Huge \fontfamily{\sfdefault}\selectfont User's Guide \\
% FILL: manual version
% e.g. 1.0
\raggedleft \huge \fontfamily{\sfdefault}\selectfont Version 3.0\\}

%AUTHOR(S) & WEBSITE%
\null
\vspace{.1in}
\color{dark_grey}
\Large \hfill {\raggedleft \fontfamily{\sfdefault}\selectfont
% FILL: author list
% e.g. Author One\\Author Two\\Author Three\\
% be sure to have a newline (\\) after the final author
N. Anders Petersson\\
Bjorn Sjogreen\\
Houjun Tang\\
}
{\fontfamily{\sfdefault}\selectfont www.geodynamics.org}

%\hrule

%LINE%
\null
\color{dark_grey} \hspace{-6mm}\rule{\textwidth}{2pt}\\ 
{\small
  \fontfamily{\sfdefault}\selectfont Center for Applied Scientific
  Computing, Lawrence Livermore National Laboratory, 7000 East Ave., Livermore, CA 94550. This is
  contribution LLNL-SM-741439.
}  
}



\pagebreak
\pagenumbering{arabic}
\paragraph {Disclaimer} 
This document was prepared as an account of work sponsored by an agency of the United States
government. Neither the United States government nor Lawrence Livermore National Security, LLC, nor
any of their employees makes any warranty, expressed or implied, or assumes any legal liability or
responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product,
or process disclosed, or represents that its use would not infringe privately owned
rights. Reference herein to any specific commercial product, process, or service by trade name,
trademark, manufacturer, or otherwise does not necessarily constitute or imply its endorsement,
recommendation, or favoring by the United States government or Lawrence Livermore National Security,
LLC. The views and opinions of authors expressed herein do not necessarily state or reflect those of
the United States government or Lawrence Livermore National Security, LLC, and shall not be used for
advertising or product endorsement purposes. 

\paragraph{Auspices Statement}
This work performed under the auspices of the U.S. Department of Energy by Lawrence Livermore
National Laboratory under contract DE-AC52-07NA27344.
%\pagebreak
\tableofcontents


\chapter{Introduction}


\emph{SW4} (Seismic Waves, 4th order) is a program for simulating seismic wave propagation on
parallel computers. It shares many features with our previous seismic wave propagation
code~\emph{WPP}~\cite{WPP2}. Both \emph{WPP} and \emph{SW4} solve the seismic wave equations in
displacement formulation using a node-based finite difference approach. The numerical method
satisfies the principle of summation by parts, which guarantees energy stability of the numerical
solution. The major difference between \emph{WPP} and \emph{SW4} lies in the accuracy of the
underlying numerical method. \emph{SW4} is fourth order accurate in space and time~\cite{SjoPet-12},
but \emph{WPP} is only second order accurate. \emph{SW4} is therefore significantly more efficient
than \emph{WPP}, because a coarser grid can be used to capture waves with the same frequency
content. Compared to a second order accurate method, the advantages of a fourth order method are
more pronounced when the solution needs to be more accurate. This is because the error diminishes at
a faster rate as the grid size is reduced. A fourth order method is also more efficient when the
solution needs to remain accurate for longer times, because the phase error grows at a slower rate
in a higher order numerical method~\cite{Gustafsson-Kreiss-Oliger}. Keeping the phase error small
is, for example, important to accurately predict the arrival times of waves that have propagated
over many wave lengths. The fourth order method is also significantly more accurate for calculating
surface waves, in particular when the ratio between the compressional and shear wave speeds is
large, i.e.~$C_p/C_s\gg 1$, see~\cite{KrePet-12}.

%% WHERE TO PUT THIS?  We have compared \emph{SW4} and \emph{WPP} on problems where the exact solution
%% is known. Compared to \emph{WPP}, \emph{SW4} gives similar accuarcy with significantly fewer grid
%% points per wave length. This means that waves with the same frequency can be resolved on a grid that
%% is coarser both in space and time. For materials with $C_p/C_s\approx 2$ and an accuracy of about 10
%% percent, the \emph{SW4} code calculates the solution about eight times faster than \emph{WPP}, using
%% about one eighth of the memory. When both codes use the same grid size, \emph{SW4} can capture waves
%% with approximately twice as high frequency.

\emph{SW4} implements substantial capabilities for 3-D seismic modeling, with a free surface
condition on the top boundary, absorbing super-grid conditions on the far-field
boundaries~\cite{PetSjo-14}, and an arbitrary number of point force and/or point moment tensor
source terms. Each source time function can have one of many predefined analytical time
dependencies, or interpolate a user defined discrete time series. \emph{SW4} supports a fully 3-D
heterogeneous material model that can be specified in several formats. It uses a curvilinear mesh
near the free surface to honor the free surface boundary condition on a realistic topography. The
curvilinear mesh is automatically generated from the description of the topography. To make
\emph{SW4} more computationally efficient, the seismic wave equations are discretized on a Cartesian
mesh below the curvilinear grid. The Cartesian mesh, which extends to the bottom of the
computational domain, is also generated automatically.

\emph{SW4} solves the seismic wave equations in Cartesian coordinates. It is therefore appropriate
for local and regional simulations, where the curvature of the earth can be neglected. Locations can
be specified directly in Cartesian coordinates, or through geographic (latitude, longitude)
coordinates. \emph{SW4} can be built to use the Proj.4 library~\cite{Proj4} for calculating the
mapping between geographic and Cartesian coordinates, or use an approximate spheroidal
mapping. \emph{SW4} can output synthetic seismograms in an ASCII text format, or in the \emph{SAC}
format~\cite{Goldstein-et-al}. It can also present simulation information as
\emph{GMT}~\cite{WesselSmithGMT} scripts, which can be used to create annotated maps. \emph{SW4} can
output the solution, derived quantities of the solution, as well as the material model along 2-D
grid planes. Furthermore, \emph{SW4} can output the 3-D volumetric solution, or material model, in a
binary file format.

Cartesian local mesh refinement can be used to make the computational
mesh finer near the free surface, where more resolution often is needed to resolve short wave
lenghts in the solution, for example in sedimentary basins. The mesh refinement is performed in the
vertical direction and each Cartesian grid is constructed from user specified refinement levels. In
this approach, the grid size in all three spatial directions is doubled across each mesh refinement
interface, leading to substantial savings in memory and computational effort. The energy conserving
mesh refinement coupling method described in~\cite{PetSjo-10}, but generalized to fourth order of 
accuracy, is used to handle the hanging nodes along the refinement interface.

Visco-elastic behavior can be important when modeling the dissipative nature of realistic materials,
especially for higher frequencies. \emph{SW4} uses the rheological model of standard linear solid
(SLS) elements, coupled in parallel. The coefficients in each SLS are determined such that the
resulting quality factors $Q_p$ and $Q_s$, for the attenuation of P- and S-waves, become
approximately constant as function of frequency. These quality factors can vary from grid point to
grid point over the computational domain and are read in the same way as the elastic properties of
the material model. The numerical method for solving the visco-elastic wave equation is
based on the technique described in~\cite{PetSjo-10b}.

While most of the \emph{SW4} code is written in C++, almost all numerical computations are
implemented in Fortan-77. \emph{SW4} uses a distributed memory programming model, implemented with
the C-bindings of the MPI library. Compatible versions of the C++ and Fortran-77 compilers as well
as the MPI library must be available to build the code. We have built and tested
\emph{SW4} on a variety of machines, ranging from single processor laptops to large super-computers
with ${\cal O}(100,000)$ cores.

With the exception of some minor details, the syntax of the \emph{SW4} command file is the same as
in \emph{WPP}. Most of the input and output files also use the same formats, but we have taken the
opportunity to improve the image file format, see Chapter~\ref{chap:formats}. 
\emph{SW4} supports most of the functionality of \emph{WPP}, version 2.2. Compared
to version 1.1 of \emph{SW4}, the main improvement in version 2.0 is the \verb+refinement+ command for
using mesh refinement with hanging nodes. A preliminary implementation of mesh refinement was first
introduced in version 1.18. It has now been further improved and generalized to support anelastic materials.

%% Similar to {\tt efiles}, the {\tt rfile} command reads the material
%% properties from a binary file that supports a hierarchical data structure, allowing the material
%% model to be represented at a higher resolution near the surface of the earth. Compared to {\tt
%%   efiles}, the {\tt rfiles} are more straight forward to generate, use linear interpolation to
%% define the material properties between the data points, and can be read in parallel (if a parallel
%% file system is available). We also support automatic byte-swapping to account for big/little endian
%% byte ordering. Reading {\tt rfiles} has been shown to work well on very large parallel machines
%% (tested on more than 400,000 cores). Furthermore, version 1.1 of \emph{SW4} provides limited
%% support for modeling wave propagation in general anisotropic materials, described by a 21 parameter
%% stiffness tensor, see Section~\ref{sec:anisotropy} for details.

The {\tt examples} subdirectory of the \emph{SW4} source distribution contains several examples and
validation tests that are used in this document. Many Matlab/octave scripts are provided in the
{\tt tools} directory.
%and described in Chapter~\ref{chap:scripts}.

\section{How to cite \emph{SW4}}

The Computational Infrastructure for Geodynamics (CIG) (geodynamics.org) makes the \emph{SW4}
source code available to you at no cost in hope that the software will benefit your
research in geophysics. A number of individuals have contributed a significant portion of their
careers toward the development of this software. It is essential that you recognize these
individuals in the normal scientific practice by citing the appropriate peer-reviewed papers and
making appropriate acknowledgments in talks and publications. The following peer-reviewed papers
discuss the numerical methods that are implemented in \emph{SW4}:
\begin{itemize}
%
  \item Petersson, N.A. and B. Sj\"ogreen (2015). Wave propagation in anisotropic elastic materials
    and curvilinear coordinates using a summation-by-parts finite difference method, Journal of
    Computational Physics, 299, 820-841. DOI: 10.1016/j.jcp.2015.07.023, URL:
    http://linkinghub.elsevier.com/retrieve/pii/S0021999115004684.
%
  \item Petersson, N.A. and B. Sj\"ogreen (2012). Stable and efficient modeling of anelastic
    attenuation in seismic wave propagation, Communications in Computational Physics, 12 (01),
    193-225.
%
  \item Sj\"ogreen, B. and N.A. Petersson (2012). A Fourth Order Accurate Finite Difference Scheme
    for the Elastic Wave Equation in Second Order Formulation, Journal of Scientific Computing, 52
    (1) , 17-48, doi: 10.1007/s10915-011-9531-1, url:
    http://link.springer.com/10.1007/s10915-011-9531-1
    %
\end{itemize}
To cite the \emph{SW4} software and manual, use:
\begin{itemize}
%
\item Petersson, N.A. and B. Sj\"ogreen (2017). SW4 v2.0. Computational Infrastructure of
Geodynamics, Davis, CA. DOI: 10.5281/zenodo.1045297.
%
\item Petersson, N.A. and B. Sj\"ogreen (2017). User's guide to {SW4}, version 2.0. Technical report
  LLNL-SM-741439, Lawrence Livermore National Laboratory, Livermore, CA.
%
\end{itemize}


\section{Acknowledgments} 
The \emph{SW4} code was developed under financial support from Lawrence Livermore National
Laboratory. The underlying numerical method was developed under financial support from
the Office of Science at the U.S.~Department of Energy.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Getting started}
\index{srun}\index{parallel execution}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Running \emph{SW4}}
This section assumes that \emph{SW4} has already been installed on your computer system. We refer to
the report by Petersson and Sjogreen~\cite{SW4-install} for instructions on how to install
\emph{SW4}.

\emph{SW4} can be executed from the command line or from a script. The simulation is specified by
the input file, and the name of the input file is given on the command line. The input file is an
ASCII text file that contains a number of commands specifying the properties of the simulation, such
as the dimensions of the computational domain, grid spacing, the duration of the simulation, the
material properties, the source model, as well as the desired output. To improve readability of this
document we have used the continuation character ``$\backslash$" to extend long commands to the
subsequent line. There is however no support for continuation characters in \emph{SW4}, so each
command must be given on one (sometimes long) line in the input file.

Since \emph{SW4} is a parallel code, it is required to be run under a parallel execution environment
such as mpiexec, mpirun, openmpirun, or srun. The \verb+srun+ command is currently always used on
the parallel machines at Livermore Computing. It is important to start \emph{SW4} with the correct
parallel execution tool. For example, if you build \emph{SW4} with the \verb+openmpi+ compilers, you
should use the \verb+openmpirun+ environment. Also note that some systems require you to start an
\verb+mpd+ daemon before running any parallel programs. Chances are high that somebody else has
already figured out how to run parallel programs on your system. If you have problems running
\emph{SW4}, ask your local system administrator, or somebody else who has experience running MPI
programs on your system.

Throughout this document we use the convention that input files have the file suffix {\tt
  .in}. However, \emph{SW4} will attempt to read any input file, regardless of its extension.

If your system is setup for using \verb+mpiexec+, the command
\begin{verbatim}
	shell> mpiexec -np 2 sw4 test.in
\end{verbatim}
runs \emph{SW4} on 2 processes, and tells it to read the input from a file named {\tt test.in}.  If you
are using \verb+mpirun+, you would instead use the command
\begin{verbatim}
	shell> mpirun -np 2 sw4 test.in
\end{verbatim}
{\bf Remark: } If \emph{SW4} produces strange looking outputs, for example where the same text is
repeated several times (e.g. once per processor), you are probably running \emph{SW4} under the
wrong parallel execution environment. Make sure you are running \emph{SW4} under an environment that
is compatible with the compiler that was used to build \emph{SW4}.
%

\subsection{Version information (-v)}
\index{command line options!-v version info}

Version information for the \emph{SW4} executable can be obtained through the {\tt -v} flag:
\begin{verbatim}
shell> mpirun optimize/sw4 -v
----------------------------------------------------------------
            sw4 version 2.0

 This program comes with ABSOLUTELY NO WARRANTY; released under GPL.
 This is free software, and you are welcome to redistribute     
 it under certain conditions, see LICENSE.txt for more details  
----------------------------------------------------------------
  Compiled on: Mon Nov  6 09:11:04 PST 2017
  By user:     petersson1
  Machine:     fourier.llnl.gov
  Compiler:    /opt/local/bin/mpicxx
  3rd party include dir: /opt/local/lib/proj47/include, and library dir: /opt/local/lib/proj47/lib
----------------------------------------------------------------
\end{verbatim}
Note that the same information is by default printed to standard out (your screen, or log file when
running in batch mode) at the beginning of every run.

\subsection{Running on the parallel machines at Livermore Computing}
%
The srun command is currently used to run parallel jobs on LC machines. For example, the command
\begin{verbatim}
	shell> srun -ppdebug -n 32 sw4 xxx.in
\end{verbatim}
runs \emph{SW4} on 32 processors on the debug partion using xxx.in as the input file. Note that the
pdebug partition is intended for shorter jobs. It is subject to both a CPU time limit and a limit on
the number of processors per job. Jobs requiring more computer resources must be submitted through
the batch system, currently using the \verb+msub+ command. Refer to the Livermore Computing web pages for
detailed information (https://computing.llnl.gov).

%\section{Warning and error messages}

%Warning and error messages are stored in separate log files...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Governing equations, coordinate system, and units}
\index{coordinate system}\index{units}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\emph{SW4} simulates the motion due to a seismic event by solving the elastic or visco-elastic wave
equations in displacement formulation. This is a system of linear hyperbolic partial differential
equations in second order formulation. By second order formulation, we mean that the partial
differential equation contains second derivatives with respect to space and time. The equations
are solved in the three-dimensional spatial domain ${\bf x}\in\Omega$ during the time interval
$0\leq t\leq T$. By default, the motion starts from rest and is driven by a forcing function ${\bf
  F}({\bf x},t)$. In the elastic case, the motion is governed by
\begin{alignat}{3}
\rho {\bf u}_{tt} &= \nabla\cdot{\cal T} + {\bf F}({\bf x},t),&\quad\mbox{${\bf x}$ in
  $\Omega$},\ 0\leq t\leq T,\label{eq:elastic-we}\\ 
{\bf u}({\bf x},0)&=0,\quad {\bf u}_t({\bf x},0) = 0, &\quad\mbox{${\bf x}$ in $\Omega$}.
\end{alignat}
Here, $\rho$ is the density, ${\bf u}({\bf x},t)$ is the displacement vector, and ${\cal T}={\cal
  T}({\bf u})$ is the stress tensor. The computational domain $\Omega$ is a box shaped region where
one side optionally follows the shape of the topography. By default, a free surface (also called
traction-free, or zero normal stress) boundary condition is enforced along the top boundary,
\[
{\cal T} \cdot \nb = 0,\quad z=\tau(x,y),\ t\geq 0.
\]
Here $\nb$ is the unit normal of the $z=\tau(x,y)$ surface. By default, a super-grid damping layer
is used on all other sides of the computational domain.

\emph{SW4} uses a right-handed Cartesian coordinate system with the z-direction pointing
downwards into the medium, see figure~\ref{fig:coordsys}. 
\begin{figure}[th]
\begin{centering}
 \includegraphics[width=0.6\linewidth]{figures/coords.png}
  \caption{\emph{SW4} uses a right handed coordinate system with the z-axis pointing
  downwards.}
  \label{fig:coordsys}
\end{centering}
\end{figure}
\emph{SW4} employs MKS (meters-kilograms-seconds) units. All distances (e.g.,~grid dimensions,
spacing, and displacements) are in meters (m), time is in seconds (s), seismic P- and S-wave
velocities are in meters per second (m/s), densities are in kilogram per cubic meter (kg/m$^3$),
forces are in Newton (N), and seismic moment (torque) is in Newton-meters (Nm). All angles
(e.g. latitude, longitude, azimuth, strike, dip and rake) are in degrees. 
%The quality factors $Q_P$ and $Q_S$ are dimensionless.

In \emph{SW4} the computational domain is rectangular in the horizontal plane and the vertical extent
is defined by the topographic surface
\[
z=\tau(x,y),
\]
which defines the shape of the free surface. \emph{SW4} can also be run with flat topography, in
which case $\tau(x,y)=0$ and the $z$-coordinate equals the depth below the free surface. In the general
case, the computational domain is given by
\begin{equation}\label{eq:domain}
0\leq x\leq x_{max},\quad 0\leq y\leq y_{max},\quad \tau(x,y) \leq z \leq z_{max}.
\end{equation}

The grid command in the input file specifies the extent of the computational domain and the grid
size $h$. When topography is enabled, the grid size in the curvilinear grid equals $h$ in the
horizontal directions, but varies in the vertical direction to allow the curvilinear grid to follow
the shape of the free surface. In this case, the number of grid points in the vertical direction is
chosen such that the average of the vertical grid size approximately equals $h$.
When mesh refinement is enabled, this is the grid size in the coarsest grid. 

The most precise way of specifying the grid is by providing the number of grid points in each
direction as well as the grid size,
%
\begin{verbatim}
	grid nx=301 ny=201 nz=101 h=500.0 
\end{verbatim}
%
This command gives a grid with grid size 500 meters, which extends 150 km in $x$, 100 km in $y$ and
50 km in the $z$-direction. Alternatively, the grid can be specified by giving the spatial range in
each of the three dimensions and explicitly specifying the grid spacing. For example, the command
%
\begin{verbatim}
	grid x=30e3 y=20e3 z=10e3 h=500.0 
\end{verbatim}
%
results in a grid which spans 30,000 meters in $x$, 20,000 meters in $y$, and 10,000
meters in the $z$-direction.  The grid spacing is 500 meters, which is used to compute the
number of grid points in each direction: nx=61, ny=41, and nz=21, for a total of
52,521 grid points. Note that the number of grid points in the different directions will be
rounded to the nearest integer value according to the pseudo C-code
\begin{equation}\label{eq:nx-calculation}
nx = \mbox{(int)} (1.5 + x/h).
\end{equation}
The extent in the $x$-direction is thereafter adjusted to
\begin{equation}\label{eq:x-calculation}
x=(nx-1) h.
\end{equation}
A corresponding procedure is performed in the other coordinate directions.

The third option is to give the spatial range in each of the three dimensions and specify the number
of grid points in one direction:
%
\begin{verbatim}
	grid x=30000 y=20000 z=10000 nx=100
\end{verbatim}
%
In this case, the grid spacing is computed as 
\[
h = x/(nx-1)= 303.03.
\]
Note that no rounding needs to take place in this case, since $h$ is a floating point number. Given this
value of $h$, ny and nz are computed using formulas corresponding to
(\ref{eq:nx-calculation}) giving ny=34 and nz=67, for a total of 227,800 grid points. Again,
the extents in the $y$ and $z$-directions are adjusted corresponding to (\ref{eq:x-calculation}). The syntax
for the grid command is given in Section~\ref{keyword:grid}.

The simulation always starts at $t=0$ and runs until $t=T$, where the user must specify $T$ with the
{\tt time} command. For example,
\begin{verbatim}
time t=1.6
\end{verbatim}
sets $T=1.6$ seconds. Alternatively, the simulation time interval can be specified as 
a number of time steps,
\begin{verbatim}
time steps=1200
\end{verbatim}
The end time will in this case be $T=1200\Delta t$,
where the time step $\Delta t$ is determined automatically by \emph{SW4} to satisfy the CFL time
step restriction. This calculation is based on the ratio between the grid size and the largest
characteristic wave speed, which depends on both the compressional and shear wave speeds. 

The simulation start time can be related to a universal time coordinate (UTC). The option {\tt
  utcstart} sets the UTC that corresponds to simulation time $t=0$, for example,
\begin{verbatim}
time t=1.6 utcstart=01/31/2012:17:34:12.233
\end{verbatim}
The format of the UTC is ``month/day/year:hour:minute:second.millisecond''. When the UTC time
is set, it is saved in the header of all time series files (see the {\tt rec} command). Note that
the UTC can be very useful for aligning simulated and observed time series.
%is also used the inverse problem with \emph{SW4opt}.

\section{Geographical coordinates and projections}
\index{geographical coordinates}
\emph{SW4} supports geographical coordinates as an alternative way of specifying spatial
locations. The geographic location of the origin of the Cartesian coordinte system (lat$_0$,
lon$_0$), see Figure~\ref{fig:geocoord}, is specified in the grid command. 
\begin{figure}
\begin{centering}
  \includegraphics[width=0.5\linewidth]{figures/latlon.png}
%  \includegraphics{LatLonAz.ps}
  \caption{Geographical coordinates in \emph{SW4}.}
  \label{fig:geocoord}
\end{centering}
\end{figure}
If no location is given, the default location is lat$_0$ = 37 degrees, lon$_0$ = -118 degrees, and
the azimuthal angle of the $x$-axis is 135 degrees from North. We remark that latitudes are positive
North of the equator and longitude are positive East of the Greenwich prime meridian. The vertical
coordinate increases downwards. For the case of general topography, $z=0$ corresponds to mean sea
level. When the topography is flat (no {\tt topography} command in the input file), $z=0$
corresponds to the free surface.

\subsection{Spheroidal mapping}
By default, the latitude (lat) and longitude (lon) are calculated using a spheroidal mapping,
\begin{alignat}{2}
\mbox{lat} &= \mbox{lat$_0$} + \frac{x\cos(\alpha) - y\sin(\alpha)}{M},\quad \alpha =
\mbox{az}\frac{\pi}{180}, \label{eq:lat}\\
\mbox{lon} &= \mbox{lon$_0$} + \frac{x\sin(\alpha ) + y\cos(\alpha)}{M\cos(\phi \pi/180)}.\label{eq:lon}
\end{alignat}
In this formula, lat, lon, az, lat$_0$, and lon$_0$ are all in degrees, and $M = 111,319.5$
meters\footnote{Note that $M/60 = 1,855.325$ meters corresponds to one minute of arc of
 longitude along the Equator on the WGS84 ellipsoid. This distance is also known as a geographical
  mile and is approximately equal to a Nautical mile (1,852 meters).}.  You can change the location
and orientation of the grid by specifying the latitude and longitude of the grid origin, as well as
the azimuthal angle between North and the $x$-axis. For example:
\begin{verbatim}
grid h=500 x=30000 y=20000 z=10000 lat=39 lon=-117 az=150
\end{verbatim}
sets the origin of the grid to latitude 39 degrees (North), longitude -117 degrees
(West), and azimuthal angle 150 degrees.

The default projection is spheriodal as described by equations \eqref{eq:lat}-\eqref{eq:lon}. You
can change the parameter $M$ with the {\bf mlat} keyword in the {\bf grid} command. By using the
{\bf mlon} keyword, you can also modify the projection by replacing $M\cos(\phi\pi/180)$ in
\eqref{eq:lon} by the constant value $M_{lon}$. Using the {\bf mlon} keyword is only recommended if
the computational domain is small and accurate values of both {\bf mlon} and {\bf mlat} are
available.

\subsection{The Proj.4 library}
More accurate projections are available through the Proj4 library (if
\emph{SW4} was built with Proj4 support). These projections are enabled by using the {\bf proj},
or any of the related, keywords in the {\bf grid} command. For example,
\begin{verbatim}
grid h=300 x=40e3 y=43e3 z=40e3 lat=45.01 lon=5.52 az=0 proj=utm ellps=WGS84
\end{verbatim}
sets the origin of the grid to latitude 45.01 degrees (North), longitude 5.52 degrees (East), and
azimuthal angle 0. Here we use the UTM projection based on the WGS84 ellipse. Note that the strings
``proj=utm'' and ``ellps=WGS84'' are passed directly to the Proj4 library to initialize the
projection. Several other options are available, see Section~\ref{keyword:grid} and the Proj4
documentation~\cite{Proj4} for further details.

\section{Super-grid damping layers}\label{sec:supergrid}

\emph{SW4} implements a super-grid modeling technique to reduce artificial reflections from the
far-field boundaries~\cite{AppCol-09, PetSjo-14}. In this method, layers are added around the domain
of interest, i.e., the domain in which we want to solve the seismic wave equation. In each layer, a
stretching function is used to transform the seismic wave equation to mimic a much larger physical
domain. The basic idea is to delay artificial reflections from the far-field boundary, because
making the physical domain larger means that it will take longer for waves to arrive at the
boundary, and then return back into the domain of interest. Inside the layers, the streching
function is combined with a high order artificial dissipation. It damps out waves that have become
poorly resolved on the grid because of the stretching function. Note that the artificial dissipation
is only added in the layers, and should not affect the accuracy of the solution in the interior of
the domain.

The coordinate stretching compresses the solution inside the layers. This corresponds to a slowing
down of all traveling waves in the direction normal to each far-field boundary. As a result, the
isotropic elastic wave equation becomes anisotropic in the super-grid layers. By using energy
estimates, it is possible to prove that the super-grid technique leads to a stable numerical method
where the total energy of the solution decreases with time. This estimate is valid for heterogeneous
material properties and free surface boundary conditions on one or more sides of the domain, and
also extends to anisotropic elastic materials and curvilinear grids. See the papers by Petersson and
Sjogreen~\cite{PetSjo-14, PetSjo-14b} for details.

Super-grid layers are by default added to all sides of the computational domain, except along the
free surface, see Figure~\ref{fig:layout}.
\begin{figure}[t]
\begin{center}
%\includegraphics[width=0.65\linewidth]{layout.eps}
\includegraphics[width=0.65\linewidth]{figures/layout.png}
\caption{\em A vertical cross-section through the computational domain with a free surface boundary
  along the top edge. The original seismic wave equation is solved the white region. The wave speed
  is reduced in the normal direction of the surrounding super-grid layers, where also a high order
  damping term is added.}\label{fig:layout}
\end{center}
\end{figure}
The default thickness of the layers is 30 grid sizes, but the thickness of the super-grid layers can
be changed with the {\tt supergrid} command, see Section~\ref{keyword:supergrid}. Note that long
waves are harder to suppress than short waves, because the artificial damping is less efficient for
waves that are well resolved on the grid. The best way of reducing artificial reflections is to make
the super-grid layers thicker. Increasing the dissipation coefficient is not recommended as it can
make the explicit time stepping unstable. Reducing the thickness of the super-grid layers to below
20 grid sizes can also lead to instabilities, unless the artificial dissipation coefficient is also
reduced. The syntax of the {\tt supergrid} command is described in Section~\ref{keyword:supergrid}.

For reasons, the super-grid layers are part of the computational domain as specified by the {\tt
  grid} command. If, for example, each super-grid layer is 30 grid points wide, the solution should
be considered artificial in the first and last 30 points in each horizontal direction, and the
bottom 30 points in the vertical direction. Note that the numerical solution within the layers do
{\em not} approximate the solution of the seismic wave equations. For this reason, it is important
to make the computational domain sufficiently large. If the super grid layers are 30 grid points
wide, the computational grid must be at least 60 grid points wide in the $x$ and $y$-directions, and
30 points wide in the Cartesian part of the $z$-direction. Additional grid points must be added in
the interior of the computational domain for the actual seismic modeling. Note that sources and
receivers should only be placed in the interior of the computational domain, i.e., the white region
of Figure~\ref{fig:layout}.

\paragraph{Remark:} As a user of \emph{SW4}, you do {\em not} have to worry about the 
stretching functions or the artificial dissipation in the super-grid layers, because they are set up
automatically. Just make sure the computational grid has a sufficient number of grid points to
accomodate the layers, and be aware that the seismic wave equation is modified in the layers,
which makes that part of the solution artificial.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Sources, time-functions, and grid size}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%The source time function can be selected from a set of predefined functions, or by spline
%interpolation of a user defined discrete time-series. Each point force or point moment tensor source
%can have a different time function. 

\section{Point force and moment tensor sources in \emph{SW4}}\label{sec:time-functions}
The forcing term ${\bf F}$ in equation \eqref{eq:elastic-we} consists of a sum of point forces and
point moment tensor source terms. For a point forcing we have
\[
{\bf F}({\bf x},t) = g(t,t_0,\omega) F_0 \left(\begin{array}{c}
  F_x\\ F_y\\ F_z\end{array}\right) \delta ({\bf x} - {\bf x_0}),
\]
where ${\bf x}_0=(x_0,y_0,z_0)$ is the location of the point force in space, and $g(t,t_0,\omega)$
is the time function, with offset time $t_0$ and frequency parameter $\omega$. The source time
function can be selected from a set of predefined functions, or by spline interpolation of a user
defined discrete time-series. The $(F_x,F_y,F_z)^T$ vector holds the Cartesian components of the force
vector, which is scaled by the force amplitude $F_0$. 

For a moment tensor source we have
\[
{\bf F}({\bf x},t) = g(t,t_0,\omega)\, {\cal  M} \cdot \nabla \delta ({\bf x} - {\bf
  x_0}), \quad 
{\cal M} = \left(\begin{array}{ccc}
M_{xx} & M_{xy} & M_{xz}\\
M_{xy} & M_{yy} & M_{yz}\\
M_{xz} & M_{yz} & M_{zz}
\end{array}
\right).
\]
The seismic moment of a moment tensor source is defined by 
\[
M_0 = \frac{1}{\sqrt{2}}\sqrt{{\cal M}:{\cal M}} = \frac{1}{\sqrt{2}}\left[ (M_{xx}^2 + M_{yy}^2 + M_{zz}^2 ) + 2
  (M_{xy}^2 + M_{xz}^2 + M_{yz}^2) \right]^{1/2}.
\]
Note that the moment tensor is always symmetric. A moment source term can alternatively be specified
by using $M_0$ and the dip, strike, and rake angles, as defined by Aki and
Richards~\cite{Aki-Richards-02}. The syntax is described in Section~\ref{keyword:source}.

The total seismic moment $\sum M_0$ [Nm] is related to the moment magnitude by the formula
\[
M_W = \frac{2}{3}\left[\log_{10}\left(\sum M_0\right) - 9.1\right],
\]
where the summation $\sum M_0$ is done over all moment sources.
After parsing all source commands in an input file, \emph{SW4} outputs the moment magnitude using
this formula. This information is given right before the time-stepping is started and looks like this:
\begin{verbatim}
-----------------------------------------------------------------------
  Total seismic moment (M0): 1.7162e+17 Nm 
  Moment magnitude     (Mw): 5.42305
  Number of sources 542
-----------------------------------------------------------------------
\end{verbatim}
Note that the calculation of the total seismic moment and magnitude only take the moment tensor sources into
account, i.e., ignores all point forces.

For moment tensor sources, the function $g(t)$ is called the moment history time function, while its
time derivative $g'(t)$ is known as the moment rate time function. \emph{SW4} calculates the
displacements of the motion corresponding to the moment history time function $g(t)$. Because
the material properties are independent of time, the equations solved by {\emph SW4} also govern the
velocities when the time function is replaced by $g'(t)$, i.e., the corresponding moment rate time
function. For example, if the solution calculated with the {\tt GaussianInt} time function
represents the displacements of the motion, the solution calculated with the {\tt Gaussian} time
function corresponds to the velocities of the same motion. Hence, if you are primarily interested in
calculating velocities, you can reduce the amount of post processing by using the corresponding
moment rate time function in the source term(s). 

If you are interested in comparing results from \emph{SW4} with some other code, keep in mind that
many other seismic wave propagation codes are based on the first order velocity-stress formulation
of the elastic wave equation. Such codes solve for the velocities of the motion. They use the moment
rate time function ($g'(t)$) for moment tensor sources, but the regular time function ($g(t)$) for
point forces.

The forcing function in \emph{SW4} is specified in the input file using at least one {\tt source} or
{\tt rupture} command. These options can be combined. The {\tt rupture} command allows complicated
source mechanisms to be described in a separate SRF (Standard Rupture Format) file. It is equivalent
to at least one (but often many) {\tt source} command(s). There needs to be at least one source
command in the input file in order for anything to happen during the simulation. Complicated source
mechanisms can be described by having many source commands in the input file. An example with one
source command is:
\begin{verbatim}
source x=5000 y=4000 z=600 mxx=1e15 myy=1e15 mzz=1e15 \
       type=RickerInt t0=1 freq=5
\end{verbatim}
The above command specifies an isotropic source (explosion) at the location ${\bf
  x}_0=(5000,4000,600)$ with amplitude $10^{15}$ Nm, using the {\tt RickerInt} time function with
offset time $t_0=1$ s and frequency parameter $\omega=5$ Hz. The off-diagonal moment tensor elements
($M_{xy}$, $M_{xz}$ and $M_{yz}$) are implicitly set to zero (which is the default value).

Note that it is not necessary to place the sources exactly on grid points. The discretization of the
source terms is fourth order accurate for any location within the computational domain, including
the free surface. However, unexpected results may be obtained if the sources are located in the
super-grid far-field layers.


\section{Predefined time functions}\label{sec:predefined}

All pre-defined source time functions start from zero ($\lim_{t\to -\infty} g(t,t_0,\omega) = 0$)
and tend to a constant terminal value, $\lim_{t\to \infty} g(t,t_0,\omega) = g_\infty$. In seismic
applications, time function that have a non-zero terminal value ($g_\infty\ne 0$) lead to a non-zero
steady-state solution after long times. Such time functions are used to solve for the displacement
of the motion. When $g_\infty = 0$, the solution tends to zero for large times. This is
expected from the velocities or accelerations of the motion due to a seismic event.

The Gaussian, Dirac, and Triangle functions integrate to one ($\int_{-\infty}^{\infty}
g(t,t_0,\omega) \, dt = 1$), while the Sawtooth, Smoothwave, and Ricker functions integrate to zero
and have maximum amplitude one. The RickerInt function is the time-integral of the Ricker function
and integrates to zero. The GaussianInt, Brune, BruneSmoothed, and Liu functions tend to one
($\lim_{t\to\infty} g(t,t_0,\omega) = 1$).

The initial conditions are homogeneous when \emph{SW4} is used to calculate the motion due to point
force and moment tensor sources. In other words, the initial displacement and velocity are zero. To
avoid incompatibilities, the source time functions must also start smoothly. Since the Triangle,
Sawtooth, Ramp, Smoothwave, Brune, BruneSmoothed, Liu and VerySmoothBump functions are identically
zero for $t<t_0$, these time functions must have $t_0\geq 0$. More care is required for the
Gaussian, GaussianInt, Ricker, and RickerInt functions, because they are centered around $t=t_0$,
with exponentially decaying tails for $t<t_0$. For these functions, incompatibilty problems can only
be avoided if $t_0$ is positive and of the order ${\cal O}(1/\omega)$, where $\omega$ equals the
{\tt freq} parameter. We recommend choosing $t_0$ such that $g(0,t_0,\omega) \leq 10^{-8}$ for these
functions.

\subsection{Gaussian}\label{gaussian}
  \[
  g(t,t_0,\omega) = \dfrac{\omega}{\sqrt{2 \pi}} e^{-\omega^2 (t - t_0)^2 /2}.
  \] 
Note that the spread of the Gaussian function (often denoted $\sigma$) is related to $\omega$ by
$\sigma = 1 / \omega$. A plot of the Gaussian time-function is shown
in Figure~\ref{fig:gaussians}.
\paragraph{Important:} To avoid artifacts from a sudden startup, use
$t_0 \geq 6/\omega$.
\subsection{GaussianInt (or Erf)}\label{gaussianint}
\[
g(t,t_0,\omega) = \dfrac{\omega}{\sqrt{2 \pi}} \int_{-\infty}^t e^{-\omega^2 (\tau - t_0)^2/2}\,d\tau.
\] 
GaussianInt is the time-integral of the Gaussian. A plot of the
GaussianInt time-function is shown in Figure~\ref{fig:gaussians}.
\paragraph{Important:} To avoid artifacts from a sudden startup, use
$t_0 \geq 6/\omega$.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.4\linewidth]{figures/f1-gaussian.png}
  \includegraphics[width=0.4\linewidth]{figures/f2-gaussianint.png}
  \caption{Gaussian (left) and GaussianInt (right) with $\omega=\pi$ and $t_0=0$.}
  \label{fig:gaussians}
\end{centering}
\end{figure}  
%
\subsection{Ricker} \label{ricker}
  \[
  g(t,t_0,\omega) = \left(2 \pi^2 \omega^2 (t - t_0)^2 - 1\right) e^{- \pi^2 \omega^2 (t - t_0)^2}.
  \]
A plot of the Ricker time-function is shown in Figure~\ref{fig:rickers}.

\paragraph{Important:} To avoid artifacts from a sudden startup, use
$t_0 \geq 1.35/\omega$.

\subsection{RickerInt}\label{rickerint}
  \[
  g(t,t_0,\omega) = (t - t_0) e^{- \pi^2 \omega^2 (t - t_0)^2}.
  \]
RickerInt is the time integral of the Ricker function, and is proportional to the time-derivative of
the Gaussian function. Since the RickerInt function tends to zero for large times, it does not lead
to any permanent displacements. A plot of the RickerInt time-function is shown in
Figure~\ref{fig:rickers}.
\paragraph{Important:} To avoid artifacts from a sudden startup, use
$t_0 \geq 1.35/\omega$.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.4\linewidth]{figures/f3-ricker.png}
  \includegraphics[width=0.4\linewidth]{figures/f4-rickerint.png}
  \caption{Ricker (left) and RickerInt (right) with $\omega=1$ and $t_0=0$.}
  \label{fig:rickers}
\end{centering}
\end{figure}  
%
\subsection{Brune} 
 \label{brune}
\[
 g(t,t_0,\omega) = \left\{
\begin{array}{ll} 
0, & t < t_0, \\ 
1 - e^{-\omega(t-t_0)}( 1+\omega(t-t_0) ), & t \geq t_0.
\end{array}
\right.
\]
Note that the Brune function only has one continuous derivative. Because its second derivative is discontinuous at
$t=t_0$, this function can generate noisy numerical solutions. We recommend filtering all computed time
series, or using the {\bf prefilter} command to remove any unresolved motions.

\subsection{BruneSmoothed}
The BruneSmoothed function has three continuous derivatives at $t=t_0$, but is otherwise similar to
the Brune function,
\[
 g(t,t_0,\omega) = \left\{
\begin{array}{ll} 
0, & t < t_0, \\ 
1 - e^{-\omega(t-t_0)}\left[ 1+\omega(t-t_0) + \dfrac{1}{2}(\omega(t-t_0))^2\right. & \\
\quad \left.-\,\dfrac{3}{2\tau_0}( \omega(t-t_0))^3  + \dfrac{3}{2\tau_0^2}( \omega(t-t_0))^4 -
 \dfrac{1}{2\tau_0^3}( \omega(t-t_0))^5 \right], & 0< \omega (t-t_0) < \tau_0,\\
1 - e^{-\omega(t-t_0)}( 1+\omega(t-t_0) ), & \omega (t-t_0) > \tau_0.
\end{array}
\right.
\]
The parameter $\tau_0$ in the above formula is fixed to the value $2.31$. Plots of the Brune and
BruneSmoothed time-functions are shown in Figure~\ref{fig:brunes}. Since the BruneSmoothed function
has three continuous derivatives, it generates less high frequency noise than the Brune function and
gives better accuracy for a given grid resolution.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.4\linewidth]{figures/f9-brune.png}
  \includegraphics[width=0.4\linewidth]{figures/f10-brunesmoothed.png}
  \caption{Brune (left) and BruneSmoothed (right) with $\omega=2$ and $t_0=-1$.}
  \label{fig:brunes}
\end{centering}
\end{figure}  

\subsection{Liu}
\renewcommand{\arraystretch}{1.5}
This function was given in the paper by Liu et al., \cite{liuetal_2006}. 
It is defined by 
\[
g(t,t_0,\omega) = \left\{ 
\begin{array}{ll}
  0, & t \leq t_0, \\
  C\left[0.7(t-t_0) + \dfrac{1.2}{\pi}\tau_1 - \dfrac{1.2}{\pi}\tau_1
  \cos\left(\dfrac{\pi (t-t_0)}{2\tau_1}\right) \right. & \\
     \hfill \left. -\,\dfrac{0.7}{\pi}\tau_1\sin\left(\dfrac{\pi (t-t_0)}{\tau_1}\right)\right],  & 
     t_0 < t \leq \tau_1+t_0, \\
%
  C\left[t-t_0-0.3\tau_1+\dfrac{1.2}{\pi}\tau_1-\dfrac{0.7}{\pi}\tau_1\sin\left(\dfrac{\pi
    (t-t_0)}{\tau_1}\right)\right. & \\ 
    \hfill
    \left. +\,\dfrac{0.3}{\pi}\tau_2\sin\left(\dfrac{\pi(t-t_0-\tau_1)}{\tau_2}\right)\right], &  
    \tau_1+t_0 < t \leq 2\tau_1+t_0, \\
%
  C\left[0.3(t-t_0)+1.1\tau_1+\dfrac{1.2}{\pi}\tau_1\right. & \\
    \hfill
    \left. +\,\dfrac{0.3}{\pi}\tau_2\sin\left(\dfrac{\pi(t-t_0-\tau_1)}{\tau_2}\right)\right], & 
    2\tau_1+t_0 < t \leq \tau+t_0, \\
  1,  &  t > \tau +t_0.
\end{array} \right.
\]
\noindent The parameters are given by $\tau=2\pi/\omega$, $\tau_1=0.13\tau$, $\tau_2 = \tau-\tau_1$,
and $C=\pi/(1.4\tau_1\pi+1.2\tau_1+0.3\tau_2\pi)$.  The Liu function resembles the Brune function,
but the rise is somewhat steeper for small $t-t_0$, see Figure~\ref{fig:liu}.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.4\linewidth]{figures/f12-liu.png}
  \caption{Liu time function with $\omega=2$ and $t_0=0$.}
  \label{fig:liu}
\end{centering}
\end{figure}  

\subsection{Triangle}
\renewcommand{\arraystretch}{1.3}
For $ t_0 < t < t_0 + 1/\omega$,
\[
  g(t,t_0,\omega) = \dfrac{16 \omega}{\pi^2} \left[ \sin(\pi\omega(t - t_0)) - \dfrac{\sin(3 \pi
      \omega(t - t_0))}{9} + \dfrac{\sin(5 \pi \omega(t - t_0)}{25} - \dfrac{\sin(7 \pi \omega(t -
      t_0))}{49}\right],
\] 
with $g(t,t_0,\omega) = 0$ elsewhere. A plot of the Triangle time-function is shown in
Figure~\ref{fig:triandsaw}.
%
\subsection{Sawtooth}
For $ t_0 < t < t_0 + 1/\omega$,
\[
  g(t,t_0,\omega) = \dfrac{8}{\pi^2} \left[\sin(2 \pi \omega (t - t_0) ) - \dfrac{\sin(6 \pi
      \omega(t - t_0))}{9} + \dfrac{\sin(10 \pi \omega (t - t_0) )}{25} - \dfrac{\sin(14 \pi
      \omega(t - t_0 ))}{49}\right],
\]
with $g(t,t_0,\omega) = 0$ elsewhere.  A plot of the Sawtooth time-function is shown in
Figure~\ref{fig:triandsaw}.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.4\linewidth]{figures/f5-triangle.png}
  \includegraphics[width=0.4\linewidth]{figures/f6-sawtooth.png}
  \caption{Triangle (left) and Sawtooth (right) with $\omega=1$ and $t_0=0$.}
  \label{fig:triandsaw}
\end{centering}
\end{figure}  
%
\subsection{Ramp}
\[ 
g(t,t_0,\omega) = \left\{ 
\begin{array}{ll} 
0, & t < t_0,\\
0.5 (1 - \cos(\pi (t - t_0) \omega)),& t_0 \leq t \leq t_0 + 1/\omega,\\
1, & t > t_0 + 1/\omega.
\end{array}
\right.
\]
A plot of the Ramp time-function is shown in Figure~\ref{fig:rampandsmoothwave}.
%
\subsection{Smoothwave}
For $ t_0 < t < t_0 + 1/\omega$,
\begin{multline*}
 g(t,t_0,\omega) = \dfrac{2187}{8} (\omega(t-t_0))^3 - \dfrac{10935}{8} (\omega(t - t_0))^4  +
  \dfrac{19683}{8} (\omega(t - t_0))^5\\ - \dfrac{15309}{8} (\omega(t - t_0))^6 +
  \dfrac{2187}{4}(\omega(t - t_0))^7,
\end{multline*}
with $g(t,t_0,\omega) = 0$ elsewhere. A plot of the Smoothwave time-function is shown in
Figure~\ref{fig:rampandsmoothwave}.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.4\linewidth]{figures/f7-ramp.png}
  \includegraphics[width=0.4\linewidth]{figures/f8-smoothwave.png}
  \caption{Ramp (left) and Smoothwave (right) with $\omega=1$ and $t_0=0$.}
  \label{fig:rampandsmoothwave}
\end{centering}
\end{figure}  
%
\subsection{VerySmoothBump} 
\[
g(t,t_0,\omega) = \left\{ 
\begin{array}{ll} 
0, & t < t_0,\\ 
1024\,\omega^5(t-t_0)^5 (1 - \omega(t-t_0))^5,& t_0 \leq t \leq t_0+1/\omega,\\ 
0, & t > t_0 + 1/\omega.
\end{array}
\right.
\]
The VerySmoothBump function satisfies $0\leq g\leq 1$. It has four continuous derivatives.
A plot of the VerySmoothBump time-function is shown in Figure~\ref{fig:verysmoothbump}.
\begin{figure}
\begin{centering}
  \includegraphics[height=0.4\linewidth]{figures/f11-verysmoothbump.png}
\hspace{10mm}
  \includegraphics[height=0.4\linewidth]{figures/f12-c6smoothbump.png}
  \caption{VerySmoothBump (left) with $\omega=0.5$ and
    $t_0=0$. C6SmoothBump (right) with $\omega=2$ and $t_0=0$.}
  \label{fig:verysmoothbump}  \label{fig:c6smoothbump}
\end{centering}
\end{figure}  
%
\subsection{C6SmoothBump} 
\[
g(t,t_0,\omega) = \left\{ 
\begin{array}{ll} 
0, & t < t_0,\\ 
51480\, \omega^7 (t-t_0)^7 (1- \omega(t-t_0))^7, & t_0 \leq t \leq t_0 + 1/\omega,\\ 
0, & t > t_0 + 1/\omega.
\end{array}
\right.
\]
The C6SmoothBump function has six continuous derivatives and integrates to one.
A plot of the C6SmoothBump time-function is shown in Figure~\ref{fig:c6smoothbump}.
%% \begin{figure}
%% \begin{centering}
%%   \includegraphics[width=0.5\linewidth]{f12-c6smoothbump.png}
%%   \caption{C6SmoothBump with $\omega=2$ and $t_0=0$.}
%%   \label{fig:c6smoothbump}
%% \end{centering}
%% \end{figure}  
%
\subsection{GaussianWindow}
\[
g(t,t_0,\omega) = \sin(\omega t) e^{-(\omega(t-t_0)/N_c)^2/2}
\]
A plot of the GaussianWindow time-function with $N_c=5$ is shown in
Figure~\ref{fig:gaussianwindow}. Note that $N_c$ is specified with the \verb+ncyc+ keyword, which
must be given when this time function is used in the \verb+source+ command.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.6\linewidth]{figures/GW.png}
  \caption{GaussianWindow with $\omega=3.14$, $t_0=0$, and $N_c=5$.}
  \label{fig:gaussianwindow}
\end{centering}
\end{figure}  

\subsection{Dirac}
The Dirac distribution $\delta(t-\tau_0)$ is not a regular time function because it is zero everywhere,
except at $t=\tau_0$, where it is unbounded. The integral of $\delta(t)$ is one, and if $f(t)$ is a
continuous function,
\begin{equation}\label{eq:dirac}
\int f(t)\delta(t-\tau_0)\, dt = f(\tau_0).
\end{equation}
We discretize the Dirac distribution on a grid $t_n = n\Delta_t$, where $\Delta_t>0$ is the same
time step that is used to solve the elastic wave equation. We obtain the discrete time series $d_n$,
$n=0,1,2,\ldots$ by imposing moment conditions such that \eqref{eq:dirac} is satisfied for the
polynomial functions $f(t)=t^q$, $q=0,1,\ldots,Q$, in the sense
\[
\Delta_t \sum_{n=0}^\infty t_n^q d_n = \tau_0^q,\quad q=0,1,\ldots,Q. 
\]
This leads to $Q+1$ conditions for the coefficients $d_n$. The specification of the grid function is
made unique by enforcing $d_n=0$ except at $Q+1$ consecutive grid points surrounding $t=\tau_0$. Note
that $\tau_0$ is {\em not} required to coincide with a time step. This procedure is similar to the
spatial discretization of point force and moment tensor sources, see~\cite{PetSjo-10} for details.

The discretized Dirac distribution triggers all frequencies on the mesh, including completely
unresolved and unphysical motions. The numerical solution is therefore meaningless unless it is
filtered to remove the unresolved motions. The filtering can either be done after the simulation is
completed, or by using the {\bf prefilter} command. The Dirac time function can also be useful for
calculating ``numerical'' Green's functions.

\section{Discrete time function}

The discrete time function uses a quintic (piecewise 5th order polynomial) spline function to
interpolate the discrete function values $g_j = g(\tau_j)$, for $j=1,2,\ldots, N_s$, where $N_s\geq
7$. The function values are specified on an equidistant grid in time, $\tau_j = t_0 + (j-1)
\delta_t$. The step size, $\delta_t>0$, can be chosen independently of the time step that is used to
solve the elastic wave equation. The start time, $t_0$, can also have an arbitrary value. The
interpolation procedure results in six polynomial coefficients for each interval $\tau_j\leq t
<\tau_{j+1}$. The coefficients are chosen such that $g(t)$ becomes four times continuously
differentiable.

It is necessary to evaluate the discrete time function throughout the simulation of the elastic wave
equation, i.e., for $0\leq t\leq T$. If the time series starts at $t_0=\tau_1>0$, the discrete time
function is evaluated using the polynomial coefficients corresponding to the first interval
$[\tau_1,\tau_2]$ for all $0\leq t<\tau_1$. Similarily, if the last data point in the time series
has $\tau_{N_s}<T$, the coefficients of the last interval are used to evaluate the function for
$\tau_{N_s}<t\leq T$. To avoid unexpected results due to extrapolation, we recommend specifying the
discrete time function for all $t\in[0,T]$. Furthermore, to avoid incompatibilities between the
forcing and the homogeneous initial conditions, we also recommend setting $g_j=0$ for all
$\tau_j\leq 0$.

The file format for a discrete time function is decribed in
Section~\ref{sec:discrete-time-function-format}.


\section{What is the frequency content in the time function?}\label{sec:freq}
\index{frequency content}

Figure~\ref{fig:fouriers} displays the absolute values of the Fourier transforms of the functions
Gaussian, RickerInt, Ricker, and the time derivative of the Brune function. Inspection of the
mathematical definitions of the Gaussian and Brune functions shows that the {\tt freq} parameter
specifies the angular frequency for these functions, while it specifies the (regular) frequency for
the Ricker and RickerInt functions. More generally, the relation between the fundamental frequency
$f_0$ and the {\tt freq} parameter is given by
\begin{equation}\label{eq:angular-scaling}
f_0 = \left\{ \begin{array}{ll}
 {\tt freq},& \mbox{for Ricker, RickerInt, VerySmoothBump, C6SmoothBump},\\
 \dfrac{\tt freq}{2\pi},& \mbox{for Liu, Brune, BruneSmoothed, Gaussian, GaussianInt, and GaussianWindow}.
\end{array}\right.
\end{equation}
The plots in Figure~\ref{fig:fouriers} were made with frequency parameter {\tt freq}=0.25 for the
Ricker and RickerInt functions and frequency parameter {\tt freq}=1.5 for the Gaussian and
$d/dt$(Brune) functions. Hence, $f_0\approx 0.25$ for all functions in
Figure~\ref{fig:fouriers}. Note that the Fourier transform of the $d/dt$(Brune) function decays much slower
than the other functions for high frequencies. This is due to its lack of smoothness at $t=t_0$.
\begin{figure}
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/figfouriers.png}
\caption{ Magnitude of the Fourier transform of $d/dt$(Brune) (dark blue), the Gaussian (green), the
  RickerInt (red), and the Ricker (light blue) time-functions. Here {\tt freq}=1.5 for the Gaussian
  and $d/dt$(Brune), and {\tt freq}=0.25 for Ricker and RickerInt.}
\label{fig:fouriers}
\end{center}
\end{figure}

It is the highest significant frequency, $f_{max}$, that generates the shortest waves
and therefore determines how fine the computational grid must be. For practical purposes $f_{max}$
can be defined as the frequency where the amplitude of the Fourier transform falls below 5 \% of its
max value. We have
\begin{equation}\label{eq:upper-power-freq}
f_{max} \approx \begin{cases}
2.5 f_0,&\mbox{Ricker, RickerInt, Gaussian time functions},\\
3.0 f_0,&\mbox{C6SmoothBump time function},\\
4.0 f_0,&\mbox{$d/dt$(Brune) time function}.
\end{cases}
\end{equation}
In other words, simulations using the Brune function are hard to resolve on the grid and need a
significantly finer grid than the other time functions to give reliable results. The relation
between the fundamental frequency $f_0$ and the highest significant frequency $f_{max}$ in
(\ref{eq:upper-power-freq}) is very important. For time functions that not are listed in that
formula, it is possible to estimate $f_{max}$ with the help of the matlab/octave scripts {\tt
  fcnplot.m} and {\tt ftfcnplot.m} in the {\tt tools} directory.

It is important to remember that the estimated highest frequency content in
\eqref{eq:upper-power-freq} assumes that $t_0$ is sufficiently large to avoid unresolved transients
due to a sudden start. Some time functions are identically zero for $t<t_0$. For those functions all
$t_0\geq 0$ give reliable results. For time functions that have an exponential tail for $t<t_0$, it
is important that this tail is sufficiently small for $t=0$. In particular, we recommend
\[
t_0 \geq 6\sigma,\quad \sigma=\begin{cases}
1/{\tt freq},& \mbox{Gaussian and GaussianInt},\\
1/\sqrt{2}\pi\,{\tt freq},& \mbox{Ricker and RickerInt}.
\end{cases}
\]

We remark that inspecting the Fourier transform of a time function only makes sense for functions
that tend to zero for large times. Functions such as {\tt GaussianInt}, {\tt Liu}, {\tt Brune}, and
{\tt BruneSmoothed} tend towards unity for large times. Their zero frequency (DC) component
therefore grows linearly with the length of the time interval, $T$. These functions need to be
differentiated before applying the Fourier transform.

\section{How to choose the grid size} \label{sec:grid-size}
\index{grid size}

The most difficult parameter to choose when preparing the input file is probably the grid size,
$h$. It is extremely important to use a grid size that is sufficiently small, because you must resolve
the waves that are generated by the source. On the other hand you don't want to use an
unnecessarily small grid size, because both the execution time and the memory requirements
increase rapidly when the mesh is refined.

The number of grid points per shortest wavelength, $P$, is a normalized measure of how well a
solution is resolved on the computational grid. Since the shear waves and surface waves have
approximately the same wave length and propagate at approximately the same speed, we can estimate
the shortest wave length by
\[
 L_{min} = \dfrac{\min C_s}{f_{max}}.
\]
Here $C_s$ is the shear velocity of the material and $f_{max}$ is the largest significant frequency
in the time function $g(t)$, as discussed above. Hence the number of grid points per wave length
equals $L_{min}/h$, which is given by
%
\begin{equation}\label{eq:resolutionformula}
  P = \frac{L_{min}}{h} = \dfrac{\min C_s}{h\,f_{max}}. 
\end{equation}
Note that $h$ needs to be made smaller to maintain the same value of $P$ if either $C_s$ is
decreased or if the frequency is increased. In formula (\ref{eq:resolutionformula}), $\min C_s$ is
found from the material properties and $h$ is determined by the input grid specification.  The
frequency spectrum of the solution is determined by the frequency spectrum of the time
function and $f_{max}$ can be estimated from equation \eqref{eq:upper-power-freq}.

\subsection{Lamb's problem}
\label{sec:lamb}

The accuracy of the numerical solution, including the implementation of a point force and the
reflection properties of the super-grid far field boundary condition, can be tested by solving
Lamb's problem~\cite{Lamb_1904}. This problem simulates the motion due to a vertical point force
applied on the free surface of a homogeneous elastic half-space.

We have implemented Mooney's formulas~\cite{Mooney_1974} for solving Lamb's problem. These formulas
give an analytical expression for the Green's function of the vertical component along the free
surface, $z=0$. This Green's function is convolved with the source time function to give the
displacement as function of time. We use a {\tt C6SmoothBump} time function and the convolution is
performed by numerical quadrature using the Quadpack library. This approach allows the displacement
to be evaluated to within $12$ decimal places. Lamb's problem is then solved numerically using
\emph{SW4} and the error in the vertical component is evaluated along the free surface. To evaluate
how fine the grid needs to be, we repeat the test for different grid sizes. See the paper by
Petersson and Sjogreen~\cite{PetSjo-14} for further details.

% 2nd example
In this example, the elastic half-space consists of a homogeneous material with shear wave
velocity $C_s=1000$ m/s, compressional wave velocity $C_p=1000\sqrt{3}$ m/s, and density $\rho=1500$
kg/m$^3$. The elastic half-space is truncated to the computational domain
\[
(x,y,z) \in [0,10000] \times [0,10000]\times[0,5000].
\]
The source is placed on the free surface in the center point of the horizontal plane:
$(5000,5000,0)$. The time dependency of the forcing is a ``C6SmoothBump'' (see Figure
\ref{fig:c6smoothbump}) with $\omega=1$ Hz, $t_0=0$ s and magnitude $10^{13}$ N. The above setup is
created with the input file shown below, which can be found in {\tt examples/lamb/seismic1.in}
\begin{verbatim}
grid nx=151 x=10e3 y=10e3 z=5e3
time t=5.0
supergrid gp=60
block vp=1.7320508076e+03 vs=1000 rho=1500
source type=C6SmoothBump x=5e3 y=5e3 z=0 fz=1e13 freq=1 t0=0
rec x=5e3 y=6e3 z=0 file=v1 sacformat=0 usgsformat=1
\end{verbatim}
Because the frequency parameter of the {\tt C6SmoothBump} time function is $f_0=1$ Hz and $C_s=1000$
m/s, the dominant wave length in the solution is about 1,000 meters. Hence the receiver is located
approximately one wave length from the source.

It is well known that the error in numerical solutions of wave propagation problems is dominated by
phase errors~\cite{Gustafsson-Kreiss-Oliger}. It is therefore interesting to investigate how the
accuracy in the numerical solution depends on the distance between the source and receiver. For this
reason, we expand the above calculation to include a second receiver at distance 10,000 meters from
the source. This input file is given in {\tt examples/lamb/seismic2.in}. In this case, we evaluate
the solution of Lamb's problem using the Fortran program {\tt src/lamb\_one\_point.f}. The vertical
displacements and errors are shown in Figure~\ref{fig:lambSAC}.
\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.9\textwidth]{figures/lamb-err-h66.png}
    \caption{Lamb's problem: Vertical displacement at 1,000 (blue) and 10,000 (red) meters from the
      source. The green and light blue lines show the corresponding errors in the
      numerical solution with $h=200/3$, corresponding to $P=5$ grid points per shortest wave
      length. The displacement is offset by 1 for the second recording.}
    \label{fig:lambSAC}
  \end{center}
\end{figure}
The waveforms are smooth and the problem appears to be well resolved. Because of geometric
spreading, the amplitude of the exact solution decreases with the distance from the source. At the
same time, the amplitude of the error increases. This is because the numerical solution accumulates
discretization errors as it propagates through the computational grid.

We show the errors in the vertical displacement in Table~\ref{tab:lamb-err}. The errors are
presented in max norm, normalized by the max norm of the exact solution. The
frequency parameter in the {\tt C6SmoothBump} time function is $f_0=1$ Hz. Following
(\ref{eq:upper-power-freq}), we estimate the highest significant frequency to be $f_{max}=3.0$
Hz. In this case the formula for the number of grid points per wave length
(\ref{eq:resolutionformula}) becomes
\[
P=\frac{1000}{3 h}.
\]
Also note how quickly the total number of grid points ($N_{GP}$) increases when the grid is
refined. 

The errors are also plotted in Figure~\ref{fig:ppw-err}.
\begin{table}
\begin{center}
\begin{tabular}{| c | c | c | c | c |}
\hline
$h$ & $P$  & $\| e_1^{(z)}\|_\infty / \|U_1^{(z)}\|_\infty$  & $\| e_{10}^{(z)}\|_\infty /
\|U_{10}^{(z)}\|_\infty$ & $N_{GP}$ \\ \hline
 200/3 & 5   & $7.17\cdot 10^{-2}$  & $4.31\cdot 10^{-1}$ & $3.0\cdot 10^7$ \\ \hline
 50    & 6.7 & $3.44\cdot 10^{-2}$  & $2.43\cdot 10^{-1}$ & $7.3\cdot 10^7$ \\ \hline
 100/3 & 10  & $9.31\cdot 10^{-3}$  & $6.99\cdot 10^{-2}$ & $2.4\cdot 10^8$ \\ \hline
 25    & 13.3 & $3.25\cdot 10^{-3}$ & $2.42\cdot 10^{-2}$ & $5.8\cdot 10^8$ \\ \hline
\end{tabular}
\caption{Lamb's problem: Relative max norm errors in the vertical displacement at $1,000$ and
  $10,000$ meters from the source. Here, $h$ is the grid size, corresponding to $P$ grid points per
  shortest wave length. Also, $N_{GP}$ is the total number of grid points in the 3-D grid.}
\label{tab:lamb-err}
\end{center}
\end{table}
The error decreases at a rate approaching ${\cal O}(h^4)$ for the finest grid, indicating that the
numerical method and the discretization of the point force are fourth order accurate.
\begin{figure}[htp]
\begin{centering}
  \includegraphics[width=0.8\linewidth]{figures/ppw-err.png}
  \caption{Lamb's problem: Error in max norm as function of the number of points per wave length at
    1,000 meters (blue) and 10,000 meters (green) from the source. The
    dotted lines indicate the asymptotic decay of the error in a fourth order accurate method.}
  \label{fig:ppw-err}
\end{centering}
\end{figure}
For the same grid size, note that the error is about 7.5 times larger at 10 km from the source,
compared to 1 km. To get the same accuracy at 10 km from the source, the grid size must be reduced
by a factor of $(7.5)^{1/4}\approx 1.65$, i.e., the number of grid points per wave length must be
increased by the same factor.

From this experiment we conclude that the accuracy in \emph{SW4} depends on the distance between the
source and the receiver, which can be normalized by the dominant wave length in the solution. For
most practical purposes the accuracy is acceptable when
\[
6 \leq P \leq 10,
\]
but the exact number depends on the required accuracy. The ratio between the compressional and shear
velocity, $C_p/C_s$, can also have a significant influence on the accuracy of the solution, and the
number of grid points per wave length must be increased for materials with large
$C_p/C_s$, see~\cite{KrePet-12}. 

We finally remark that the best way of checking the accuracy in a numerical simulation is to repeat
the calculation on a finer mesh and compare the results. Unfortunately, this approach is seldomly
used in realistic situations because the computational cost increases too rapidly as the mesh is refined.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Topography} \label{sec:topography}
\index{topography}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The topography command in \emph{SW4} is used to specify the shape of the top surface of the
computational domain,
\[
z=\tau(x,y).
\]
The topography can currently be described in one of four ways: a Gaussian hill
(\S~\ref{sec:topo-gauss-hill}), by the elevation on a latitude-longitude grid
(\S~\ref{sec:topo-gridfile}), through a \verb+rfile+ raster file (\S~\ref{sec:topo-rfile}), an \verb+sfile+ (\S~\ref{sec:topo-sfile}), or by
using a \verb+gmg+ (\S~\ref{sec:topo-gmg})file.

A curvilinear grid is automatically constructed between the topography surface and a user specified depth
$z=$\verb+zmax+. If no topography command is present in the input file, the top surface is taken to
be the plane $z=0$, and no curvilinear grid is constructed. When the topography surface $z=\tau(x,y)$ varies between
$\tau_{min}\leq z\leq \tau_{max}$ ($z$ is positive downwards), the grid generation usually works well if
\begin{equation}\label{zmax-limit}
\mbox{\tt zmax} \geq \tau_{max} + 3(\tau_{max}-\tau_{min}),
\end{equation}

Sometimes it is easier to think in terms of elevation, $e(x,y)=-\tau(x,y)$, because $e$ is positive
above mean sea level. Another way of stating \eqref{zmax-limit} is to set the elevation of the
bottom grid line in the curvilinear grid to satisfy
\begin{equation}
\label{elev-limit}
e_{grid} \leq e_{min} - 3(e_{max} - e_{min}),\quad e_{min}\leq e(x,y) \leq e_{max}.
\end{equation}
You then set \verb+zmax+$=-e_{grid}$.

After reading the topography, \emph{SW4} prints out the min and max $z$-coordinates, as well as the
specified value of \verb+zmax+. For example,
\begin{verbatim}
***Topography grid: min z = -1.1443e+03, max z = 1.0929e+03, \
   top Cartesian z = 8.000000e+03
\end{verbatim}
Here, $\tau_{min} = -1144.3$, $\tau_{max} = 1092.9$ and \verb+zmax=+ 8000.  We have $\tau_{max} +
3(\tau_{max}-\tau_{min})=7804.5$, which satisfies \eqref{zmax-limit}. Alternatively, in terms of
elevation, $e_{max}=1144.3$ and $e_{min}=-1092.9$, so $e_{min} - 3(e_{max}-e_{min}) = -7804.5$ and
$e_{grid}=-8000$, which satisfies \eqref{elev-limit}.

Except for the Gaussian hill topography, the topography surface is smoothed by a Jacobi iteration
before the curvilinear grid is generated,. The purpose of the smoothing is to ensure that the
variations in topography can be resolved on the computational grid. By default, 10 iterations are
performed and this gives a satisfactory result in many cases. It is possible to change the number of
iteration by using the \verb+smooth+ option in the topography command. You can inspect the result of
the smoothing by saving the top grid surface in an image file,
\begin{verbatim}
image mode=grid z=0 cycle=0 file=test
\end{verbatim}
Note that the $z$ coordinate (positive downwards) is saved on a grid image file, while the elevation
(positive upwards) of the raw (before smoothing) topography is saved on a topo image file (obtained by
specifying \verb+mode=topo+ instead of \verb+mode=grid+).

\section{Gaussian hill topography}\label{sec:topo-gauss-hill}
The simplest type of topography is a Gaussian hill, i.e., a topography described by the Gaussian,
\[
  \tau(x,y)= A e^{-( (x-x_c)/Lx )^2 - ( (y-y_c)/L_y )^2}.
\]
The user can place one Gaussian hill at a location specified by $(x_c,y_c)$, in the $(x,y)$-plane.
Furthermore, the user can adjust the amplitude of the hill, $A$, as well as
its spread in the $x$ and $y$-directions, $L_x$ and $L_y$ respectively. 
The Gaussian hill topography command has the following syntax:
\begin{verbatim}
topography input=gaussian zmax=7.5 gaussianAmp=2.4 \
           gaussianXc=3.6 gaussianYc=2.4 \
           gaussianLx=0.25 gaussianLy=0.3
\end{verbatim}
Note the \verb+zmax+ option, which tells \emph{SW4} to extend the curvilinear grid to $z=7.5$.
The most common use of the Gaussian hill topography is for testing, see for example the input
scripts in \verb+examples/twilight+:
\begin{verbatim}
gauss-twi-1.in  gauss-twi-2.in  gauss-twi-3.in 
\end{verbatim}

\section{Topography grid file}\label{sec:topo-gridfile}
The topography can be given on a regular lattice in geographical (lat, lon), or Cartesian $(x, y)$
coordinates. This approach works well together with the \verb+block+, \verb+pfile+, and \verb+ifile+
material commands. It can also be used together with the \verb+rfile+ or \verb+sfile+ commands, but
in those cases it is important that the topography is consistent with the material data, because it
is given relative to mean sea level ($z=0$).

To setup the topography, you can give the command
% for the Grenoble basin test case described in
% Section~\ref{sec:grenoble}, you 
\begin{verbatim}
topography input=grid file=grenobleCoarse.topo zmax=3000 order=2
\end{verbatim}
The file \verb+grenobleCoarse.topo+ holds the elevation (in meters) relative to mean sea level and
must conform to the simple ASCII text format described in Section~\ref{sec:ifile-format}. In the
above case, a curvilinear grid is constructed between the topography surface and $z=3000$, and the
\verb+order=2+ option specifies a second order polynomial stretching in the curvilinear mapping
function. The topography is shown in Figure~\ref{fig:grenoble-topo}.
%
\begin{figure}[htp]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{figures/grenoble-topo.png}
    \caption{Topography in the vicinity of Grenoble, France.}
    \label{fig:grenoble-topo}
  \end{center}
\end{figure}

\section{efile topography}\label{sec:topo-efile}
We deprecated the ability to read an \verb+efile+ in SW4. Users are advised to use \verb+sfile+ or \verb+gmg+ formats.
% The Etree databases for the San Francisco bay area and Northern California contain topographic
% information. You can setup the computational grid to follow this topography by using the following command,
% \begin{verbatim}
% topography input=efile etree=USGSBayAreaVM-08.3.0.etree zmax=8e3 order=3
% \end{verbatim}
% Note that the syntax has been changed from \emph{WPP}. This style of the topography command tells
% \emph{SW4} to read the topography from the specified Etree file. Figure~\ref{fig:erfile-topo} (left) shows
% the resulting elevation of the free surface. 
% %
% \begin{figure}[htp]
%   \begin{center}
%     \includegraphics[width=0.49\textwidth]{figures/efile-topo.png}\hfill
%     \includegraphics[width=0.49\textwidth]{figures/rfile-topo.png}
%     \caption{Topography and bathymetry in the vicinity of Berkeley, California, as
% represented by an {\tt efile} (left) and an {\tt rfile} (right). Here the red line indicates
% zero elevation.}
%     \label{fig:erfile-topo}
%   \end{center}
% \end{figure}
% %
% The \verb+efile+ keyword can also be called \verb+etree+. The \verb+order=3+ option specifies a
% cubic stretching function in the vertical direction. A higher value makes the curvilinear grid
% smoother near the bottom, but can cause a larger variation in grid size near the top. The
% \verb+zmax=8e3+ option tells \emph{SW4} to put the bottom boundary of the curvilinear grid at
% $z=8000$.

% When the computational domain is larger, it is possible to combine the topographic information from
% the detailed and regional databases, using the following syntax:
% \begin{verbatim}
% topography input=efile etree=USGSBayAreaVM.etree xetree=USGSBayAreaVMExt.etree \
%            zmax=8e3 order=3
% \end{verbatim}
% Here the filenames have been abbreviated to improve readability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{rfile topography}\label{sec:topo-rfile}

The first block in an \verb+rfile+ raster file contains the topographic
information. You can setup the computational grid to follow this topography by using the following command,
\begin{verbatim}
topography input=rfile zmax=2e3 order=3  file=berkeley.rfile
\end{verbatim}
Here, the topography command tells \emph{SW4} to read the topography from the specified {\tt
  rfile}. The \verb+order=3+ option specifies the type of
stretching to use when making the curvilinear grid, and the \verb+zmax=2e3+ option tells \emph{SW4}
to put the bottom boundary of the curvilinear grid at $z=2000$. 
% Figure~\ref{fig:erfile-topo} (right)
% shows the elevation of the resulting topography. In this example, the {\tt rfile} holds the same
% information as the {\tt efile (deprecated since 2021)} (shown on the left side of the same figure). The reason the {\tt efile} topography looks rough (pixelated) is that the grid size of the computational grid is
% $h=20$ m, while the horizontal resolution of both the {\tt rfile} and the {\tt efile} is 100 m. The
% reason the {\tt rfile} topography is smoother is because bi-linear interpolation is used to define
% the topography in between the grid points of the {\tt rfile}, while the current query routines for
% the {\tt efile} only support a piecewise constant representation.

Note that the topography must be described by the same {\tt rfile} as the material model, see
Section~\ref{sec:rfile-mat} for further information. The format
for the \verb+rfile+ is described in Section~\ref{sec:rfile-format}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sfile topography}\label{sec:topo-sfile}
The \verb+sfile+ also contains the same topography data as \verb+rfile+, and can be accessed using 
the \verb+topo+ \verb+input=sfile+ argument.
See Section~\ref{sec:sfile-mat} for more information.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{gmg topography}\label{sec:topo-gmg}
The \verb+gmg+ also contains topography data, and can be accessed using 
the \verb+topo+ \verb+input=gmg+ argument.
See Section~\ref{sec:gmg-mat} for more information.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{The material model} \label{sec:material}
\index{material}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In \emph{SW4}, an isotropic elastic material model is defined by the grid point values of the density
($\rho$), the compressional velocity ($V_p$), and the shear velocity ($V_s$). The material
properties can be specified by the \verb+block+ command (\S~\ref{sec:block}), the \verb+rfile+ command (\S~\ref{sec:rfile-mat}), the \verb+pfile+
command (\S~\ref{sec:pfile}), the \verb+ifile+ command (\S~\ref{sec:ifile}), the \verb+gmg+ command (\S~\ref{sec:gmg-mat}), or by a combination of
them. If the same computational grid is used for several simulations, the material model can also be
obtained through the \verb+vimaterial+ command, assuming that it was initially saved using the
\verb+volimage+ command. See \S~\ref{sec:vimat} for details.

This chapter only discusses isotropic elastic materials. See Chapter~\ref{sec:attenuation} for
isotropic visco-elastic material models and Section~\ref{sec:anisotropy} for anisotropic elastic
models.

\emph{SW4} requires that the material model is defined for all interior and boundary grid points in
the computational grid, as defined by the {\tt grid} and optionally the {\tt topography}
commands. Note that \emph{SW4} also uses two layers of ghost points, just outside the computational
domain. If the material model is not defined for ghost points, its properties are extrapolated from
the nearest boundary point. In other words, \emph{SW4} does {\em not} require the material model to
be defined at the ghost points, but will use it if it is provided. This is a change from
\emph{WPP}.

The order within the material commands (block, pfile, rfile, sfile, gmg, and ifile) {\em does} matter (unlike
all other commands) in that the priority of the material command increases towards the end of the
input file. Hence, a material command in the input file can be completely or partially overridden by
subsequent material commands.

In the block, pfile, and ifile commands, material properties are assigned based on the depth below
the free surface. This means that the internal material model depends on the topography, but the
material properties along the free surface will always be the same, independent of the topographic
model. For the rfile and sfile commands, material properties are defined as functions of the
$z$-coordinate, i.e., relative to mean sea level ($z=0$). In this case the topography information is
embedded in the material description. The {\tt rfile} command should always be used with topography
from the same {\tt rfile}. 

%If you combine the {\tt efile} commands with a planar topography, a
%linear mapping is constructed before the material properties are assigned. The properties at the
%free surface are thus mapped to the top grid surface ($z=0$), and the bottom grid surface (with
%$z=z_N$) is assigned material properties for elevation $-z_N$. Elevation values at intermediate grid
%points follow from the linear mapping.
%The material properties in the coarser Cartesian grids are not effected
%by this mapping procedure.

After reading all material commands in the input file and assigning material properties to the
computational grid, \emph{SW4} outputs general information about the ranges in the material
model. For a purely elastic material, the output looks like
\newpage
\begin{verbatim}
       ----------- Material properties ranges ---------------
       1590 kg/m^3 <=  Density <= 3300 kg/m^3
       768 m/s    <=  Vp      <= 7790 m/s
       500 m/s    <=  Vs      <= 4420 m/s
       1.536        <=  Vp/Vs   <= 4.48
       3.975e+08 Pa     <=  mu      <= 6.44701e+10 Pa
       1.4282e+08 Pa     <=  lambda  <= 7.13863e+10 Pa
       ------------------------------------------------------
\end{verbatim}
It is always a good idea to check that these numbers are reasonable before proceeding with the
simulation. In addition, we recommend inspecting the material model along a few \verb+image+ planes.

Before the simulation is started, \emph{SW4} checks that density, $V_p$, and $V_s$ are
positive at all grid points. In addition, it is verified that the first Lam\'e parameter satisfies
$\lambda>0$, that is $V_p/V_s > \sqrt{2}$. If either of these conditions is violated, the program
stops with an error message. You can obtain more detailed diagnostics by setting \verb+verbose=3+
(or higher) in the \verb+fileio+ command.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The block command}\label{sec:block}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The block command can be used to specify material properties in rectangular volumes of the
computational domain, either with constant values or linear vertical gradients. By combining the
block command with the sub-region options we can define a material model composed of three layers:
\begin{verbatim}
block vp=4000 vs=2500 rho=2000 
block vp=6000 vs=3500 rho=2700 z1=15000
block vp=8000 vs=4500 rho=3300 z1=35000 z2=100000
\end{verbatim}
In this case the top layer has a thickness of 15 km, the middle layer 20 km and the lower layer 65 km. Because
these block commands do not specify horizontal coordinates, the values extend to the grid boundaries in
both horizontal directions.  To add a box shaped inclusion of a new material we could add the following line
\begin{verbatim}
block vp=3000 vs=2000 rho=1000 \ 
      x1=4000 x2=8000 y1=3000 y2=7000 z1=10000 z2=70000
\end{verbatim}
\begin{figure}[ht]
\begin{centering}
  \includegraphics[width=0.45\linewidth]{figures/blockVpimage.png}
  \includegraphics[width=0.45\linewidth]{figures/flag.png}
  \caption{Examples of material models specified with the block command.}
  \label{fig:blockpics}
\end{centering}
\end{figure}
An image of $V_p$ in the plane $x=50,000$ is shown in Figure~\ref{fig:blockpics} (left).

Several block commands can be combined to generate more complicated material models, for example
\begin{verbatim}
block vp=8000 vs=4500 rho=3300 vpgrad=-0.01
block vp=3000 vs=2000 rho=1000 \
      x1=1e4 x2=9e4 y1=1e4 y2=9e4 z1=1e4 z2=9e4 vpgrad=0.02
block vp=4000 vs=2500 rho=2000 \
      x1=15e3 x2=85e3 y1=15e3 y2=85e3 z1=15e3 z2=85e3
block vp=6000 vs=3500 rho=2700 \
      x1=15e3 x2=85e3 y1=15e3 y2=85e3 z1=45e3 z2=55e3
block vp=6000 vs=3500 rho=2700 \
      x1=15e3 x2=85e3 z1=15e3 z2=85e3 y1=38e3 y2=45e3
\end{verbatim}
This material is displayed on the right side of Figure~\ref{fig:blockpics}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The efile command} \label{sec:efile}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We deprecated the ability to read an \verb+efile+ in SW4. Users are advised to use \verb+sfile+ or \verb+gmg+ formats.
% \begin{figure}
% \begin{centering}
%   \includegraphics[width=0.49\textwidth]{figures/velmodelbb_roads.png} \hfil
%   \caption{The geographical extent of the etree models for Northern California and the San Francisco
%   bay area.}
%   \label{fig:sfmodel}
% \end{centering}
% \end{figure}
% The efile command is used to obtain material properties from an etree database file. Etree data
% bases use an oct-tree data structure, which allows material properties to be represented with finer
% spatial resolution near the surface. Topography and bathymetry information is included in the data
% base. Note that the same etree database file can be used independently of the grid size. We
% currently have access to an etree database file for Northern California and the extended San
% Francisco bay area. The geographical extent of the etree model is given in Table~\ref{tab:sfdata},
% which also is shown on a map in Figure~\ref{fig:sfmodel}. This model was developed by the USGS and
% can currently be downloaded from {\tt http://earthquake.usgs.gov/data/3dgeologic}. Be aware that the files
% are large (8 + 6 Gbyte) and can take a very long time to download.
% \begin{table}
% \begin{center}
% \begin{tabular}{|l|l|l|} \hline
% \multicolumn{3}{|c|}{\bf Detailed Model} \\ \hline
% Corner & Longitude & Latitude \\ \hline
% SE & -120.64040 & 37.04718 \\ \hline
% SW & -121.91833 & 36.31746 \\ \hline
% NW & -123.85736 & 38.42426 \\ \hline
% NE & -122.56127 & 39.17461 \\ \hline
% \end{tabular} \hspace{5 mm}
% \begin{tabular}{|l|l|l|} \hline
% \multicolumn{3}{|c|}{\bf Regional Model} \\ \hline
% Corner & Longitude & Latitude \\ \hline
% SE & -118.944514 & 36.702176 \\ \hline
% SW & -121.930857 & 35.009018 \\ \hline
% NW & -126.353173 & 39.680558 \\ \hline
% NE & -123.273199 & 41.48486\\ \hline
% \end{tabular}
% \caption{Geographical extent (NAD27 projection) for the central California velocity models. Both
%   models are defined down to 45 km depth.}\label{tab:sfdata}
% \end{center}
% \end{table}%

% In the etree database, material properties are stored as functions of geographical coordinates
% (latitude, longitude, elevation), and \emph{SW4} must determine the geographical coordinates before
% it obtains the material properties from the database. Depending on the options of the \verb+grid+
% command, \emph{SW4} either uses formulas (\ref{eq:lat})-(\ref{eq:lon}), or the \verb+proj.4+
% library, to compute the geographic mapping. Internally to \emph{SW4}, the \emph{cencalvm} software
% library is used to query the etree database, which in turn relies on additional libraries. The
% description in this section assumes that \emph{SW4} has been configured to use the \verb+efile+
% command, see~\cite{SW4-install} for details.

% It is important to note the bounds of the geographical region in the database. Assuming the
% computational domain is contained within the bounds of the database, it is easy to set up the
% material model in the input file:
% \begin{verbatim}
% grid x=100e3 y=100e3 z=40e3 lat=38.0 lon=-121.8 az=144 h=1000
% efile etree=/p/lscratchd/andersp/USGSBayAreaVM-08.3.0.etree 
% \end{verbatim}
% To verify that the computational domain is inside the etree database, we recommend checking the
% geographical coordinates on a map during the construction of the input file. We often use the Google Earth
% program for this purpose.
% %
% In the case when the computational domain is larger than the region covered by the efile, a block
% command can be used to assign material properties to grid points outside of the efile region:
% \begin{verbatim}
% grid x=300000 y=300000 z=60000 lat=38 lon=-121.5 az=135 nx=100
% block vp=8000 vs=4000 rho=1000 rhograd=0.5
% efile etree=/p/lscratchd/andersp/USGSBayAreaVM-08.3.0.etree 
% \end{verbatim}
% However, sharp jumps in material properties can lead to significant scattering of seismic waves. In
% some cases, better results can be obtained by reducing the size of the computational domain to match
% the extent of the etree region.

% To enable use of the extended SF model, the extended etree file must also be downloaded and
% then added to the efile command line (file names have been shortened for improved readability):
% \begin{verbatim}
% efile etree=USGSBayAreaVM.etree xetree=USGSBayAreaVMExt.etree
% \end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The rfile command} \label{sec:rfile-mat}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A material raster file ({\tt rfile}) can be used for storing material properties and
topography/bathymetry. It uses a binary, block-structured, data format that allows material
properties to be represented with finer spatial resolution near the surface of the
earth. Topography/bathymetry information is described by the first block of the raster file. The
grid sizes in the {\tt rfile} are independent of the grid size in the computational grid. The {\tt
  rfile} parser in \emph{SW4} attempts to determine the byte ordering and automatically swap the
bytes if it encounters little-endian ordering on a big-endian machine, or vice versa.

There are two main reasons why the raster file format is ideally suited for large material models
with heterogeneous properties. First, the data on an {\tt rfile} is organized to allow each core to
only read the relevant part of the file, thus saving memory. Secondly, the {\tt rfile} format can be
read in parallel (if a parallel file system is available). In this approach, only a subset of the
cores (processors) interact with the file system, and the data is propagated to all other cores
using calls to the MPI library. The parallel reading capability of the {\tt rfile}
format has been shown to scale well on up to 131,072 cores. In practice, it is the most important
advantage over the {\tt efile format (deprecated since 2021)} and allows material models of the same complexity to be read
significantly faster. 

Material properties in the rfile are stored internally on a block-structured grid, and relies on the
\verb+proj.4+ library to map between Cartesian and geographic coordinates. The {\tt rfile} command
can therefore only be used if \emph{SW4} has been linked with the \verb+proj.4+
library. See~\cite{SW4-install} for instructions.

It is important to note the bounds of the geographical region in the material model. Assuming that
the computational domain is contained within those bounds, and the azimuth of the grid agrees with
the \verb+rfile+, the following command sets up the material model:
\begin{verbatim}
grid x=12e3 y=12e3 z=5e3 nx=601 lat=37.93 lon=-122.25 az=143.6380 proj=tmerc \
     datum=NAD83 lon_p=-123.0 lat_p=35.0 scale=0.9996
rfile filename=USGSBayAreaVM-08.3.0.rfile directory=/Users/petersson1
\end{verbatim}
To verify that the computational domain is inside the \verb+rfile+, we recommend checking the
geographical coordinates on a map during the construction of the input file. We often use the Google Earth
program for this purpose. The restriction that the azimuth of the computational grid
must agree with the azimuth of the \verb+rfile+ is made to simplify the parallel reading algorithm.

The topography and material properties are evaluated on the computational grid using linear
interpolation from the underlying grid in the {\tt rfile} format. When the computational grid is
finer than the grid in the {\tt rfile}, the interpolation leads to some smoothing, see
Figure~\ref{fig:rfile-efile}.
\begin{figure}[h]
\begin{centering}
  \includegraphics[width=0.48\textwidth]{figures/rfile-cp.png}\hfill
\includegraphics[width=0.48\textwidth]{figures/efile-cp.png}\\
  \caption{The compressional wave speed ($C_P$) along the topography using the {\tt rfile} (left) and the {\tt efile (deprecated since 2021)} (right) commands. Here,
    the computational grid has size $h=20$ m, while the horizontal grid sizes of the {\tt rfile}
  and {\tt efile} are both $hh=100$ m. Notice the stair-stepping in the right figure.}
  \label{fig:rfile-efile}

  \includegraphics[width=0.48\textwidth]{figures/rfile-cp-x.png}\hfill
\includegraphics[width=0.48\textwidth]{figures/efile-cp-x.png}\\
  \caption{The compressional wave speed in a vertical cross-section, using the {\tt rfile} (left) and the {\tt efile} (right) commands. Here,
    the computational grid has size $h=20$ m. Near the surface, the grid sizes of the {\tt rfile}
  and {\tt efile} are both $hh=100$ m in the horizontal direction and $hv=25$ m in the vertical
  direction. Below $z=400$, the horizontal and vertical grid sizes are doubled.}
  \label{fig:rfile-efile-2}
\end{centering}
\end{figure}
In this case, the {\tt rfile} was generated by copying the topography and material properties from
the {\tt efile}, using the same resolution in both file formats. A vertical cross-section of the same
model is shown in Figure~\ref{fig:rfile-efile-2}.

The query routines for the {\tt efile} format define constant material properties in each cell,
while the reader of a {\tt rfile} uses linear interpolation to define properties in between the grid
point values. Thus, material discontinuities (such as the vertical fault line) are maintained by 
the {\tt efile} command, but become slightly smeared out by the {\tt rfile} command. On the other
hand, the {\tt efile} interpretation of the material properties on either side of the fault line
leads to stair-stepping artifacts, while the linear interpolation of the {\tt rfile} command results
in a much smoother model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The sfile command} \label{sec:sfile-mat}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The \verb+sfile+ command (``s'' being the next letter after ``r''), was created to include a depth-based curvilinear grid for the material model,  which provides finer resolution close to the surface and avoids storing ``air'' or ``water'' points above the surface. It also includes the ability to write the material model for seismic inversion calculations (using the \verb+sfileoutput+ command, see {\em SW4-mopt} documentation).

\begin{verbatim}
sfile filename=USGSBayAreaVM-08.3.0.sfile directory=/path/to/sfile
\end{verbatim}

The file contents are similar to the \verb+rfile+ file, but are defined with internal (curvilinear) refinement boundaries, and all 5 material properties. Note that the \verb+rfile+ caveats about the computational domain still apply, and geographical region bounds should all be checked against the \verb+sfile+'s {\em origin}, ({\em nx,ny}), {\em hh}, {\em z\_bot}, etc.

Figure~\ref{fig:sfile} shows a schematic of the data layout in a 2D slice
  of the \verb+sfile+ domain.
The material data grids and interfaces are numbered from the top to bottom,
  with the very bottom interface assumed to be flat (constant {\em z\_bot}).
Each grid is bounded above by a {\em z\_interface\_*} (``*'' is the same 
  grid index) at the same constant horizontal grid resolution, {\em hh}.
The very top interface is the finest topography used by SW4 
  \verb+topo+ command for the computational domain.
The number of vertical points is constant, and the vertical grid resolution
  {\em hv} is constant along each grid line (but different across grid lines)
  when there is topography.
The refinement boundaries halve the horizontal grid resolution from bottom
  to top, and double the number of grid intervals.
In order to avoid gaps at refinement boundaries, the bottom interfaces
  of the upper grid are defined as co-linear points calculated from the top
  interface of the lower grid.

See \ref{keyword:sfile} for usage information and \ref{sec:sfile-format}
  for HDF5 file format details.

\begin{figure}[htbp!]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/sfile.png}
  \caption{A schematic of the grid and data layout in {\tt sfile} files.
  Material data lives at grid points (black circles) on grids specified
  by their grid index, horizontal grid spacing, and number of points
  along grid lines connecting the top and bottom interfaces.
  In this case, there are 3 total grids of material data, starting
  from a constant elevation at the bottom of the domain, then separated by
  two interior interfaces, with the domain topography on top.
  }
\label{fig:sfile}
\end{center}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The gmg command} \label{sec:gmg-mat}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The \verb+gmg+ command uses data stored in the GeoModelGrids format (developed by Brad Aagard from USGS, \url{https://geomodelgrids.readthedocs.io}), which has georeferenced grid-based earth models composed of blocks with different grid resolutions. The latest San Francisco Bay region 3D seismic velocity model (v21.1, released on  December 9, 2021) can be downloaded at \url{https://www.usgs.gov/data/san-francisco-bay-region-3d-seismic-velocity-model-v211}. The \verb+gmg+ command has the same syntax with \verb+rfile+ and \verb+sfile+:

\begin{verbatim}
gmg filename=USGS_SFCVM_v21-1_detailed.h5 directory=/path/to/gmgfile/
\end{verbatim}

The file contents are similar to the \verb+sfile+ format, both are using HDF5 as the underlying file format, but they use different schema and curvilinear refinement boundaries. More tools and descriptions about the GeoModelGrids are available at \url{https://github.com/baagaard-usgs/geomodelgrids} and \url{https://geomodelgrids.readthedocs.io}).

See Section \ref{keyword:gmg} for more details options.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The pfile command}\label{sec:pfile}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The pfile command can be used to assign material properties based on depth profiles. A pfile
contains the values of the model features (P-velocity, S-velocity, density, and optionally the
attenuation factors $Q_P$ and $Q_S$) as function of depth at points on a regular lattice covering
the horizontal extent of the computational domain. The points on the lattice are either defined by
their latitude and longitude coordinates, or by the $x$ and $y$-coordinates. The number of grid
points in the depth direction needs to be the same for all profiles, but the grid spacing does not
need to be uniform and can also be different for each profile. Material discontinuities can be
represented by two material values for the same depth value. Material layers, which only occur in a
subset of the profiles, can be tapered to have zero thickness in the remaining profiles. This is
handled by introducing multiple data points with the same depth and material values in a profile.

The lattice of the pfile does not need to have any relation to the computational mesh used in
\emph{SW4} and is often much coarser. The material properties in the computational mesh are assigned
values using Gaussian averaging between the nearest $N_G\times N_G$ profiles in the
latitude-longitude plane and linear interpolation in the depth direction. Let the grid point have
longitude $\theta$, latitude $\phi$ and depth $d$. Material properties are first linearly
interpolated in the depth direction along each profile and then averaged in the latitude-longitude
plane. The number of points in the Gaussian averaging, $N_G$, is assigned by the user in the
\verb+pfile+ command. For example, the following line in the input file makes \emph{SW4} read a
pfile named \verb+material.ppmod+:
\begin{verbatim}
pfile filename=material.ppmod vsmin=1000 vpmin=1732 smoothingsize=4
\end{verbatim}
The optional \verb+vsmin+ and \verb+vpmin+ keywords are used to assign minimum threshold values for
the $P$- and $S$-velocities, respectively. Here, {\tt smoothingsize=4} means that $N_G=4$ in the
Gaussian averaging. A larger value of $N_G$ ($\geq 5$) is particularily useful to avoid staircasing
imprints when the computational grid is much finer than the pfile lattice, see
Figure~\ref{fig:pfile-smoothing}. The {\tt smoothingsize} keyword can be assigned any number greater
than or equal to one.
\begin{figure}
\begin{centering}
  \includegraphics[width=0.48\textwidth]{figures/ps1.png}\hfill
\includegraphics[width=0.48\textwidth]{figures/ps3.png}\\
  \includegraphics[width=0.48\textwidth]{figures/ps4.png}\hfill
\includegraphics[width=0.48\textwidth]{figures/ps5.png} 
  \caption{The {\tt smoothingsize} parameter can be used to average out imprinting from the
    horizontal lattice in a coarse pfile material model. Here we show $V_P$ in the plane $x=3,500$
    as function of $y$ and $-z$. In this case, {\tt smoothingsize}=1 in the top left, {\tt
    smoothingsize}=3 in the top right, {\tt smoothingsize}=4 in the bottom left, and  {\tt
      smoothingsize}=5 in the bottom right plot.}
  \label{fig:pfile-smoothing}
\end{centering}
\end{figure}

When $N_G$ is odd, the Gaussian averaging starts by finding the closest grid point on the
latitude-longitude lattice, $(\phi_i,\theta_j)$. The material property $c$ ($\rho$, $V_p$, $V_s$,
$Q_s$, or $Q_p$) is assigned by the formula
\begin{equation}\label{eq:gaussian-average}
c(\phi,\theta) = \dfrac{ \sum_{m=i-W}^{i+W} \sum_{n=j-W}^{j+W} c_{m,n} \omega_{m,n} }
{ \sum_{m=i-W}^{i+W} \sum_{n=j-W}^{j+W} \omega_{m,n} },\quad W = \frac{N_G-1}{2},
\end{equation}
where the weights are given by
\[
\omega_{m,n} = e^{-[(\phi_m-\phi)^2 + (\theta_n-\theta)^2]/\alpha^2},\quad \alpha = \frac{N_G \Delta}{2
  \sqrt{-\log 10^{-6}}},
\]
where the parameter $\Delta$ is given in header of the pfile (on line 2). It should approximately equal the
grid size in latitude and longitude (which do {\em not} have to be equal). This choice of $\alpha$ makes
the weights $\omega_{m,n}<10^{-6}$ for points that are further from $(\phi_m, \theta_n)$ than $N_G
\Delta/2$, which justifies the truncation of the series in (\ref{eq:gaussian-average}). A
similar procedure is used for even values of $N_G$, but in this case the averaging formula
(\ref{eq:gaussian-average}) is centered around the nearest cell center on the latitude-longitude
lattice.

By default the pfile data are assumed to be given in latitude-longitude coordinates. It is also
possible to read pfiles where the data is given on a Cartesian grid in $(x, y)$-coordinates. To
indicate that the pfile contains data on a  Cartesian grid, use the {\tt style}
option as in the following example:
\begin{verbatim}
pfile filename=materialxy.ppmod vsmin=1000 vpmin=1732 smoothingsize=4 \\
      style=cartesian
\end{verbatim}

Data files for the pfile command are written in an ASCII text format. See
Section~\ref{sec:pfile-format} for a description of both the latitude-longitude pfile and the
Cartesian pfile grid formats.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The ifile command}\label{sec:ifile}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The {\bf ifile} command reads a file holding the depth to material interface surfaces. The material
properties between each pair of material surfaces must be defined by the {\bf material} command. The
depth must be non-negative. Zero depth corresponds to the topography. Material surfaces are
specified on a regular lattice in gegraphic coordinates. The unit for depth is meters, while
latitude and longitude are in degrees. The {\bf ifile} command may be combined with other material
specifications and it is {\em not} necessary that the lattice in geographical coordinates covers the
horizontal extent of the computational domain.

Let $N_{mat}\geq 1$ material surfaces be known at longitudes
\[
\phi_i,\quad i=1,2,\ldots,N_{lon},
\]
and latitudes
\[
\theta_j,\quad j=1,2,\ldots,N_{lat},
\]
Note that the latitudes and the longitudes must either be strictly increasing or strictly
decreasing, but the step size may vary. Also note that the lattice points are independent of those
in the {\bf topography} command.

The material surfaces should be given on the regular lattice
\[
d_{q,i,j} = \mbox{depth to surface number $q$ at longitude $\phi_i$, latitude $\theta_j$.}
\]
The material surfaces correspond to material properties in the following way. At longitude $\phi_i$,
latitude $\theta_j$ material number 1 (as defined by the {\bf material} command) occupies depths
$0\leq d \leq d_{1,i,j}$. Material number 2 occupies depths $d_{1,i,j} \leq d \leq d_{2,i,j}$, and
so on. If $d_{1,i,j}=0$, material number 1 is not used. Similarily, material number $k>1$ is not
used if $d_{k-1,i,j} = d_{k,i,j}$. Material properties are only defined for depths down to the last
surface, i.e.,
\[
0\leq d \leq d_{Nmat,i,j}.
\]
If the computational domain extends below the last material surface, it is necessary to use other
commands to define the material properties in those regions.

The material properties can have a constant, linear, quadratic, and square root dependence of
depth. For example, the most general dependence for density is
\[
\rho(d) = \rho_{k,0} + \rho_{k,1} d + \rho_{k,2} d^2 + \rho_{k,1/2} \sqrt{d},\quad d_{k-1,i,j} \leq d < d_{k,i,j}.
\]
Bi-linear interpolation in longitude and latitude is used to define the material surfaces in between
the data points. Note that only constant values are supported for the quality factors
($Q_P$ and $Q_S$) within each material. 

%An example that uses an ifile material description is discussed in Section~\ref{sec:grenoble}. 
The \verb+ifile+ file format is described in Section~\ref{sec:ifile-format}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The vimaterial command}\label{sec:vimat}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The \verb+vimaterial+ command is intended to speed up the reading of large material models for cases
when many simulations use the same computational grid. In order for this command to work, the
\verb+grid+ and \verb+topography+ commands must be identical between runs. An initial run must
construct the material model using the commands described in the previous sections (block,
pfile, ifile). The initial run must also save the material model using the \verb+volimage+
command. Each of these commands saves one scalar property per file, so three files must be saved for
an elastic material. In subsequent simulations the \verb+vimaterial+ command can replace the initial
material model. This approach works the best on machines with a fast (parallel) file system. Also
note that the \verb+volimage+ files can easily become very large, because the material properties
are saved at each grid point.

For example, if the material model and the topography are given in the etree format, the initial run
reads this information and saves it on 5 separate \verb+volimage+ files,
\begin{verbatim}
fileio pfs=1 path=MaterialModel
grid x=275e3 y=120e3 z=40e3 h=400 lon=-122.688 lat=39.009 az=142.25
topography input=rfile file=USGSBayAreaVM-08.3.0.rfile zmax=8e3 order=3
attenuation nmech=3 phasefreq=1 maxfreq=10

volimage mode=rho file=Lp cycle=0 precision=double
volimage mode=mu file=Lp cycle=0 precision=double
volimage mode=lambda file=Lp cycle=0 precision=double
volimage mode=qp file=Lp cycle=0 precision=double
volimage mode=qs file=Lp cycle=0 precision=double
\end{verbatim}
The \verb+volimage+ files are written in the \verb+MaterialModel+ subdirectory, as specified by the
\verb+path+ option in the \verb+fileio+ command.

Subsequent runs, that use identical grid and topography commands, can read the material
model directly from the \verb+volimage+ files,
\begin{verbatim}
fileio pfs=1 path=OtherRun
grid x=275e3 y=120e3 z=40e3 h=400 lon=-122.688 lat=39.009 az=142.25
topography input=rfile file=USGSBayAreaVM-08.3.0.rfile zmax=8e3 order=3
attenuation nmech=3 phasefreq=1 maxfreq=10

vimaterial path=MaterialModel rho=Lp.cycle=0.rho.3Dimg mu=Lp.cycle=0.mu.3Dimg \
           lambda=Lp.cycle=0.lambda.3Dimg qs=Lp.cycle=0.qs.3Dimg \
           qp=Lp.cycle=0.qp.3Dimg
\end{verbatim}
Note that a path can be specified in the \verb+vimaterial+ command, and that the \verb+fileio+
command now writes the results to a different directory.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Mesh refinement} \label{sec:mesh-ref}
\index{mesh refinement}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The refinement command in \emph{SW4} enables the user to locally refine the computational mesh in
areas where finer resolution is needed, i.e., where the wave speed is small. In order to maintain a
constant resolution in terms of the number of grid points per wavelength for a given frequency (see
Equation~(\ref{eq:resolutionformula})), the grid size should be adjusted such that the ratio $V_s/h$
becomes approximately constant over the computational domain. In \emph{SW4}, we use a composite grid
approach consisting of a set of structured component grids with hanging nodes on the grid refinement
interfaces. This allows the grid resolution to follow the main variations in wave speed, and gives
ideal wave propagation properties in each component grid. To assure stability of the numerical
scheme, an energy conserving coupling approach is used to couple the solution across grid refinement
interfaces.

When using mesh refinement, the extent of the computational domain is determined by the grid command,
which also specifies the grid size in the coarsest component grid,
\begin{verbatim}
grid h=2000 x=40000 y=40000 z=40000
\end{verbatim}
The two refinement commands
\begin{verbatim}
refinement zmax=23000
refinement zmax=6000
\end{verbatim}
specify two mesh refinement interfaces: $z_1=23000$, and $z_2=6000$. As a result, the composite grid
contains three component grids, where the coarsest component has grid size $h=2000$ and covers the
bottom of the computational domain: $z_1\leq z\leq 40000$. Next refinement grid has half the grid
size ($h=1000$) and covers $z_1\leq z\leq z_2$. The grid size in the third component is another
factor of two smaller ($h=500$) and covers the top of the computational domain: $z_2\leq z\leq
0$. The composite grid is shown in Figure~\ref{fig:gridrefs1}, where the grid is plotted in the
vertical $x=20000$ plane.
%
\begin{figure}
\begin{centering}
  \includegraphics[width=0.7\linewidth]{figures/comp-grid-2.png}
  \caption{Composite grid with two mesh refinement interfaces and three Cartesian grids.}
  \label{fig:gridrefs1}
\end{centering}
\end{figure}  
Note that refinement grids are aligned in the sense that every second grid point coincides with a grid point in
the next coarser grid.

The summation by parts finite difference boundary stencil is used at the interfaces between the
component grids. This stencil is applied at six points near the boundary, and is eight points wide,
which leads to a minimum requirement on the number of grid points in the $z$-direction.  On
component grids where {\em both} the upper and lower boundaries are interfaces to another grid, or
has a free surface boundary condition, there has to be at least 12 grid points in the $z$-direction.
However, on grids where {\em only one} of the upper or lower boundaries is an interface to another
grid, or has a free surface boundary condition, eight grid points are required in the
$z$-direction. \emph{SW4} will stop with an error message if the number of grid points in the
$z$-direction is below either of these limits. Normally, the eight grid point limit would only be
tested at the bottom of the computational domain, which by default uses a supergrid damping
layer. Note that the supergrid layer is 30 grid points thick (by default), and must be fully
contained in the bottom grid.

Mesh refinement can also be used together with topography. Here we use an example from a simulation
of the 2007 Alum Rock earthquake.
%(simulation described in~\ref{sec:alumrock}.)
The composite grid is setup with the commands
\begin{verbatim}
grid x=100e3 y=100e3 z=40e3 lat=38.0 lon=-121.8 az=143.638 h=2000
refinement zmax=23e3
refinement zmax=12e3
topography input=rfile zmax=6e3 order=2 file=USGSBayAreaVM-08.3.0.rfile
rfile filename=USGSBayAreaVM-08.3.0.rfile
\end{verbatim}
Here the base grid, which always is Cartesian, has grid size $h=2000$ and covers $23000\leq z\leq
40000$. Next Cartesian grid has half the grid size ($h=1000$) and covers $12000\leq z\leq 23000$. The
grid size in the finest Cartesian component grid is reduced by another factor of two, which gives
$h=500$. This component extends to the bottom of the curvilinear grid, i.e., $12000\leq z\leq
6000$. The vertical extent of the curvilinear grid is specified by the \verb+zmax=6000+ option in
the topography command, i.e., the curvilinear grid covers the domain between $z=6000$ and the
topography surface, $z=\tau(x,y)$. In the horizontal directions, the grid size in the curvilinear
grid is the same as in the finest Cartesian grid. The number of grid points in the vertical
direction is choosen such that the average vertical grid size is the same as the grid size in the
horizontal directions.  A portion of the computational grid is shown in the vertical cross section
$x=50000$, see Figure~\ref{fig:efile-grid}.
%
\begin{figure}[htbp]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{figures/rfile-grid.png}
    \caption{A composite grid with two mesh refinement interfaces and topography. In this case there
      are three Cartesian components and one curvilinear grid following a non-planar topography.}
    \label{fig:efile-grid}
  \end{center}
  \vspace{-10pt}
\end{figure}

After constructing the computational grid, \emph{SW4} outputs information about the number of grid
points in each component grid. For the above example, we get
\begin{verbatim}
Global grid sizes (without ghost points)
Grid         h        Nx        Ny        Nz       Points
   0      2000        51        51        10        26010
   1      1000       101       101        12       122412
   2       500       201       201        13       525213
   3       500       201       201        12       484812
Total number of grid points (without ghost points): 1.15845e+06
\end{verbatim}
Note that most grid points are in grids number 2 and 3, with grid size $h=500$. Further down in
the output file, \emph{SW4}, provides information about the resolution in terms of grid points per
wave length:
\begin{verbatim}
***** PPW = minVs/h/maxFrequency ********
g=0, h=2.000000e+03, minVs/h=1.81531 (Cartesian)
g=1, h=1.000000e+03, minVs/h=3.29057 (Cartesian)
g=2, h=5.000000e+02, minVs/h=5.52953 (Cartesian)
g=3, h=5.000000e+02, minVs/h=0.16 (curvilinear)
\end{verbatim}
As is common in seismic applications, the material velocities are the lowest near the free surface,
i.e., in grid number 3 in this case. From this information, we can estimate the highest frequency
that can be reliably propagated on this mesh. To get $P=8$ grid points per shortest wave length, we
can use a source time function with maximum frequency
\[
f_{max} = \min\frac{V_S}{h P} = \frac{0.16}{8} = 0.02\, \mbox{Hz}.
\]
In this case the grid was made very coarse to make Figure~\ref{fig:efile-grid} clearer. The grid
size need to be decreased for practical computations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Attenuation}\label{sec:attenuation}
\index{attenuation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Viscoelastic modeling}\label{sec:ve-model}

\emph{SW4} implements a linear viscoelastic material model by superimposing $n$ standard
linear solid (SLS) mechanisms, leading to the governing equations
\begin{equation}\label{eq:ve-wave-eqn}
{\displaystyle \rho\dfrac{\p^2\ub}{\p t^2} = \Lb(\lambda_0,\mu_0)\ub - \sum_{\nu=1}^n
\Lb(\lambda_{\nu},\mu_\nu)\bar{\ub}^{(\nu)} + \Fb,\quad \xb\in\Omega,\ t\geq 0},
\end{equation}
where the spatial operator is
\begin{equation}\label{eq:spatial-op}
\Lb(\lambda,\mu)\ub =: \nabla(\lambda(\nabla\cdot\ub)) + \nabla\cdot \left(2\mu {\cal
  D}(\ub)\right),\quad {\cal D}(\ub) = \frac{1}{2}\left(\nabla \ub + \nabla\ub^T\right).
\end{equation}
The memory variables, $\bar{\ub}^{(\nu)}$, in \eqref{eq:ve-wave-eqn} are governed by the
differential equations
\begin{equation}\label{eq:ve-ode}
\displaystyle \frac{1}{\omega_\nu}\frac{\p \bar{\ub}^{(\nu)}}{\p t} + \bar{\ub}^{(\nu)} = \ub,\quad
\xb\in\Omega,\ t\geq 0,
\end{equation}
for $\nu=1,2,\ldots,n$, where $\omega_\nu>0$ are the relaxation frequencies. For more details on
visco-elastic modeling and the numerical method used by \emph{SW4}, we refer to the paper by
Petersson and Sjogreen~\cite{PetSjo-10b} and the references therein.

There are three components in each of the vector variables $\ub$ and $\bar{\ub}^{(\nu)}$,
$\nu=1,2,\ldots,n$, resulting in $3+3n$ differential equations for as many dependent
variables. Hence, compared to the purely elastic case, visco-elastic modeling will require more
memory and more CPU-time.

The material parameters $\mu_\nu$ and $\lambda_{\nu}$, as well as the relaxation frequencies
$\omega_\nu$ are determined by Emmerich and Korn's~\cite{Emm-Korn-87} least-squares procedure. In
this approach, the material parameters are selected such that the quality factors $Q_S$ and $Q_P$ become close to constant
over a frequency range
\[
\omega_{min}\leq \omega \leq \omega_{max}.
\]
Because the computational cost of viscoelastic modeling increases with the number of mechanisms,
$n$, it is desirable to use the smallest value of $n$ that gives acceptable accuracy in the
approximation of $Q(\omega)$. In Figure~\ref{fig:q2-5}, we present $Q(\omega)$ when the material
coefficients are chosen to approximate $Q=100$ in the frequency band $\omega\in[1,100]$. Clearly,
$n=2$ provides inadequate modeling of a constant $Q$ over two decades in frequency, but $n= 3$ gives
a much better approximation. Increasing $n$ further only leads to small improvements. It is
interesting to note that in all models, $Q(\omega)$ grows rapidly for $\omega>\omega_{max}$. Hence
the viscoelastic model does {\em not} provide significant damping of higher (poorly resolved)
frequencies in the numerical solution, and does {\em not} act as an artificial dissipation.
%-------------------------Figure -------------------------------------
\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/q2-5.png}
\caption{Actual quality factor $Q(\omega)$ approximating $Q_0=100$ in the frequency band
  $\tilde\omega\in[1,100]$, for different numbers of viscoelastic mechanisms.}
\label{fig:q2-5}
\end{centering}
\end{figure}

Wave propagation in visco-elastic materials is dispersive, i.e., the phase velocity of a wave
depends on its frequency. Figure~\ref{fig:phase-velo} illustrates that the frequency dependence on
the phase velocity becomes more pronounced when $Q$ gets smaller. Also note that the phase velocity
grows approximately linearly on a logarithmic scale in $\omega$, throughout the frequency band
$[\omega_{min},\omega_{max}]$. Outside this band, the phase velocity tends to constant values.
%-------------------------Figure -------------------------------------
\begin{figure}
\begin{centering}
\includegraphics[width=0.7\textwidth]{figures/phase-velo2.png}
\caption{Relative phase velocity over the frequency band
  $\omega\in[1,100]$. Here, $n=3$, and the different colors correspond to different values of $Q$.}
\label{fig:phase-velo}
\end{centering}
\end{figure}
Due to the dispersive nature of visco-elastic materials, it is necessary to specify the reference
frequency, $\omega_r$, at which the phase velocities are specified.

In \emph{SW4}, visco-elastic modeling is enabled by the {\tt attenuation} command. For example, the
command
\begin{verbatim}
attenuation nmech=3 phasefreq=2.5 maxfreq=10
\end{verbatim}
enables visco-elastic modeling with three SLS mechanisms, tuned for the max frequency
$f_{max}=10$~Hz, such that the phase velocities are valid at the reference frequency
$f_r=2.5$~Hz. For simplicity, the lower frequency in the modeling is always two orders of
magnitude smaller than the max frequency,
\[
f_{min}=\frac{f_{max}}{100}.
\]

Instead of using \verb+maxfreq+, the upper frequency limit can alternatively be specified through the
\verb+minppw+ option. In this case the material model is first evaluated to find $\min V_S/h$. The
upper frequency limit is then calculated through the relation $P=\min V_s/(h
f)$, i.e.,
\[
f_{max} = \frac{1}{P_{min}}\min \frac{V_s}{h},\quad P_{min}=\mbox{minppw}.
\]
The syntax for using \verb+minppw+ is given by
\begin{verbatim}
attenuation nmech=3 phasefreq=2.5 minppw=5
\end{verbatim}
This procedure results in the same visco-elastic model as by replacing the \verb+minppw+ keyword by \verb+maxfreq=+$f_{max}$.

After the input file has been parsed, \emph{SW4} outputs basic information about the attenuation
modeling:
\begin{verbatim}
*** Attenuation parameters calculated for 3 mechanisms, 
      max freq=2.000000e+00 [Hz], min_freq=2.000000e-02 [Hz], \
      velo_freq=1.000000e+00 [Hz]
\end{verbatim}
Note that \verb+max_freq+ = $\omega_{max}/(2\pi)$, etc.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Output options}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Setting the output directory}\label{sec:output-dir}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The fileio command is used to specify by which method and in which directory \emph{SW4} should write
its output files.  If the specified directory does not exist, \emph{SW4} attempts to create it for you. The
fileio command may also be used to set the level of diagnostic messages (verbose) and how often the
time step information is printed. For example, the command
\begin{verbatim}
	fileio path=sw4_dir verbose=1 printcycle=10
\end{verbatim}
causes all output files to be written to the directory "./sw4\_dir". The path may be absolute or
relative to the working directory. The \verb+verbose=1+ option enables some extra diagnostic
messages to be printed to standard output. The default value is 0. A higher value gives more
details, but values exceeding 2 give a lot of information and are mostly intended for debugging
purposes. The \verb+printcycle=10+ instructs \emph{SW4} to output time step information every 10
time steps, instead of the default, which is every 1000 time steps.

\paragraph{Serial and Parallel file systems}

Some parallel machines have a dedicated parallel file system that allows many processors to
simultaneously write to the same file. These file systems are often mounted under a particular
sub-directory. By default, \emph{SW4} assumes that the file system is serial, which means that only
one processor is allowed to write to the same file at the same time. If you have access to a
parallel file system, the I/O performance of \emph{SW4} can sometimes be significantly improved by allowing
several processors to simultaneously write to the same file. You enable this feature by using the {\tt pfs=1}
option,
\begin{verbatim}
	fileio pfs=1 nwriters=16 path=/p/lscratcha/my_output_directory
\end{verbatim}
Note that the parallel file systems is often only accessible from certain
directories. Setting \verb+pfs=1+ without re-directing the output to such a directory may cause
\emph{SW4} to either crash or hang.
The number of processes (cores) that write to disk can be changed with the \verb+nwriters+
option. By default, \verb+nwriters=8+. There is a trade-off when selecting \verb+nwriters+.
If \verb+nwriters+  is too small, \emph{SW4} will not make optimal use of the parallel file system, and some
extra overhead is incurred by passing parts of the data to the writing processors. If \verb+nwriters+ is 
too large, the I/O operation is chopped up in too many small pieces, which will reduce the efficiency. 
To obtain good I/O performance, the striping of the parallel file system needs be set appropriately. In our experience
\verb+nwriters+ should be at least as large as the stripe count. On the Lustre file system, used at Livermore Computing,
the \verb+lfs+ command can be used to set the striping. The striping is set on directories, not on files.
For example to set the stripe count to 30 on the directory \verb+/p/lscratchd/user/sw4runs+, give the command
\begin{verbatim}
lfs setstripe -s 8M -c 30 /p/lscratchd/user/sw4runs
\end{verbatim}
This also sets the stripe size to 8 M byte. The stripe count, 30, will apply to all files that are subsequently
written to the directory. Increasing the stripe count from the default value (currently 2 at LC)
to somewhere around 30--60 can make a big difference when writing large 3D data files, 
such as produced by the volimage command. If only image slices and receiver data are output, the stripe count
is less significant.

%The data is buffered on these cores before it is saved to
%disk. Increasing \verb+nwriters+ therefore allows larger files to be written using the same amount
%or memory. On the other hand, making \verb+nwriters+ smaller usually speeds up the reading or
%writing of large files. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Time-history at a receiver station: the rec (or sac) command}\label{sec:rec}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\emph{SW4} can save the time-history of the solution at a receiver station that is located anywhere
in the computational domain. The basic command looks like this:
\begin{verbatim}
rec x=100e3 y=50e3 z=0 file=sta1
\end{verbatim}
For backwards compatibility with \emph{WPP}, the \verb+rec+ command can also be called \verb+sac+.
The above command makes \emph{SW4} save the three components of the solution at the grid point. The
solution is saved at the grid point which is the closest to the specified $(x,y,z)$ location. 

By default, \emph{SW4} saves the data using the binary Seismic Analysis Code (SAC) format,
see~\cite{Goldstein-et-al}. Since each SAC file contains one component of the solution, the default
\verb+rec+ command results in three files:
\begin{verbatim}
sta1.x  sta1.y  sta1.z
\end{verbatim}
The x,y,z files hold the corresponding solution component. Note that the orientation of the
$z$-component is positive downwards.

The location of the receiver station can alternatively be given in geographical (latitude,
longitude, depth) coordinates. Information about the event location, date, time, and station name is
saved in the header of the SAC file. The event location is taken as the hypocenter, i.e., the
location of the source with the earliest initiation time. The \verb+file+ name is used as the
default station name, but can be modified with the \verb+sta+ option. The date and time are by
default set to be the starting time of the simulation. That datum can be changed by using the
\verb+utcstart+ option in the \verb+time+ command,
%
\begin{verbatim}
time t=10 utcstart=01/04/2012:17:34:45.2343
rec lat=38.25 lon=-122.20 depth=0 file=sta1 sta=EKM
\end{verbatim}
%%
Note that the \verb+depth+ option specifies the depth of the receiver relative to the topography. To
place a receiver at elevation $e$ relative to mean sea level ($e$ is negative below sea level) you
use the option {\tt z=}$-e$. Station that are placed above the topography will be ignored and do not
generate any data.

By default, SAC files are written to disk every 1000 time steps, and at the end of the
simulation. We can change this frequency by using the {\tt writeEvery} option. For example, to
write the SAC file every 100 time steps, you would say
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 writeEvery=100
\end{verbatim}

% {\tt velocity=1} option, \emph{SW4} instead outputs the
%three components of the time-derivative of the solution, i.e., the velocity if \emph{SW4} is setup
%to solve for displacements. The

By default, \emph{SW4} outputs the three components of the solution $\ub(\xb_r,t)=(u_x,u_y,u_z)^T$
at each time step. Here, this quantity is called the displacement. However, it is
important to note that physical meaning of the solution depends on the source time function. For
example, if the displacement corresponds to a \verb+GaussianInt+ source time function, the solution
would hold the corresponding velocity if the time function was changed to a \verb+Gaussian+.

The components that are saved by the \verb+rec+ command can be rotated to the East, North, and vertical
(positive up) directions by using the \verb+nsew+ option,
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 nsew=1
\end{verbatim}
Here, the angle between North and the $x$-axis is determined by the azimuth ({\tt az=...}) option in
the grid command:
\begin{verbatim}
grid x=100e3 y=50e3 z=30e3 lat=37.5 lon=-122.0 az=135
\end{verbatim}
By default, the \verb+rec+ command outputs the three components of the solution (the displacement). The
\verb+rec+ command can also output the time derivative of the solution (the velocity),
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 variables=velocity nsew=1
\end{verbatim}
As indicated here, the \verb+variables+ option can be combined with \verb+nsew+.  To remind the user
of what quantities are saved in a SAC file, we modify the file name extensions according to the
following table:
\begin{center}
%\begin{tabular}{|c|c|c|} \hline
%   & \verb+velocity=0+  & \verb+velocity=1+ \\ \hline
\begin{tabular}{|c|c|c|} \hline
\verb+variables+  & \verb+nsew=0+ & \verb+nsew=1+ \\ \hline\hline
displacement & .x, .y, .z    & .e, .n, .u  \\ \hline
velocity     & .xv, .yv, .zv & .ev, .nv, .uv  \\ \hline
\end{tabular}
\end{center}

It is also possible to save the divergence, curl, or strain of the solution. The {\tt variables}
option governs this behavior. For example,
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 variables=div
\end{verbatim}
outputs a single file named {\tt sta1.div} containing the divergence of the solution, which is
independent of the orientation of the components. Similarly,
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 variables=curl
\end{verbatim}
outputs the Cartesian components of the curl in the files {\tt sta1.curlx}, {\tt sta1.curly}, and
{\tt sta1.curlz}. Furthermore, \emph{SW4} can output the components of the symmetric strain tensor,
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 variables=strains
\end{verbatim}
In this case, six files are generated: {\tt sta1.xx}, {\tt sta1.yy}, {\tt sta1.zz}, {\tt sta1.xy},
{\tt sta1.xz}, and {\tt sta1.yz}. It is also possible to output the non-symmetric displacement gradient by,
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 variables=displacementgradient
\end{verbatim}
which outputs nine components named {\tt sta1.duxdx} to {\tt sta1.duzdz} for the components $\partial u^{(x)}/\partial x$
to $\partial u^{(z)}/\partial z$.

For the curl, the strain, and the displacement gradient only \verb+nsew=0+ has been implemented. That is, we always output the
Cartesian components of these quantities.

%% The {\tt velocity} and {\tt nsew} options also work together with divergence and curl. Setting {\tt
%%   velocity=1} will output the time derivative of any quantity selected by the {\tt variables}
%% option. The {\tt nsew} option has no effect on the scalar divergence field, but {\tt nsew=1} will
%% make \emph{SW4} output a representation of the curl vector in the East, North, and vertical
%% components.  
%% The file name extensions for the div and curl variables are described in the following
%% table:
%% \begin{center}
%% \begin{tabular}{|c|c|c|c|c|} \hline
%%    & \multicolumn{2}{|c|}{\tt variables=div} & \multicolumn{2}{|c|}{\tt variables=curl} \\ \hline
%%    & \verb+velocity=0+  & \verb+velocity=1+ & \verb+velocity=0+  & \verb+velocity=1+  \\ \hline
%% \verb+nsew=0+ & .div & .vdiv & .curlx, .curly, .curlz & .vcurlx, .vcurly, .vcurlz \\ \hline
%% \verb+nsew=1+ & .div & .vdiv & .curle, .curln, .curlu & .vcurle, .vcurln, .vcurlu \\ \hline
%% \end{tabular}
%% \end{center}

%% When {\tt velocity=1}, the strains of the time derivative of the solution are output on files 
%% named {\tt sta1.vxx}, {\tt sta1.vyy}, etc.
%% There is currently no support for outputting the strains in East, North, and vertical coordinates.
\subsection{The ASCII text format}
\emph{SW4} can also output receiver time-histories on an ASCII text format,
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 sacformat=0 usgsformat=1
\end{verbatim}
The ASCII text file holds all components (usually three, but only one when {\tt
  variables=div}, and six when {\tt variables=strains} ) in a single file named {\tt sta1.txt}. When
the \verb+usgsformat=1+ option is used, the file gets extension .txt independently of the
\verb+nsew+ and \verb+variables+ options.  Instead, the header of the file is modified to reflect
its content. Note that you need to give the \verb+sacformat=0+ option unless you want the solution
to be output in both formats.

\subsection{The SAC HDF5 format}
\emph{SW4} can also output receiver time-histories in the HDF5 format,
\begin{verbatim}
rec lat=38.25 lon=-122.20 depth=0 file=sta1 hdf5file=sta.hdf5 sacformat=0 hdf5format=1
\end{verbatim}
The HDF5 file holds all components (usually three, but only one when {\tt
  variables=div}, and six when {\tt variables=strains} ) in a single file named {\tt sta.hdf5}. When
the \verb+hdf5format=1+ and \verb+hdf5file=sta.hdf5+ option is used. 
Note that you need to give the \verb+sacformat=0+ option unless you want the solution
to be output in both formats.

\subsection{Notes on the {\tt rec} command}
\begin{itemize}
\item The files are treated in the same way on parallel and serial file systems, because the data
  for each recording station originates from one processor (core) and is always written by that processor only.
\item The binary SAC format is described in Section~\ref{sec:sac-format}.
\item The ASCII text format is very simple and is outlined in its header.
\item The HDF5 format is described in Section~\ref{sec:sachdf5-format}.
\item The binary SAC files can be read by the SAC program. We also provide a matlab/octave script in
  {\tt tools/readsac.m}.
\item The ASCII text file format can be read by the Matlab/Octave script in {\tt tools/readusgs.m}.
%The ASCII text format was slightly modified with the addition of the strain output option. 
%The Matlab/Octave script {\tt tools/readusgsold.m} can be used to read
%the older version of ASCII text files.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{2-D cross-sectional data: the image command}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The image command saves two-dimensional horizontal or vertical cross-sectional data at a specified
time level. It can be used for visualizing the solution, making the images for a movie, or checking
material properties. Each image file contains a scalar field as function of the spatial coordinates
in the cross-sectional plane. The scalar field can be either a component of the solution, a derived
quantity of the solution, a material property, or a grid coordinate, All in all, \emph{SW4} can
output twenty-nine different image quantities, plus six additional image types for testing. See
Section~\ref{keyword:image} for details.

The cross-sectional plane is specified by a Cartesian coordinate ($x$, $y$, or $z$). The image can
be written at a specific time step or at a specified time. Images can also be output at a fixed
frequency, either specified by a time step interval or a time interval.

For example, the command
\begin{verbatim}
image mode=ux y=500 file=picturefile cycle=1
\end{verbatim}
tells \emph{SW4} to output the $x$-component of the displacement (the solution) along the vertical
$y=500$ plane.  The data is written to a file named {\tt picturefile.cycle=1.y=500.ux.sw4img} after
the first time step ({\tt cycle=1}). The example
\begin{verbatim}
image mode=div x=1000 file=picturefile cycleInterval=100
\end{verbatim}
outputs the divergence of the solution field in the $yz$-plane at the grid surface closest to
$x=1000$. The data is written to the files
\begin{verbatim} 
picturefile.cycle=100.x=1000.div.sw4img
picturefile.cycle=200.x=1000.div.sw4img
...
\end{verbatim}
With this setup, one image file is output every 100 time steps.

Note that the divergence of the solution field does not contain shear (S) waves and the
rotation (curl) of the solution field does not contain compressional (P) waves. These
options can therefore be used to distinguish between P- and S-waves in the solution.

The hvelmax and vvelmax modes store the maximum in time of the horizontal and vertical velocity
components, respectively. As these names indicate, it is assumed that the sources in \emph{SW4} are
set up for calculating displacements. The horizontal velocity is defined as $\max(|u^N_t|,|u^E_t|)$,
where $u^N$ and $u^E$ are the displacement components in the North and East directions,
respectively. The vertical velocity is $|w_t|$, where $w$ is the displacement component in the
$z$-direction. For these modes, the cycleInterval or timeInterval options only determine how often
the maxima are written to disk; the actual accumulation of the maximuma is performed after each time
step.

When \emph{SW4} is run in parallel, the data that gets saved on an {\tt image} file originates from
all processors that are intersected by the image plane. For horizontal image planes, this means all
processors. To improve the I/O performance, image data is first communicated to a number of
dedicated image writing processors. By default, 8 processors write each image file to disk (or all
processors if \emph{SW4} is run on fewer than 8). This number can be changed using the {\tt fileio}
command,
\begin{verbatim}
fileio nwriters=4
\end{verbatim}
The above command tells \emph{SW4} to use 4 processors to write each image file. For simulations
that use very large number of grid points and many processors, care must be taken to make sure that
enough memory is available to buffer the image data before it is written to disk.

\paragraph{Notes on the image command:}
\begin{itemize}
\item By default, single precision data is saved. Double precision data can be saved by
  using the {\tt precision=double} option.
\item When topography is used, an image plane along the free surface is specified by the {\tt z=0} option.
\item A {\tt mode=topo z=0} image holds the elevation (negative $z$-coordinate) of the raw
  topography. It can only be written when topography is used.
\item A {\tt mode=grid z=0} image holds the $z$-coordinate (negative elevation) of the grid along
  the free surface, which is the actual shape of the upper surface of the computational domain.
\item When topography is used, vertical image planes intersect both component
grids in the composite grid. In this case, cross-sectional data from both component grids are stored
on the image file.
\item When attenuation is enabled, the P- and S-phase velocities depend on frequency. The values
  saved on image files correspond to the zero frequency limit.
\item The images files are written in a binary format, see Section~\ref{sec:image-format} for
  details.
\item We provide matlab/octave scripts for reading image files in the {\tt tools} directory. The
  basic function is called {\tt readimage.m}. 
% A higher level interface is provided by the {\tt imageinfo.m} and {\tt plotimage.m} scripts.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Checkpoint and Restart the checkpoint command}\label{sec:checkpoint}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
SW4 can write out checkpoint files with a fixed time step interval. The checkpoint file can be used for restarting a simulation from when the latest checkpoint is written. SW4 writes out one single file for each checkpoint, and user can choose to use either a binary format or the HDF5 format. Checkpoint files can be very large, as it contains data of the entire domain. For the HDF5 format, compression is also supported (with the same parameter as the \verb+ssioutput+ command), users are advised to set a relatively low tolerance with the lossy compression to prevent significant precision loss with the restart. And user should also be aware that a restart from a checkpoint file that uses lossy compression will likely result in different solution results.

Below is an example command to write a checkpoint file every 80,000 steps to the \verb+output+ directory. The checkpoint file name will be starting with \verb+HFCheck+ and includes the time step value when it is written (e.g. HFCheck.cycle=160000.sw4checkpoint). 
\begin{verbatim}
checkpoint cycleInterval=80000 restartpath=output file=HFCheck
\end{verbatim}
To use the HDF5 format and optionally with compression:
\begin{verbatim}
checkpoint cycleInterval=80000 restartpath=output file=HFCheck \
    hdf5=yes zfp-accuracy=1e-5
\end{verbatim}

To restart from a previously written checkpoint file, add the \verb+restartfile+ key word and the checkpoint file name to the \verb+checkpoint+ command:
\begin{verbatim}
checkpoint cycleInterval=80000 restartpath=output file=HFCheck \
    restartfile=HFCheck.cycle=160000.sw4checkpoint \
    hdf5=yes zfp-accuracy=1e-5
\end{verbatim}

Note that when using the \verb+checkpoint+ command in combination with the \verb+rec+, \verb+rechdf5+, and  \verb+ssioutput+ commands, it is advisable to align their write intervals, such that the latest time-series data are also written at the time writing a checkpoint file. For example, a user may set  \verb+writeEvery=1000+ (default) in the \verb+rechdf5+ command, and set \verb+dumpInterval=400+ in the \verb+ssioutput+ command, and set \verb+cycleInterval=40000+, as 40000 is divisible by both 1000 and 4000.

More details are provided in Section \ref{keyword:checkpoint}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Creating a GMT script with the gmt command}\label{sec:gmt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The Generic Mapping Toolkit (\emph{GMT})~\cite{WesselSmithGMT} is a suite of image generation
programs for geophysical applications. These programs can be used to make postscript plots like
Figure~\ref{fig:topography-gmt}. In the example shown here, topography information is included as
well as information on the general setup of the simulation. Note that the {\tt gmt} command in
\emph{SW4} causes an ASCII text file to be generated. This file contains a UNIX C-shell script with
commands for the \verb+gmt+ programs, holding general information about the run such as geometric
coordinates of the computational domain as well as locations of sources and receivers. There are
many options for these programs, and they might need to be fine-tuned to suit the needs of a particular
application, see the \emph{GMT} documentation for details. 

To have \emph{SW4} generate a \emph{GMT} shell script file, you give the command
\begin{verbatim}
gmt file=bolinas.gmt
\end{verbatim}
%
\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{figures/topography-gmt-small.png} 
\caption{Location of the source and stations for the Barnwell simulation. This figure was
  generated using the GMT command, see Section~\protect\ref{keyword:gmt} for details.}
\label{fig:topography-gmt}
\end{center}
\end{figure}
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Examples} \label{sec:examples}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In addition to the layer over half-space problems discussed here, there are additional, more
realistic, examples in the \verb+sw4/examples+ directory. Those cases illustrate the set up of
heterogeneous material models and also visco-elastic attenuation.

\section{The elastic layer over half-space problem: LOH.1}
The LOH.1 problem, defined in the input script \verb+examples/scec/LOH.1-h50.in+, has a layered
material model where the top 1000 meters ($z\in [0, 1000]$) has different properties than the rest of the
domain. The computational domain is taken to be $(x,y,z) \in [0,30000]^2\times [0,17000]$. The
grid size is choosen to be $h=50\,m$ and the material properties in the
different layers are described by
\begin{verbatim}
grid h=50 x=30000 y=30000 z=17000
block vp=4000 vs=2000 rho=2600 
block vp=6000 vs=3464 rho=2700 z1=1000
block vp=4630.76 vs=2437.56 rho=2650 z1=999 z2=1001
\end{verbatim}
The last \verb+block+ command defines the properties right at the interface, using a harmonic
average for the Lam\'e parameters ($\mu$, $\lambda$), and a artithmetic average for denisty. The
problem is driven by a single point moment source, positioned in the lower half-space. The time
function in this problem is a Gaussian (if setup as in the input file, the Gaussian source is
equivalent to using a Brune time function followed by a post processing deconvolution step, as is
described in~\cite{Day-2001}). The advantage of using the Gaussian is that no post processing is
necessary, and the Gaussian function produces less high wave number waves, which are poorly resolved
on the computational mesh. Note that \verb+freq=16.6667+ corresponds to the spread $\sigma=0.06$
({\tt freq} = $1/\sigma$) in the Gaussian time function. The command lines to setup the source and
the time duration of the simulation are:
\begin{verbatim}
time t=9
source x=15000 y=15000 z=2000 mxy=1e18 t0=0.36 freq=16.6667 \ 
       type=Gaussian
\end{verbatim}

We use the \verb+fileio+ command to save all output files in the sub-directory
\verb+LOH1-h50+. If this directory does not exist, \emph{SW4} will attempt to create it for you.
\begin{verbatim}
fileio path=LOH1-h50
\end{verbatim}

The magnitude of the solution along the free surface ($z=0$) is saved on an image file every 0.5
seconds
\begin{verbatim}
image mode=mag z=0 file=surf timeInterval=0.5
\end{verbatim}
In addition, the solution is recorded along a line of receivers on the free surface:
\begin{verbatim}
rec x=15600 y=15800 z=0 file=sta01 usgsformat=1
rec x=16200 y=16600 z=0 file=sta02 usgsformat=1
rec x=16800 y=17400 z=0 file=sta03 usgsformat=1
rec x=17400 y=18200 z=0 file=sta04 usgsformat=1
rec x=18000 y=19000 z=0 file=sta05 usgsformat=1
rec x=18600 y=19800 z=0 file=sta06 usgsformat=1
rec x=19200 y=20600 z=0 file=sta07 usgsformat=1
rec x=19800 y=21400 z=0 file=sta08 usgsformat=1
rec x=20400 y=22200 z=0 file=sta09 usgsformat=1
rec x=21000 y=23000 z=0 file=sta10 usgsformat=1
\end{verbatim}
The velocity time histories for station 10 are shown in Figure~\ref{fig:LOH1} together with a
semi-analytical solution. In Matlab or octave, the semi-analytical solution can be generated by the
scipt in \verb+tools/loh1exact.m+. The syntax is
\begin{verbatim}
octave:4> [t ra tr ve]=loh1exact(0.06);
\end{verbatim}
As is customary in seismology, the velocity components have been rotated to polar components, with
the origin at the source. The vertical component (\verb+ve+) is positive downwards. The {\tt rec}
command outputs the $u_x$, $u_y$ and $u_z$-components of the velocity. These components are rotated
to radial and transverse components using the transformations,
\[
u_{rad} = 0.6 u_x + 0.8 u_y,\quad u_{tran} = -0.8 u_x + 0.6 u_y.
\]
The vertical component is stored in $u_z$ (positive downwards). We conclude that most features in
the solution are very well captured on the grid with $h=50$. The numerical solution becomes almost
identical with the semi-analytical solution when the grid is refined to $h=25$ (experiment not shown).
\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.99\textwidth]{figures/LOH1.png}
    \caption{LOH.1: The radial (top), transverse (middle) and vertical (bottom) velocities for
      receiver number 10. Here the numerical solutions are plotted in red ($h=50$) and the semi-analytical solution is plotted in black.}
    \label{fig:LOH1}
  \end{center}
\end{figure}

By using formulas (\ref{eq:resolutionformula})-(\ref{eq:upper-power-freq}), we can calculate the
number of points per wave length for this simulation. Since we are using a Gaussian time-function,
the center frequency is $f_0=1/(2\pi\sigma)\approx 2.6526$ and we estimate the highest significant
frequency to be $f_{max}\approx 2.5 f_0 = 6.6315$ Hz. The material model has $\min V_s = 2000$
m/s. The grid has size $h=50$ m, which results in
\[
P = \dfrac{2000}{50\cdot 6.6315} \approx 6.03.
\]
From our previous discussion (see Section~\ref{sec:grid-size}), 6 points per wave length is on the
low side, but visual inspection of Figure~\ref{fig:LOH1} indicates very good agreement of the wave
forms. The finer grid with $h=25$ gives $P\approx 12.1$. For the purpose of most engineering
calculations, we suggest using in between $P=6$ and $P=12$ grid points per shortest wave length.

\section{The visco-elastic layer over half-space problem: LOH.3}
The LOH.3 benchmark problem adds effects of anelastic attenuation to the LOH.1 problem. It is
defined in the input script \verb+examples/scec/LOH.3-h50.in+. The input file is very similar to the
LOH.1 case. The visco-elastic modeling is enabled by the \verb+attenuation+ command,
\begin{verbatim}
attenuation phasefreq=2.5 nmech=3 maxfreq=15
\end{verbatim}
In this case, three standard linear solid mechanisms are used (\verb+nmech=3+) to give a material
with approximately constant quality factors in the frequency band $0.15 \leq f \leq 15$ Hz. Note
that only the upper frequency limit needs to be specified (\verb+maxfreq=15+); the lower limit is
always 100 times smaller (and can not be specified). Since the visco-elastic material is dispersive,
we use the \verb+phasefreq=2.5+ option to specify at what frequency the compressional and shear
speeds should apply. In the description of the LOH.3 problem this frequency is given as 2.5 Hz, see
Day et al.~\cite{Day-2003}.

Apart from the density and the material velocities, the material model must include the quality
factors for the attenuation of compressional ($Q_P$) and shear waves ($Q_S$). For this problem, we
use the block commands
\begin{verbatim}
block vs=3464 vp=6000 rho=2700 Qs=69.3 Qp=155.9
block vs=2000 vp=4000 rho=2600 z2=1000 Qs=40 Qp=120
block vs=2437.6 vp=4630.8 rho=2650 Qs=54.65 Qp=137.95 z1=999 z2=1001
\end{verbatim}

Similar to the LOH.1 test case, the source is of point moment-tensor type with a Gaussian
time-function. However, note that the Gaussian has spread $\sigma=0.05$ for LOH.3. This corresponds
to center angular frequency {\tt freq}$= 1/\sigma=20$ rad/s and center frequency
$f_0=20/(2\pi)\approx 3.18$ Hz. The source is specified by the command
\begin{verbatim}
source x=15000 y=15000 z=2000 mxy=1e18 t0=0.3 freq=20 \
       type=Gaussian
\end{verbatim}
Again, artifacts from a sudden startup are avoided by taking the center time to be {\tt t0}$=6
\sigma = 0.3$.  The solution is recorded in the same array of receivers as before.
In this case the semi-analytical solution can be created by the Matlab/Octave script
\verb+tools/loh3exact.m+. The syntax is
\begin{verbatim}
octave:15> [t ra tr ve]=loh3exact(0.05);
\end{verbatim}
As for the LOH.1 problem, the semi-analytical solution is given in polar components. The solution
from \emph{SW4} is saved in Cartesian coordinates and the numerical solution at station 10 can be
read into Octave using the command,
\begin{verbatim}
octave:23> [t1 ux uy uz]=readusgs("sta10.txt");
\end{verbatim}
The components are rotated to polar components using the Octave commands,
\begin{verbatim}
octave:25> ur =  0.6*ux + 0.8*uy;
octave:26> ut = -0.8*ux + 0.6*uy;
\end{verbatim}
We can compare the radial component of the semi-analytical and numerical solutions by giving the
commands
\begin{verbatim}
octave:33> plot(t,ra,"k",t1,ur,"r");axis([0 9 -1.5 1.5])
\end{verbatim}

All three components of the solution at station 10 are shown in Figure~\ref{fig:LOH3}.
\begin{figure}[ht]
  \begin{center}
    \includegraphics[width=0.99\textwidth]{figures/LOH3.png}
    \caption{LOH.3: The radial (top), transverse (middle) and vertical (bottom) velocities at
      receiver number 10. Here the numerical solution with grid size $h=50$ is plotted in red and
      the semi-analytical solution is plotted in black.}
    \label{fig:LOH3}
  \end{center}
\end{figure}
Note that the wave forms are very similar to LOH.1, but the amplitudes are slightly smaller.
As for LOH.1, we can estimate the resolution in terms of the number of grid points per shortest
significant wave length. In this case the center frequency is $f_0\approx 3.18$ Hz and we estimate
the upper power frequency to be $f_{max}\approx 2.5 f_0 = 7.95$ Hz. The material model has $\min V_s
= 2000$ m/s where the grid size is $h=50$ m, and we arrive at
\[
P = \dfrac{2000}{50\cdot 7.95} \approx 5.03.
\]
From our previous discussion (see Section~\ref{sec:grid-size}), 5 points per wave length can only be
expected to give marginal accuracy, but visual inspection of Figure~\ref{fig:LOH3} still indicates
rather good agreement of the wave forms. Note that the visco-elastic dissipation damps out higher
frequencies faster than lower frequencies. Station 10 is 10 km away from the source, and the
domainant wave length is approximately $2000/3.18 \approx 628.9$ meters. Hence, by the time the
solution reaches station 10, it has propagated about 16 wave lengths. The higher frequency
components of the solution are therefore less prominent compared to the purely elastic LOH.1
problem. This can also be seen by comparing the amplitudes in Figures~\ref{fig:LOH3}
and~\ref{fig:LOH1}.


%\section{The Grenoble basin test case}\label{sec:grenoble}
%\index{examples!grenoble}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Keywords in the input file}\label{chap:keywords}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The syntax of the input file is
\begin{verbatim}
command1 parameter1=value1 parameter2=value2 ... parameterN=valueN
# comments are disregarded
command2 parameter1=value1 parameter2=value2 ... parameterM=valueM
...
\end{verbatim}
Each command starts at the beginning of the line and ends at the end of the same line. Blank and
comment lines are disregarded. A comment is a line starting with a \# character. The order of the
parameters within each command makes no difference. The material commands (block, ifile, pfile, rfile, sfile, and gmg)
are applied in the order they appear. The ordering of all other commands is inconsequential. Note
that the entire input file is read before the simulation starts.

Parameter values are either integers (-2,0,5,...), real numbers (20.5, -0.05, 3.4e4), or strings
(earthquake, my-favorite-simulation). Note that there must be no spaces around the = signs and
strings are given without quotation marks and must not contain spaces. Depending on the specific
command, some parameter values are required to fall within specified ranges.

A brief description of all commands is given in the following sections. The commands marked as
[required] must be present in all \emph{SW4} input files, while those marked as [optional] are just
that. Other commands, such as those specifying the material model can be given by a combination of
different commands (block, pfile, rfile, sfile, or ifile). Note that some required commands must occur
exactly once (grid, time). Some optional commands should not occur more than once (topography,
fileio, prefilter, globalmaterial, gmt, developer). Any number of output commands can be given (rec,
image, volimage). Unless \emph{SW4} is run in one of its test modes (twilight, testlamb,
testpointsource, testrayleigh, testenergy), at least one source must be specified, and the material
must be specifed by at least one of the (block, pfile, ifile, rfile, sfile, gmg) commands. Also note that the
test modes are mutually exclusive. Not all of these rules are currently enforced by the parser, but
\emph{SW4} can give unexpected behavior if they are violated.

Note that the same command parser is used for \emph{SW4} and its companion code \emph{SW4opt}, which
calculates source parameters from seismic observations. Here we only document the commands and options
that are relevant for \emph{SW4}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Basic commands}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{fileio [optional]}
\index{command!fileio}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The {\bf fileio} command is used for specifying output directories, setting the amount of
information output by \emph{SW4}, the output frequency during the time-stepping, as well
as enabling fast I/O for parallel file system. See \S~\ref{sec:output-dir} for more information.
\begin{flushleft}\bf
Syntax:\\ \tt fileio path=... verbose=... printcycle=... pfs=... nwriters=... \\ 
\bf Required parameters:\\ 
\rm None
\end{flushleft}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf fileio command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
path        & path to a directory where all output will be written & string & . \\ \hline
verbose	    & sets the level of diagnostic messages written to standard out ($\geq 0$) & int & 0  \\ \hline
printcycle  & sets the interval for printing the cycle, time, dt info & int & 100 \\ \hline
pfs         & assume a parallel (1) or serial (0) file system when writing files (several
processes can simultaneously write the same file on a parallel file system) & int & 0 \\ \hline
nwriters    & set the number of processes that write an image or volimage file & int & 8 \\ \hline
\end{tabular}
\end{center}
\index{fileio parameters!path, verbose, printcycle, pfs, nwriters}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{grid [required]}
\index{command!grid}
\label{keyword:grid}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf Syntax:\\
\tt
grid nx=...  ny=...  nz=...
x=... y=... z=... h=... lat=... lon=... az=... mlat=... mlon=... proj=... ellps=...
datum=... scale=... lat\_p=... lon\_p=...\\
\bf Required parameters:\\
\rm See below.
\end{flushleft}
The grid command specifies the extent of the computational domain and the grid size in the base
grid. Optionally the grid command also specifies the latitude and longitude of the origin and the
azimuth angle between North and the $x$-axis. A number of different projections can be specified.
%The ghostpts option is only relevant for testing and should normally never be used.
%When grid refinement is used, the base grid is the coarsest grid. 

There are three basic ways of specifying the extent of the computational domain and the grid size:  
\begin{itemize}
   \item number of grid points in all three directions and the grid size: {\bf nx=... ny=... nz=... h=...}
   \item lenghts in all three directions and the grid size: {\bf x=... y=... z=... h=...}
   \item lenghts in all three directions and the number of grid points in one direction (the
   x-direction in this example): {\bf x=... y=... z=... nx=...}
\end{itemize}
It is not allowed to over-specify the grid size. For example, if {\bf x=...} is given, you can not
specify both {\bf h=...} and {\bf nx=...}. Similarly, it is not allowed to over-specify the extent
of the computational domain. For example, when {\bf h=...} is given, you can not prescribe both {\bf
  y=...} and {\bf ny=...}.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf grid command parameters (part 1)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default}\\ \hline \hline
x & physical dimension of grid in the x-direction & real & m & none\\ \hline
y & physical dimension of grid in the y-direction & real & m & none\\ \hline
z & physical dimension of grid in the z-direction & real & m & none\\ \hline
\hline
h & grid spacing & real & m & none\\ \hline
\hline
nx & number of grid points in the x-direction & int & none & none\\ \hline
ny & number of grid points in the y-direction & int & none & none\\ \hline	
nz & number of grid points in the z-direction & int & none & none\\ \hline	
\end{tabular}
\end{center}
\index{grid parameters!size - x, y, z, h, nx, ny, nz}

The default projection is spheriodal as described by equations \eqref{eq:lat}-\eqref{eq:lon}. You
can change the parameter $M$ with the {\bf mlat} keyword. By using the {\bf mlon} keyword, you
modify the projection by replacing $M\cos(\phi\pi/180)$ in \eqref{eq:lon} by the constant
$M_{lon}$. 

More accurate projections are available through the Proj4 library (if \emph{SW4} was built with
Proj4 support). These projections are enabled by using one of the keywords {\bf proj}, {\bf ellps},
{\bf datum}, {\bf scale}, {\bf lat\_p}, or {\bf lon\_p}. The values assigned to these keywords are
used to generate a string which is passed directly to the {\tt pj\_init\_plus} routine in the Proj4
library. For example, the \verb+grid+ command
\begin{verbatim}
grid x=12e3 y=12e3 z=5e3 nx=601 lat=37.93 lon=-122.25 az=143.6380 proj=tmerc \
     datum=NAD83 lon_p=-123.0 lat_p=35.0 scale=0.9996
\end{verbatim}
results in the string
\begin{verbatim}
pstr = "+units=m +proj=tmerc +datum=NAD83 +lon_0=-123.0 +lat_0=35.0 +scale=0.9996"
\end{verbatim}
Note that the values of {\bf lat\_p} and {\bf lon\_p} are passed as arguments to {\bf lat\_0} and
{\bf lon\_0}, respectively. See the Proj4 documentation for further guidance.
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf grid command parameters (geographical coordinates and projection)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default}\\ \hline \hline
az & clockwise angle from North to the x-axis & real & degrees & 135.0 \\ \hline
lat & latitude geographical coordinate of the origin & real & degrees & 37.0 \\ \hline
lon & longitude geographical coordinate of the origin & real & degrees & -118.0 \\ \hline
mlat & meters per degree of latitude (spheroidal projection) & real & meters & 111,319.5 \\ \hline
mlon & meters per degree of longitude (spheroidal projection) & real & meters & None \\ \hline
proj & name of  projection (see proj4 documentation) & string & None & utm \\ \hline
ellps & name of ellipse (see proj4 documentation) & string & None & WGS84 \\ \hline
datum & datum of projection (e.g. NAD83) & string & None & None \\ \hline
lon\_p & central meridian of projection & string & degrees & lon \\ \hline
lat\_p & latitude of projection origin & string & degrees & lat \\ \hline
scale & scale factor for central meridian & string & None & None \\ \hline
\end{tabular}
\end{center}
Note: The default projection, given by equations \eqref{eq:lat}-\eqref{eq:lon}, is used if neither
of the {\bf proj}, {\bf ellps}, {\bf datum}, {\bf scale}, {\bf lat\_p}, or {\bf lon\_p} keywords
are specified. The default value for \verb+lat_p+ and \verb+lon_p+ are taken from the geographic
coordinates of the grid origin (\verb+\lon+ and \verb+lat+, respectively). The default value for
\verb+ellps+ is only used in the case that \verb+datum+ is not specified.

\index{grid parameters!location - az, lat, lon, mlat, mlon, proj, ellps, datum, scale, latp, lonp}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{time [required]}
\index{command!time}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf Syntax:\\
\tt
time t=... steps=... utcstart=...\\
\bf Required parameters:\\
\tt t \rm or \tt steps
\end{flushleft}
The time command specifies the duration of the simulation. You can either specify the final time in
seconds by using {\bf t}, or specify the number of time-steps with {\bf steps}.  The size of the
time step is computed internally by \emph{SW4}. You may not over specify the duration of the
simulation, i.e., you can not give both {\bf t=...} and {\bf steps=...}.

The optional {\bf utcstart} keyword is used to assign the Universal Time Coordinate (UTC)
corresponding to simulation time $t=0$. The format of the UTC time is a string (without quotation)
``month/day/year:hour:minute:second.millisecond''. For example, the 17th hour, 34th minute, 12th
second and 233th millisecond of January 31, year 2012, is encoded as {\bf
  utcstart=01/31/2012:17:34:12.233}. When the UTC time is set, all time-series (saved with the {\tt
  rec} command) are time stamped with that datum. The UTC time stamp is essential for correctly
aligning observed data when solving the inverse problem with \emph{SW4opt}.

Note that the \verb+prefilter+ command does {\it not} modify the start time. This is a change from
\emph{WPP}. See \S\ref{keyword:prefilter} for a discussion.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf time command parameters}\\ \hline
{\bf Option} & {\bf Description} & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline \hline
t & duration of simulation & real & s	& none \\ \hline
steps & number of cycles (time-steps) to advance & int & none & none\\ \hline
utcstart & month/day/year:hour:minute:second.millisecond & string & datum & {\emph{SW4} start time}\\ \hline
\end{tabular}
\end{center}
\index{time parameters!t, steps, utcstart}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{supergrid [optional]} 
\index{command!supergrid}
\label{keyword:supergrid}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt
supergrid gp=... dc=... width=...
\\
\bf Required parameters:\\
\rm
None
\end{flushleft}
Note that the keywords are different from \emph{WPP}. Also note that
increasing {\tt dc} may lead to instabilities.
\begin{center}
\begin{tabular}{|l|p{10cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf supergrid command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} &{\bf Units} & \bf{Default} \\ \hline \hline
%
gp &  Number of grid points in the supergrid layer & int & none & 30\\ \hline
width &  Physical width of the supergrid layer & float & meters & none \\ \hline
%
dc & Damping coefficient in supergrid region & real & none & 0.02 \\ \hline
\end{tabular}
\end{center}
The parameters {\tt gp} and {\tt width} are mutually exclusive, setting both will lead to an error. 
\index{supergrid parameters!gp, dc}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{prefilter [optional]}\label{keyword:prefilter}
\index{command!prefilter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf
Syntax:\\
\tt prefilter fc1=... fc2=... type=... passes=... order=...\\
\bf 
Required parameters:\\
\rm 
None
\end{flushleft}
The \verb+prefilter+ command is used to filter all source time functions before the simulation
starts. This approach gives the same result as filtering all time-series after the simulation is
completed. Hence, the \verb+prefilter+ command can be used to reduce the amount of post
processing. The command is particularly useful in combination with the {\bf Dirac} source time
function, which triggers all frequencies on the grid. The \verb+prefilter+ option is also useful for
removing unphysical modes from image files, e.g. max velocities or displacements.  The
\verb+prefilter+ command modifies the time functions in all source commands using a discrete
Butterworth filter. Lowpass and bandpass filters are supported, with orders between 1 and 10. Only
the {\bf fc2} frequency is used for lowpass filters, while it is assumed that {\bf fc1}$<${\bf fc2}
for bandpass filters. The filtering is either forwards in time ({\bf passes=1}), or forwards and
backwards ({\bf passes=2}). For {\bf passes=1}, the filter is causual but gives the filtered signal
a phase shift. When {\bf passes=2} the filter has zero phase shift, but is acausual. In this case,
the filtered signal is only exponentially small as $t\to-\infty$. In order to avoid unphysical
oscillations due to an abrupt start, an estimate of the length of this tail is calculated. A warning
message is printed to stdout if the time shift ({\bf t0}) in the source is smaller than this value.
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf prefilter command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ 
\hline \hline
fc1 & first (low) corner frequency in the filter $(>0)$   & real  & Hz & 0.1 \\ \hline
fc2 & second (high) corner frequency in the filter $(>0)$ & real  & Hz & 1.0 \\ \hline
type & lowpass or bandpass                                & string & None & bandpass \\ \hline
passes & number of passes (1 or 2) & int & None & 2 \\ \hline
order  & order of filter (1-10) & int & None & 2 \\ \hline
\end{tabular}
\end{center}
\index{prefilter parameters!fc1, fc2, type, passes, order}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Sources [required]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{source}
\index{command!source}
\label{keyword:source}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf
Syntax:\\ \tt source
x=... y=... z=... lat=... lon=... depth=... topodepth=... m0=... mxx=... mxy=... mxz=...
myy=... myz=... mzz=... f0=... fx=... fy=... fz=... rake=... strike=... dip=... t0=... 
freq=... type=... ncyc=... dfile=...\\ 
\bf
Required parameters:\\ \rm See below.
\end{flushleft}
There can be multiple source commands in an input file. Each source command either sets up a point
force or a point moment tensor source and should follow the following rules:
\begin{itemize}
\item The location of the source must be specified by either Cartesian ({\bf x, y, z}) or
  geographical ({\bf lat, lon, depth} or {\bf topodepth}) coordinates. The depth below mean sealevel
  ($z=0$) is specified with {\bf z}, while {\bf depth} or {\bf topodepth} specifies the depth below the
  topography.
\item Select a point force or a point moment tensor source:
  \begin{itemize}
  \item Point force: give at least one component of the force vector ({\bf fx, fy, fz}) and
    optionally the amplitude {\bf f0}.
  \item A point moment tensor source can be specified in one of two ways:
    \begin{enumerate}
    \item Seismic moment {\bf m0}, and double couple focal mechanism, {\bf strike/dip/rake} angles
      (as defined in Aki and Richards~\cite{Aki-Richards-02}). 
    \item At least one component of the moment tensor ({\bf mxx}, {\bf mxy}, etc.) and optionally a
      scaling factor {\bf m0}. 
    \end{enumerate}
  \end{itemize}
\item Specify a pre-defined source time function (with the {\bf type} keyword), or give the file
  name for a discrete time function (using the {\bf dfile} keyword).
\end{itemize}
Note that all pre-defined time functions use the {\bf t0} keyword, and all functions except {\bf
  Dirac} also use the {\bf freq} keyword. The only pre-defined time function that uses the {\bf
  ncyc} keyword is {\bf GaussianWindow}.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf source command parameters (part 1)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
x & x position of the source (within domain) & real & m & none \\ \hline
y & y position of the source (within domain) & real & m & none \\ \hline
z & z position of the source (within domain) & real & m & none \\ \hline
\hline
depth & depth of the source $(\geq 0)$ & real & m & none \\ \hline
topodepth & (same as depth) & real & m & none \\ \hline
lat & latitude geographical coordinate of the source & real & degrees & none \\ \hline
lon & longitude geographical coordinate of the source & real & degrees & none \\ \hline
\hline
t0 & offset in time $(\geq 0)$ & real & s & 0.0 \\ \hline
freq & frequency $(>0)$ (not used for Dirac)& real & Hz or rad/s & 1.0 \\ \hline
type & Name of source time function & string & none & RickerInt \\ \hline
ncyc & Number of cycles (must be specified for the GaussianWindow function) & int & none & 0
\\ \hline
dfile & File name for discrete time function & string & none & none \\ \hline
\end{tabular}
\end{center}
\index{source parameters!location - x, y, z, depth, topodepth, lat, lon} 
\index{source parameters!t0, freq, type, ncyc, dfile} 
The {\bf type} keyword specifies the source time function. It can have
the following values: {\tt GaussianInt, Erf, Gaussian, RickerInt, Ricker, Ramp, Triangle, Sawtooth,
  Smoothwave, VerySmoothBump, Brune, BruneSmoothed, GaussianWindow, Liu, Dirac}, and {\tt
  C6SmoothBump}. The functions are described in \S~\ref{sec:predefined}.  
\index{source time function!GaussianInt, Gaussian, RickerInt, Ricker, Ramp, Triangle, Sawtooth, Smoothwave,
  VerySmoothBump, Brune, BruneSmoothed, GaussianWindow, Liu, Dirac, C6SmoothBump}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf source command parameters (point moment tensor)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
m0 & moment amplitude & real & Nm & 1.0 \\ \hline
mxx & xx-component of the moment tensor & real & Nm & 0.0 \\ \hline
myy & yy-component of the moment tensor & real & Nm & 0.0 \\ \hline
mzz & zz-component of the moment tensor & real & Nm & 0.0 \\ \hline
mxy & xy-component of the moment tensor & real & Nm & 0.0 \\ \hline
mxz & xz-component of the moment tensor & real & Nm & 0.0 \\ \hline
myz & yz-component of the moment tensor & real & Nm & 0.0 \\ \hline
\hline
strike & strike angle (see Aki and Richards) & real & degrees & none \\ \hline
dip    & dip angle    & real & degrees & none \\ \hline
rake   & rake angle   & real & degrees & none \\ \hline
\end{tabular}
\end{center}
\index{source parameters!moment - m0, mxx, myy, mzz, mxy, mxz, myz}
\index{source parameters!Aki and Richards - strike, dip, rake}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf source command parameters (point force)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
f0 & point force amplitude & real & N & 1.0 \\ \hline
fx & forcing function in the x direction & real & N & 0.0 \\ \hline
fy & forcing function in the y direction & real & N & 0.0 \\ \hline
fz & forcing function in the z direction & real & N & 0.0 \\ \hline
\end{tabular}
\end{center}
\index{source parameters!point force - f0, fx, fy, fz}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{rupture}
\index{command!rupture}
\label{keyword:rupture}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf
Syntax:\\ \tt rupture file=...\\ 
\bf
Required parameters:\\ \rm name of SRF file.
\end{flushleft}
The \verb+rupture+ command is used to describe complex time-dependent rupture mechanisms over a
fault surface. The \verb+rupture+ command reads a SRF (Standard Rupture Format) file and generates a
kinematic rupture model consisting of a set of moment tensor source terms. The local shear modulus
of the material is taken into account to calculate the strength of each source terms such that the
prescribed amount of slip is achieved on each sub-fault of the SRF file. 

The SRF file format is described on the SCEC wiki webpage:
\verb+http://scec.usc.edu/scecpedia/Standard_Rupture_Format+

Note that when using a rupture file, the default SW4 time-series output is usually velocity instead of displacement.

\index{rupture parameters! file}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{rupturehdf5}
\index{command!rupturehdf5}
\label{keyword:rupturehdf5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf
Syntax:\\ \tt rupturehdf5 file=...\\ 
\bf
Required parameters:\\ \rm name of SRF file in HDF5 format.
\end{flushleft}
The \verb+rupturehdf5+ command is similar to the \verb+rupture+ command, it reads a SRF-HDF5 file that is
converted from a SRF file using the python script found at sw4/tools/srf2hdf5.py.

The SRF-HDF5 file format is described in Section~\ref{sec:rupturehdf5-format}

\index{rupturehdf5 parameters! file}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The material model [required]} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

It is required that the material model is defined in the entire computational domain. The material
properies are extrapolated to the ghost points if they are not covered by the material model (this
is a change from \emph{WPP}). The material commands \verb+block+, \verb+ifile+, \verb+rfile+, \verb+sfile+, \verb+gmg+, and
\verb+pfile+, are applied in the same order as they are given. Hence, it is possible to overwrite
the properties specified by a material command given earlier in the file. This can be particularily
useful when using the \verb+block+ command. Finally, the properties of the optional
\verb+globalmaterial+ command are enforced after all other material commands have been applied. Also
note that the input file is scanned for the \verb+attenuation+ command before any other commands are
parsed. This command may be located anywhere in the input file.

\subsection{attenuation [optional]}
\index{command!attenuation}
\label{keyword:attenuation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The \verb+attenuation+ command is used to enable visco-elastic modeling as described in
Section~\ref{sec:attenuation}. The visco-elastic model is defined through the quality factors $Q_P$
and $Q_S$. Similar to the elastic properties, the quality factors may vary from point to point
throughout the computational domain. If visco-elastic modeling is enabled, the $Q_P$ and $Q_S$
factors must be specified as part of every material command described below. When visco-elastic
modeling is {\em not} enabled, the $Q_P$ and $Q_S$ factors are not required in the material
commands, and are ignored if present.
\begin{flushleft}\bf
Syntax:\\
\tt
attenuation phasefreq=... nmech=... maxfreq=... minppw=... qmultiplier=...
\\
\bf Required parameters:\\
\rm None \\
\bf Note: \rm you may not specify both \verb+maxfreq+ and \verb+minppw+.
\end{flushleft}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf attenuation command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Unit} & \bf{Default} \\ \hline \hline
phasefreq & The frequency ($>0$) at which $C_S$ and $C_P$ are specified & real & Hz & 1.0\\ \hline
nmech     & Number of SLS mechanisms to approximate constant $Q_P$ and $Q_S$ (between 0 and 8) & int & None & 3\\ \hline
maxfreq   & The upper frequency limit  ($>0$) for approximating constant $Q_P$ and $Q_S$ & real & Hz & 2.0 \\ \hline
minppw    & Calculate the upper frequency limit based on this number of grid points per shortest
wave length ($>0$)& real & None & None \\ \hline
qmultiplier & A number that will multiply both $Q_P$ and $Q_S$ & real$>0$  & None & 1.0 \\ \hline
\end{tabular}
\end{center}
\index{attenuation parameters!phasefreq, nmech, maxfreq, minppw, qmultiplier}
If you specify the \verb+minppw+ option, the upper frequency limit is calculated based on the
relation $P=\min C_S/(h f)$, i.e.,
\[
f_{max} = \frac{1}{P_{min}}\min \frac{C_S}{h},\quad f_{max} = \mbox{maxfreq},\quad P_{min}=\mbox{minppw}.
\]
The {\tt qmultiplier} value will multiply $Q_P$ and $Q_S$ at all grid points, before the computation starts,
\[
 Q_P := {\tt qmultiplier} \times Q_P\qquad Q_S := {\tt qmultiplier} \times Q_S.
\] 
This option gives the user an easy way to modify the quality factors, even if they are given on
material file formats that are hard to access manually. Use {\tt qmultiplier} with caution. If the
quality factors are small (i.e., {\tt qmultiplier}$<<1$), the equations will become
ill-posed. \emph{SW4} will detect too small quality factors and terminate before the time stepping
starts.

As a computationally inexpensive alternative to the visco-elastic modeling described in
Section~\ref{sec:attenuation}, it is possible to set \verb+nmech=0+. In this case, the attenuation
modeling is performed without memory variables. After each time step, the solution field at each
grid point $\xb_{i,j,k}$ is simply multiplied by the factor
\[
e^{-\pi f_c \delta_t/Q},
\]
where $\delta_t$ is the time step, $f_c$ is the center frequency, and $Q=Q_S(\xb_{i,j,k})$. The
center frequency is specified by the \verb+maxfreq+ keyword. Note that the attenuation factor $Q_P$
is not used in this case, but it must still be specified.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{block}
\index{command!block}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{keyword:block}
\begin{flushleft}\bf
Syntax:\\
\tt block
vp=... vs=... rho=... qp=... qs=... vpgrad=... vsgrad=... rhograd=... absdepth=... x1=... x2=... y1=... y2=... z1=... z2=...\\
\bf
Required parameters:\\
\tt
%vp, vs, rho
vp, vs, rho  (qp and qs with attenuation)
\end{flushleft}
%
The block command specifies material properties that are constant or vary linearly with depth. By
default, the material properties apply to the entire computational domain. By using the optional
parameters {\bf x1=...}, {\bf x2=...}, etc., the material properties are only assigned in parts of
the computational domain. When used together with the {\bf topography} command, the {\bf absdepth}
flag determines how the $z$-coordinates are used. If {\bf absdepth}=0 (default) {\bf z1=...} and
{\bf z2=...} specify depths below the free surface. If {\bf absdepth}=1,  {\bf z1=...} and
{\bf z2=...} bound the $z$-coordinate of the material block.

The gradient parameters {\bf vpgrad}, {\bf vsgrad}, and {\bf rhograd} specify linear variations in the
$z$-direction (downward). The units for {\bf vpgrad} and {\bf vsgrad} are 1/seconds, which
can be interpreted as m/s per m, or km/s per km. The linear variation is relative to the properties at
the free surface ($z=0$ or depth=0 with topography), e.g.,
\[
C_p(z) = {\bf vp} + z \, {\bf vpgrad}.
\]
Note that when {\bf vpgrad} is specified together with ${\bf z1}=z_1$, $C_p(z_1) = {\bf vp} + z_1\,
{\bf vpgrad}$. Hence, the material properties at the top of the block ($z=z_1$) can be very
different from {\bf vp} when $z_1\, {\bf vpgrad}$ is large.
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf block command parameters (part 1)}\\ \hline
{\bf Option} & {\bf Description}          & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
vp          & P-wave velocity           & real $>0$  & m/s      & none \\ \hline
vs          & S-wave velocity           & real $>0$  & m/s      & none \\ \hline
rho         & density                   & real $>0$  & kg/m$^3$ & none \\ \hline
vpgrad      & vertical gradient for vp  & real       & m/s/m    & none \\ \hline
vsgrad      & vertical gradient for vs  & real       & m/s/m    & none \\ \hline
rhograd     & vertical gradient for rho & real       & kg/m$^4$ & none \\ \hline
qp (or Qp)  & P-wave quality factor     & real $>0$  & none     & none \\ \hline
qs (or Qs)  & S-wave quality factor     & real $>0$  & none    & none \\ \hline
\end{tabular}
\end{center}
\index{block parameters!vp, vs, rho, vpgrad, vsgrad, rhograd, qp, qs}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf block command parameters (part 2)}\\ \hline
{\bf Option} & {\bf Description}          & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
x1          & minimum x-dim for the box shaped sub-region & real & m & -max x \\ \hline
x2          & maximum x-dim for the box shaped sub-region & real & m & 2 max x \\ \hline
\hline
y1          & minimum y-dim for the box shaped sub-region & real & m & -max y \\ \hline
y2          & maximum y-dim for the box shaped sub-region & real & m & 2 max y \\ \hline
\hline
z1          & minimum z-dim for the box shaped sub-region & real & m & -max z \\ \hline
z2          & maximum z-dim for the box shaped sub-region & real & m & 2 max z \\ \hline
\hline
absdepth    & {\tt z1} and {\tt z2} relative to topography (0), or absolute $z$-coordinate (1) & int
& none & 0 \\ \hline 
\end{tabular}
\end{center}
\index{block parameters!x1, x2, y1, y2, z1, z2, absdepth}
%

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %  Efiles
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{efile}
% \index{command!efile}
% \label{keyword:efile}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{flushleft}
% \bf
% Syntax:\\
% \tt
% efile etree=... xetree=... logfile=... query=... access=... resolution=...\\
% \bf 
% Required parameters:\\
% \tt etree
% \end{flushleft}
% \begin{center}
% \begin{tabular}{|l|p{8cm}|l|l|l|} \hline
% \multicolumn{5}{|c|}{\bf efile command parameters (part 1)}\\ \hline
% \bf{Option} & \bf{Description}                                    & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline 
% \hline
% etree      & full path to the etree database file                 & string   & none   & none \\ \hline
% xetree     & full path to the extended etree database file        & string   & none   & none \\ \hline
% logfile    & name of log file                                     & string   & none   & none \\ \hline
% \end{tabular}
% \end{center}
% \begin{center}
% \begin{tabular}{|l|p{8cm}|l|l|l|} \hline
% \multicolumn{5}{|c|}{\bf efile command parameters (part 2)}\\ \hline
% \bf{Option} & \bf{Description}                                & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline 
% \hline
% query      & type of query to perform                         & string  & none   & MAXRES \\ \hline
% resolution & average properties over this distance (for query=FIXEDRES) & real  & m      & $h$ \\ \hline
% access     & can be set to parallel or serial                 & string  & none   &  parallel \\ \hline
% \end{tabular}
% \end{center}
% \index{efile parameters!etree, xetree, logfile, query, resolution, access}
%
% The query option can be set to one of the following:
% %
% \begin{center}
% \begin{tabular}{lp{12cm}} \hline
% \bf{query option} & \bf{Description} 
% \\ \hline 
% MAXRES & Sample the data at the maximum available
% resolution in the database. This is the default query type. 
% \\ 
% FIXEDRES & Average the material properties at the requested resolution, which is specified with the
% \verb+resolution+ keyword. The default resolution is the grid spacing. $h$ \\
% \end{tabular}
% \end{center}
% %
% For example, to set the data to be sampled at 1 km resolution:
% \begin{verbatim}
% rfile query=FIXEDRES resolution=1000 etree=USGS-SF1906.etree
% \end{verbatim}
% Note: the logfile option can be used to track if any grid points were outside the etree database
% domain, or if any grid points were located in the air.

%
\subsection{pfile}
\index{command!pfile}
\label{keyword:pfile}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt
pfile filename=... directory=... smoothingsize=... vpmin=... vsmin=... rhomin=... flatten=... style=... \\
\bf Required parameters:\\
\tt filename
\end{flushleft}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l||l|} \hline
\multicolumn{5}{|c|}{\bf pfile command parameters}\\ \hline
{\bf Option} & {\bf Description}                        & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
filename      & name of input pfile                     & string  & none & none \\ \hline
directory     & name of directory for the input pfile   & string  & none & . \\ \hline
smoothingsize & smooth data over stencil of this width ($\geq 1$) & int & none & 5 \\ \hline
vpmin         & minimum threshold value for $C_p$       & real    & m/s  & 0  \\ \hline
vsmin         & minimum threshold value for $C_s$       & real    & m/s  & 0  \\ \hline
rhomin        & minimum threshold value for density     & real    & m/s  & 0  \\ \hline
flatten       & Flatten the earth model (T or F)        & string  & none & F  \\ \hline
style         & type of grid data: {\tt geographic} or {\tt cartesian} & string  & none & geographic \\ \hline
\end{tabular}
\end{center}

\index{pfile parameters!filename, directory, smoothingsize, vpmin, vsmin, rhomin, flatten, style}

%
\subsection{rfile}
\index{command!rfile}
\label{keyword:rfile}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt
rfile filename=... directory=...\\
\bf Required parameters:\\
\tt filename
\end{flushleft}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l||l|} \hline
\multicolumn{5}{|c|}{\bf rfile command parameters}\\ \hline
{\bf Option} & {\bf Description}                        & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
filename      & name of raster file                     & string  & none & none \\ \hline
directory     & name of directory for the raster file   & string  & none & . \\ \hline
\end{tabular}
\end{center}
Note that only relative paths are currently supported in the \verb+filename+ keyword. Use the
\verb+directory+ keyword to specify absolute paths.

\index{rfile parameters!filename, directory}

%
\subsection{sfile}
\index{command!sfile}
\label{keyword:sfile}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt
sfile filename=... directory=...\\
%sfile mode=... filename=... directory=...\\

\bf Required parameters:\\
\tt filename
\end{flushleft}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l||l|} \hline
\multicolumn{5}{|c|}{\bf sfile command parameters}\\ \hline
{\bf Option} & {\bf Description}                        & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
%mode      & \verb+read+ to read the file                    & string  & none &
%  read
%\\ \hline
%\hline
filename      & name of raster file                     & string  & none & none \\ \hline
directory     & name of directory for the raster file   & string  & none & . \\ \hline
\end{tabular}
\end{center}
Note that sfile uses HDF5 format, so SW4 must be compiled with HDF5. Also only relative paths are currently supported in the \verb+filename+ keyword. Use the
\verb+directory+ keyword to specify absolute paths.

\index{sfile parameters!filename, directory}



%
\subsection{gmg}
\index{command!gmg}
\label{keyword:gmg}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt
gmg filename=... directory=...\\

\bf Required parameters:\\
\tt filename
\end{flushleft}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l||l|} \hline
\multicolumn{5}{|c|}{\bf gmg command parameters}\\ \hline
{\bf Option} & {\bf Description}                        & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
%mode      & \verb+read+ to read the file                    & string  & none &
%  read
%\\ \hline
%\hline
filename      & name of GMG file                     & string  & none & none \\ \hline
directory     & name of directory for the GMG file   & string  & none & . \\ \hline
\end{tabular}
\end{center}
Note that GMG uses HDF5 format, so SW4 must be compiled with HDF5. Also only relative paths are currently supported in the \verb+filename+ keyword. Use the
\verb+directory+ keyword to specify absolute paths.

\index{gmg parameters!filename, directory}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{ifile}
\index{command!ifile}
\label{keyword:ifile}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt ifile filename=... input=...\\
\bf Required parameters:\\
\tt filename
\end{flushleft}
The ifile command specifies the depth of material surfaces as function of longitude and latitude,
and must be used in conjunction with the {\bf material} command. The file format is
described in Section~\ref{sec:ifile-format}.
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf ifile command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
filename & name of input file holding material surfaces & string & None  \\ \hline
input & {\tt cartesian} or {\tt geographic} & string & None  \\ \hline
\end{tabular}
\end{center}
\index{ifile parameters!filename, input}
If {\tt input=cartesian}, the file is assumed to give the material surfaces as function of the $x$-
and $y$-coordinates. If {\tt input=geographic}, they are functions of latitude and longitude. See
Section~\ref{sec:ifile-format} for details.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{material}
\index{command!material}
\label{keyword:material}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt material
id=... vp=... vs=... rho=... vpgrad=... vsgrad=... rhograd=... vp2=... vs2=... rho2=... vpsqrt=... vssqrt=... rhosqrt=... qp=... qs=...\\ 
\bf Required parameters:\\
\tt id, vp, vs, rho
\end{flushleft}
The {\bf material} command is used to define material properties together with the {\bf ifile}
command, see Section~\ref{sec:ifile-format} for the file format.
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf material command parameters (constants)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
id & material ID number $>0$         & int & None  \\ \hline
vp & P-wave velocity & real & None \\ \hline
vs & S-wave velocity & real & None \\ \hline
rho & Density & real & None \\ \hline
qp or Qp & P-wave quality factor & None & None \\ \hline
qs or Qs & S-wave quality factor & None & None \\ \hline
\end{tabular}
\end{center}
\index{material parameters!id, vp, vs, rho, qp, qs}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf material command parameters (gradients)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
vpgrad & P-velocity gradient & real & 0.0 \\ \hline
vsgrad & S-velocity gradient & real & 0.0 \\ \hline
rhograd & Density gradient   & real & 0.0 \\ \hline
\end{tabular}
\end{center}
\index{material parameters!vpgrad, vsgrad, rhograd}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf material command parameters (higher order)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
vp2 & P-velocity quadratic coefficient & real & 0.0 \\ \hline
vs2 & S-velocity quadratic coefficient & real & 0.0 \\ \hline
rho2 & Density quadratic coefficient   & real & 0.0 \\ \hline
vpsqrt & P-velocity $\sqrt{z}$ coefficient & real & 0.0 \\ \hline
vssqrt & S-velocity $\sqrt{z}$ coefficient & real & 0.0 \\ \hline
rhosqrt & Density $\sqrt{z}$ coefficient    & real & 0.0 \\ \hline
\end{tabular}
\end{center}
\index{material parameters!vp2, vs2, rho2, vpsqrt, vssqrt, rhosqrt}

\subsection{globalmaterial [optional]}
\index{command!globalmaterial}
\label{keyword:globalmaterial}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt globalmaterial vpmin=... vsmin=...\\
\bf Required parameters:\\
\rm None
\end{flushleft}
The {\bf globalmaterial} command is used to put threshold values on the $P$- and $S$-velocities in
the material model. These thresholds are enforced after the material properties have been assigned
to all grid points.
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf globalmaterial command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
vpmin & Minimum P-wave velocity $(>0)$ & real & None \\ \hline
vsmin & Minimum S-wave velocity $(>0)$ & real & None \\ \hline
\end{tabular}
\end{center}
\index{globalmaterial parameters!vpmin, vsmin}

%\subsection{randomize [optional]}
%\index{command!randomize}
%\label{keyword:randomize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{flushleft}\bf
%Syntax:\\
%\tt randomize amplitude=... lengthscale=... lengthscalez=... gradient=... sdthreshold=... seed1=... seed2=... seed3=... \\
%\bf Required parameters:\\
%\rm None
%\end{flushleft}
%The {\bf randomize} command makes a random perturbation of the material velocities $C_p$ and $C_s$, according to
%$$
% C_p := (1+A(z)*\theta)C_p\qquad C_s := (1+A(z)*\theta)C_s\qquad
%$$
%where $\theta$ is a random field with correlation lengths specified by the {\tt lengthscale}
%and {\tt lengthscalez} options. The range of $\theta$ is limited to $-n\sigma \leq \theta \leq n\sigma$, where
%$\sigma$ is the standard deviation of $\theta$ and $n$ is set by the parameter {\tt sdthreshold}. 
%By default $n=3$. This is large enough to avoid visible ``clipping'' effects. 
%To enforce $-1 \leq \theta \leq 1$, set $n=1.732$. 
%$C_p$ and $C_s$ use the same random field, hence the ratio $C_p/C_s$ is unaffected
%by the perturbation. The density is not perturbed.
%The perturbation amplitude is allowed to vary with the $z$-coordinate as
%$$
% A(z) = A_0 + g*z,
%$$
%where $A_0$ is specified by the {\tt amplitude} option, and $g$ is specified by the {\tt gradient} option.
%The random field, $\theta$ is generated by smoothing a completely uncorrelated field of uniformly 
%distributed pseudo-random numbers. 
%The pseudo-random number generator uses three seed variables. Varying the seeds will give a different perturbations, but
%the random perturbation is not affected by the number of processors.
%\begin{center}
%\begin{tabular}{|l|p{8cm}|l|l||l|} \hline
%\multicolumn{5}{|c|}{\bf Randomize command parameters}\\ \hline
%\bf{Option}  & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
%amplitude    & Amplitude of random perturbation ($A_0$) & real & None & 0.1 \\ \hline
%lengthscale  & Horizontal correlation length & real & m & 100 \\ \hline
%lengthscalez & Vertical correlation length & real & m & lengthscale \\ \hline
%sdthreshold  & Limits range of $\theta$ to $\pm\,$sdthreshold$\,\sigma$ & real & None & 3 \\ \hline
%seed1 & Random number generator seed & int & None & 1234 \\ \hline
%seed2 & Random number generator seed & int & None & 5678 \\ \hline
%seed3 & Random number generator seed & int & None & 9876 \\ \hline
%gradient & Amplitude gradient in the depth direction & real & 1/m & 0 \\ \hline
%\end{tabular}
%\end{center}
%\index{randomize parameters!lengthscale, lengthscalez, seed1, seed2, seed3, gradient}

\subsection{randomblock [optional]}
\index{command!randomblock}
\label{keyword:randomblock}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt randomblock corrlen=... corrlenz=... sigma=... hurst=... zmin=... zmax=... seed=...  \\
\bf Required parameters:\\
\rm None
\end{flushleft}
The {\tt randomblock} command adds a random perturbation to the material velocities $C_s$ and $C_p$. SW4 adds the random
perturbation after the specified material model has been read. The randomblock command will work together with any of
the material commands described in this section.
$C_p$ and $C_s$ use the same random field, hence the ratio $C_p/C_s$ is
unaffected by the perturbation. The density is not perturbed. \par
The random perturbation uses the von Karman self-similar correlation function, which has energy spectrum
proportional to
$$
  \frac{1}{(1+a^2k^2)^{H+3/2}}
$$
where $a^2k^2=a_h^2k_x^2+a_h^2k_y^2+a_v^2k_z^2$, and $H$ is the Hurst exponent. $a_h$ and $a_v$ are normalized
horizontal and vertical correlation lenghts, respectively.
The material velocities are updated by the random block according to
$$
 C_s := C_s*(1+\theta)\qquad  C_p := C_p*(1+\theta)
$$
where $\theta$ is a generated random number, scaled to have mean zero and standard deviation $\sigma$. \par
The the limits {\tt zmin} and {\tt zmax} allow specification of different correlation lenghts and/or Hurst exponents
at different depths, by using more than one {\tt randomblock} command. If no limits are given, the random perturbation 
will be applied over the entire computational domain. 

Unlike the old {\tt randomize} command, the random numbers are not globally defined, i.e., two runs using
different number of processors will use different sequences of random numbers, even if the random seeds
are the same in the two runs.

\begin{center}
\begin{tabular}{|l|p{8cm}|l|l||l|} \hline
\multicolumn{5}{|c|}{\bf Randomblock command parameters}\\ \hline
\bf{Option}  & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
corrlen  & Horizontal correlation length & real & m & 1000 \\ \hline
corrlenz & Vertical correlation length & real & m & corrlen \\ \hline
sigma  & standard deviation of perturbation, $\sigma$  & real & None & 0.1 \\ \hline
hurst & Hurst exponent in correlation fcn. & real & None & 0.3 \\ \hline
zmin & Minimum $z$-coordinate of random block & real & m & min $z$ of domain \\ \hline
zmax & Maximum $z$-coordinate of random block & real & m & max $z$ of domain \\ \hline
seed & Random number generator seed & int & None & read from {\tt /dev/urandom} \\ \hline
\end{tabular}
\end{center}
\index{randomblock parameters!corrlen, corrlenz, sigma, hurst, zmin, zmax, seed}


\subsection{anisotropy [optional]}
\index{command!anisotropy}
\label{sec:anisotropy}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt anisotropy\\
\bf Required parameters:\\
\rm None
\end{flushleft}
The {\bf anisotropy} command enables modeling of general anisotropic elastic materials described by
a 21 parameter stiffness matrix $C$. The $6\times 6$ stiffness matrix is symmetric and must be
positive definite. Currently, the anisotropic model can {\em not} be used together with attenuation.
Furthermore, the material model can only be specified with the \verb+ablock+ command, see
Section~\ref{keyword:ablock}. Material commands for the isotropic model will be ignored when
the {\bf anisotropy} command is used.

\subsection{ablock [optional]}
\index{command!ablock}
\label{keyword:ablock}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt ablock x1=... x2=... y1=... y2=... z1=... z2=... rho=... rhograd=...\\
c11=... c12=... c13=... c14=... c15=... c16=... \\ 
c22=... c23=... c24=... c25=... c26=... \\
c33=... c34=... c35=... c36=... \\
c44=... c45=... c46=... \\
c55=... c56=... \\
c66=... \\
cgrad11=... cgrad12=... cgrad13=... cgrad14=... cgrad15=... cgrad16=... \\ 
            cgrad22=... cgrad23=... cgrad24=... cgrad25=... cgrad26=... \\
                        cgrad33=... cgrad34=... cgrad35=... cgrad36=... \\
                                    cgrad44=... cgrad45=... cgrad46=... \\
                                                cgrad55=... cgrad56=... \\
                                                            cgrad66=... \\
\bf Required parameters:\\
\tt rho, \rm and a sufficient number of \tt cij \rm to make the $C$ matrix positive definite.
\end{flushleft}
The stiffness matrix defines the relation between stresses and strains using Voigt notation, see
for example Carcione~\cite{carcione-01} for details.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Topography command [optional]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{topography [optional]}
\index{command!topography}
\label{keyword:topo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf
Syntax:\\
\tt 
topography input=... file=... resolution=... zmax=... order=... smooth=... gaussianAmp=... gaussianXc=... gaussianYc=... gaussianLx=... gaussianLy=...\\
\bf 
Required parameters:\\
\tt 
input, zmax, file (except when input=gaussian)\\
\rm Also see discussion below.
\end{flushleft}
The topography command specifies the shape of the free surface boundary, and optionally allows the
polynomical order of the grid mapping to be adjusted. The topography is given as elevation (in
meters) relative to mean sea level, i.e., positive above sea level and negative below sea level. The
curvilinear grid is located between the topography and $z=z_{max}$ (recall that $z$ is directed
downwards). If the elevation '$e$' of the topography ranges between $e_{min}\leq e \leq e_{max}$, we
recommend using $z_{max} \geq -e_{min} + 2|e_{max} - e_{min}|$.

There are five ways of specifying the topography:
\begin{itemize}
\item {\bf input=geographic} Read the topography from a file, where the coordinates are given as as
  function of geographic coordinates (latitude and longitude). The file name must be specified by
  the {\bf file=...} keyword. The format for this file is described in Section~\ref{sec:topo-file-format}.
\item {\bf input=cartesian} Read the topography as function of Cartesian coordinates. The file name
   must be specified by the {\bf file=...} keyword. The format for this file is described in
   Section~\ref{sec:topo-file-format}.
\item {\bf input=rfile} Read the topography from a binary raster file. The name of the raster file
   must be specified by the {\bf file=...} keyword. The format of this file is described in
   Section~\ref{sec:rfile-format}.
% \item {\bf input=efile} Read the topography from the Etree database. The database file name
%    must be specified by the {\bf file=...} keyword. The spatial resolution for querying the Etree
%   database may be specified by the {\bf resolution=...} keyword.
\item {\bf input=gaussian} Build an analytical topography in the shape of a Gaussian hill. The
  amplitude is specified by {\bf gaussianAmp=...}, the hill is centered at {\bf gaussianXc=...},
  {\bf gaussianYc=...}, and the half width of the hill in the $x$ and $y$-directions are specified by 
   {\bf gaussianLx=...}, and {\bf gaussianLy=...}. Note that this topography is not smoothed, i.e.,
   the {\bf smooth} keyword is not used in this case.
\end{itemize}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf topography command parameters (basic)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default}\\ \hline \hline
%
input & Type of input: geographic (or grid), cartesian or gaussian & string & none & none\\ \hline
%
file & File name if input=geographic or input=cartesian & string & none & none\\ \hline
%
% etree & File name of detailed database if input=efile (same as file) & string & none & none\\ \hline
%
% xetree & File name of extended etree database if input=efile & string & none & none\\ \hline
%
% resolution & Resolution for querying the efile if input-efile & real & meters & none \\ \hline
%
zmax & z coordinate of the interface between  Cartesian and curvilinear grid& real &  m & 0\\ \hline
%
order & Interpolation order (2-6) & int & none & 4\\ \hline
%
smooth & Number of smoothing iterations of topography grid surface & int & none & 10 \\ \hline
\end{tabular}
\end{center}
\index{topography parameters!input, file, resolution, zmax, order, smooth}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf topography command parameters (Gaussian Hill)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default}\\ \hline \hline
%
gaussianAmp & Amplitude for a Gaussian hill topography & real & meters & 0.05\\ \hline	
gaussianXc & x-coordinate of center for a Gaussian Hill & real & meters & 0.5\\ \hline	
gaussianYc & y-coordinate of center for a Gaussian Hill & real & meters & 0.5 \\ \hline
gaussianLx & Width of the Gaussian hill in the x-direction & real & meters & 0.15 \\ \hline
gaussianLy & Width of the Gaussian hill in the y-direction & real & meters & 0.15 \\ \hline
\end{tabular}
\end{center}
\index{topography parameters!gaussianAmp, gaussianXc, gaussian Yc, gaussianLx, gaussianLy}

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{refinement [optional]}
\index{command!refinement}
\label{keyword:refinement}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 Each {\bf refinement} command corresponds to a mesh refinement patch for $z\leq{\bf zmax}$. The grid
 size in each refinement patch is half of the next coarser grid size. The grid size in the coarsest
 grid is prescribed by the {\bf grid} command.
 \begin{flushleft}\bf
 Syntax:\\
 \tt refinement zmax=...
 \\
 \bf Required parameters:\\
 \tt zmax
 \end{flushleft}
 %
 \begin{center}
 \begin{tabular}{|l|p{8cm}|l|l|l|} \hline
 \multicolumn{5}{|c|}{\bf refinement command parameters}\\ \hline
 \bf{Option} & \bf{Description} & \bf{Type} & \bf{Unit} & \bf{Default} \\ \hline \hline
 zmax & maximum z-coordinate for the refinement region & real & m & None\\ \hline
 \end{tabular}
 \end{center}
 \index{refinement parameters!zmax}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Output commands [optional]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The output commands enable results from the simulation to be saved on file. The {\bf rec} command
saves a time series of the solution at a recording station, which can be read by the SAC
program~\cite{Goldstein-et-al} or the readsac.m Matlab script in the {\tt tools} directory. The {\bf
  image} command is used to save a two-dimensional cross-section of the solution, the material
properties, or the grid. The image files can be read by the readimage.m Matlab script in the
{\tt tools} directory. The {\bf volimage} command is used to save three-dimensional volumetric data
of the solution, derived quantities of the solution, or the material model. These files are written
in a binary format. The readimage3d.m Matlab script in the {\tt tools} director can read the 
three-dimensional data into Matlab or Octave.
%These files can be read by the VisIt post processor, using the {\bf volimage} plug-in. 
The {\bf gmt} command outputs a shell script file containing the location of all {\bf rec}
stations and the epicenter, i.e., the location of the {\bf source} command with the earliest start
time. This shell script file can be used for further postprocessing by programs in the GMT
suite~\cite{WesselSmithGMT}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{rec (or sac) [optional]}
\index{command!rec}
\index{command!sac}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The \verb+rec+ command is used to save the time history of the solution at a fixed location in
space, see \S~\ref{sec:rec} for examples. For backwards compatibility with \emph{WPP}, this command
can also be called \verb+sac+. However, some options of the \verb+sac+ command in \emph{WPP} have
changed names and others are no longer supported.
\begin{flushleft}
\bf
Syntax:\\
\tt
rec x=... y=... z=... lat=... lon=... depth=... topodepth=... sta=... file=... writeEvery=... nsew=... usgsformat=... sacformat=... hdf5format=... variables=... hdf5file=... downsample=...
\\
\bf Required parameters:\\
\rm Location of the receiver in Cartesian or geographical coordinates.
\end{flushleft}
%
The file format is described in Section~\ref{sec:sac-format}.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf sac command parameters (part 1)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
x & x position of the receiver & real & m & 0.0 \\ \hline
y & y position of the receiver & real & m & 0.0 \\ \hline
z & z position of the receiver & real & m & 0.0 \\ \hline
\hline
lat & latitude geographical coordinate of the receiver & real & degrees & none \\ \hline
lon & longitude geographical coordinate of the receiver & real & degrees & none \\ \hline
depth & depth of the receiver (below topography) & real & m & none \\ \hline
topodepth & depth of the receiver (same as depth) & real & m & none \\ \hline
\end{tabular}
\end{center}
\index{rec parameters!location - x, y, z, lat, lon, depth, topodepth} 
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf sac command parameters (part 2)}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
file & file name  & string & none & station \\ \hline
sta & name of the station & string & none & (same as file) \\ \hline
hdf5file & file name  & string & none & station \\ \hline
writeEvery & cycle interval to write the file to disk & int & none & 1000 \\ \hline
%
usgsformat & output all components in an ASCII text file & int & none & 0 \\ \hline
sacformat & output each component in a SAC file & int & none & 1 \\ \hline 
hdf5format & output all components in an HDF5 file & int & none & 0 \\ \hline 
\hline
nsew & output (x,y,z)-components (0) or East, North, and vertical ($-z$) components (1)& int & none & 0 \\ \hline
variables & displacement, velocity, div, curl, strains, or displacementgradient & string & none & displacement \\ \hline
downsample & only available when hdf5format=1, outputs all components with the given downsample rate, resulting in less output data size & int & none & 1\\ \hline
\end{tabular}
\end{center}
Let ${\bf u}=(u^{(x)},\ u^{(y)},\ u^{(z)})$ denote the solution of (\ref{eq:elastic-we}) computed by SW4. 
The {\tt variables} output options have the following meaning. {\tt displacement} gives the three components of the computed solution, ${\bf u}$. {\tt velocity} gives the three components of the time derivative, ${\bf u}_t$. {\tt div} gives a single variable containing the divergence of ${\bf u}$. {\tt curl} gives the three components of the curl of ${\bf u}$. {\tt strains} give the six strain components in order: $u^{(x)}_x$,$u^{(y)}_y$,$u^{(z)}_z$,$(u^{(y)}_x+u^{(x)}_y)/2$, $(u^{(z)}_x+u^{(x)}_z)/2$, and
$(u^{(y)}_z+u^{(z)}_y)/2$. {\tt displacementgradient} gives the nine components: $u^{(x)}_x$, $u^{(x)}_y$, $u^{(x)}_z$,
$u^{(y)}_x$, $u^{(y)}_y$, $u^{(y)}_z$, $u^{(z)}_x$, $u^{(z)}_y$, and $u^{(z)}_z$. \par

The geographic coordinate option {\tt nsew=1} is only effective when {\tt variables} is
{\tt displacement}, {\tt velocity}, or {\tt div}.

\index{rec parameters!file, sta, writeEvery, usgsformat, sacformat, hdf5format, nsew, variables}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{rechdf5 (or sachdf5) [optional]}
\index{command!rechdf5}
\index{command!sachdf5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Similar to the \verb+rec+ command, the \verb+rechdf5+ command is used to save the time history of the solution at a fixed location in
space in the HDF5 format, see \S~\ref{sec:rec} for examples. The major difference is that all station's data is stored in a single
file instead of multiple ones in either SAC or USGS format.
\begin{flushleft}
\bf
Syntax:\\
\tt
rechdf5 infile=... outfile=... writeEvery=... downsample=... variables=...
\\
\bf Required parameters:\\
\rm Location of the receiver in Cartesian or geographical coordinates stored in HDF5 format.
\end{flushleft}
%
The HDF5 file format is described in Section~\ref{sec:sachdf5-format}.
%

\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf sachdf5 command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Units} & \bf{Default} \\ \hline \hline
infile & input file name  & string & none & station.h5 \\ \hline
outfile & input file name  & string & none & station\_out.h5 \\ \hline
writeEvery & cycle interval to write the file to disk & int & none & 1000 \\ \hline
%
\hline
variables & displacement, velocity, div, curl, strains, or displacementgradient & string & none & displacement \\ \hline
downsample & outputs all components with the given downsample rate, resulting in less output data size & int & none & 1\\ \hline
\end{tabular}
\end{center}

\index{rechdf5 parameters!writeEvery, infile, outfile, downsample, variables}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% images
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{image [optional]}
\index{command!image}
\label{keyword:image}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf Syntax:\\ \tt image x=... y=... z=...
time=... timeInterval=... cycle=... cycleInterval=... file=... mode=... precision=...\\ \bf Required
parameters:\\ \rm Location of the image plane (x, y, or z) \\ Time for output (time, timeInterval,
cycle, or cycleInterval)\\ \bf Notes: \\ \rm \verb+mode=topo+ can only be used when the
\verb+topography+ command is used.\\ \verb+z=0+ corresponds to the free surface when
\verb+topography+ is used. It is not possible to output a plane with $z=\mbox{const.}$ that cuts
through the curvilinear grid. When \verb+topography+ is used, any such $z$-plane will be output on
the free surface. \\ The error in the solution can only be calculated in testing mode, i.e., while
using \verb+twilight+, \verb+testlamb+, or \verb+testpointsource+.
\end{flushleft}
%
The image file format is described in Section~\ref{sec:image-format}.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf image command parameters (part 1)}\\ \hline
\bf{Option} & \bf{Description}                             & \bf{Type} & \bf{Units} & \bf{Default} \\ 
\hline \hline
x          & x location of image plane  $(\geq 0)$    & real    & m        & none \\ \hline
y          & y location of image plane  $(\geq 0)$    & real    & m        & none \\ \hline
z          & z location of image plane  $(\geq 0)$    & real    & m        & none \\ \hline
\end{tabular}
\end{center}
\index{image parameters!location - x, y, z}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf image command parameters (part 2)}\\ \hline
\bf{Option} & \bf{Description}                             & \bf{Type} & \bf{Units} & \bf{Default} \\ 
\hline \hline
time          & Time-level for outputting image (closest time step) $(\geq 0)$ & real  & s    & none \\ \hline
timeInterval  & Time-level interval for outputting a series of images $(> 0)$  & real  & s    & none \\ \hline
cycle         & Time-step cycle to output image $(\geq 0)$                     & int    & none & none \\ \hline
cycleInterval & Time-step cycle interval to output a series of images $(\geq 1)$ & int    & none & none \\ \hline\hline
file          & File name header of image                                   & string & none & image \\ \hline
precision     & Floating point precision for saving data (float or double)  & string & none & float \\ \hline
mode          & The field to be saved                                       & string & none & rho \\ \hline
\end{tabular}
\end{center}
\index{image parameters!timing - time, timeInterval, cycle, cycleInterval}
\index{image parameters!file, precision, mode}
%
{\bf mode} can take one of the following values:
%
\begin{center}
\begin{tabular}{|c|l|} \hline
\multicolumn{2}{|c|}{\bf mode options (grid, location \& topography)}\\ \hline
\bf{Value} & \bf{Description} \\ 
\hline  \hline
lat     & latitude (in degrees)  \\ \hline
lon     & longitude (in degrees) \\ \hline
topo    & elevation of topography [\emph{only available with topography}]\\ \hline
grid    & grid coordinates in the plane of visualization (\emph{e.g.} y-z plane if x=const) \\ \hline
gridx   & grid $x$-coordinates in the plane of visualization \\ \hline
gridy   & grid $y$-coordinates in the plane of visualization \\ \hline
gridz   & grid $z$-coordinates in the plane of visualization \\ \hline
\end{tabular}
\end{center}
\index{image parameters!modes - lat, lon, topo, grid, gridx, gridy, gridz}
\begin{center}
\begin{tabular}{|c|l|} \hline
\multicolumn{2}{|c|}{\bf mode options (material)}\\ \hline
\bf{Value} & \bf{Description} \\ 
\hline  \hline
rho     & Density \\ \hline
lambda  & 1st Lam\'e parameter \\ \hline
mu      & 2nd Lam\'e parameter (shear modulus) \\ \hline
p       & Compressional wave speed \\ \hline
s       & Shear wave speed \\ \hline
qp      & $Q_P$ quality factor \\ \hline
qs      & $Q_S$ quality factor \\ \hline
\end{tabular}
\end{center}
\index{image parameters!modes - rho, lambda, mu, p, s, qp, qs}
\begin{center}
\begin{tabular}{|c|l|} \hline
\multicolumn{2}{|c|}{\bf mode options (solution)}\\ \hline
\bf{Value} & \bf{Description} \\ 
\hline  \hline
ux      & displacement in the x-direction \\ \hline
uy      & displacement in the y-direction \\ \hline
uz      & displacement in the z-direction \\ \hline\hline
div     & divergence of $\ub$ (displacement) \\ \hline
curl    & magnitude of the rotation of $\ub$ \\ \hline 
mag     & magnitude of $\ub$ \\ \hline
hmag    & magnitude of $(u^{(x)}, u^{(y)})$ (horizontal components) \\ \hline
hmax & maximum in time of magnitude of $(u^{(x)}, u^{(y)})$ \\ \hline
vmax & maximum in time of $|u^{(z)}|$ (vertical component) \\ \hline\hline
%
divdudt (veldiv) & divergence of $\ub_t$ (velocity)\\ \hline
curldudt (velcurl) & magnitude of the rotation of $\ub_t$ \\ \hline
magdudt (velmag) & magnitude of the $\ub_t$ \\ \hline
hmagdudt (hvelmag)& magnitude of ($u^{(x)}_t, u^{(y)}_t)$ \\ \hline
hmaxdudt (hvelmax) & maximum in time of magnitude of $(u^{(x)}, u^{(y)})$ \\ \hline
vmaxdudt (vvelmax) & maximum in time of $|u^{(z)}_t|$    \\ \hline
\end{tabular}
\end{center}
\index{image parameters!modes - ux, uy, uz, div, curl, mag, hmag, hmax, vmax}
\index{image parameters!modes - divdudt, curldudt, magdudt, hmagdudt, hmaxdudt, vmaxdudt}
\begin{center}
\begin{tabular}{|c|l|} \hline
\multicolumn{2}{|c|}{\bf mode options (testing)}\\ \hline
\bf{Value} & \bf{Description} \\ 
\hline  \hline
uxexact & $x$-component of exact solution\\ \hline
uyexact & $y$-component of exact solution\\ \hline
uzexact & $z$-component of exact solution\\ \hline
uxerr   & $x$-component of error (difference between computed and exact solution)\\ \hline
uyerr   & $y$-component of error (difference between computed and exact solution)\\ \hline
uzerr   & $z$-component of error (difference between computed and exact solution)\\ \hline
\end{tabular}
\end{center}
\index{image parameters!modes - uxexact, uyexact, uzexact, uxerr, uyerr, uzerr} 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% image in HDF5 format
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{imagehdf5 [optional]}
\index{command!imagehdf5}
\label{keyword:imagehdf5}
\begin{flushleft}
\bf Syntax:\\ \tt imagehdf5 x=... y=... z=...
time=... timeInterval=... cycle=... cycleInterval=... file=... mode=... precision=...\\ \bf Required
parameters:\\ \rm Location of the image plane (x, y, or z) \\ Time for output (time, timeInterval,
cycle, or cycleInterval)\\ \bf Notes: \\ imagehdf5 is identical to the image command, while writing the image data in an HDF5 file. One can easily read and plot the data using python function provided in the jupyter notebook at \verb+tools/plotimageh5.ipynb+
\end{flushleft}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 3D images
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{volimage [optional]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{command!volimage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{keyword:volimage}
\begin{flushleft}
\bf Syntax:\\ \tt 
volimage file=... mode=... precision=... 
         time=... timeInterval=... cycle=... cycleInterval=... startTime=... \\
\bf Required parameter:\\
\rm Time for output: (time, timeInterval, cycle, or cycleInterval).
\end{flushleft}
%
The \verb+volimage+ command in \emph{SW4} allows you to save 3D volumetric data on file. These files
can be read by the Matlab/Octave script in \verb+tools/readimage3d.m+. You may also want to use the
open source post processor \emph{VisIt}, to read these files. Be aware that these files can be {\em
  very} large. The output occurs at certain time levels during the simulation. The time levels are
controlled by the parameters {\bf time=...}, {\bf timeInterval=...}, {\bf cycle=...}, or {\bf
  cycleInterval=...}, which have the same meaning as in the image command. In addition, the {\bf
  startTime=...} option can be used in conjunction with {\bf cycleInterval} or {\bf timeInterval} to
only output data after a specified time level in the simulation. The options {\bf file=...}, {\bf
  mode=...}, and {\bf precision=...} have the same meaning as the corresponding parameters in the
image command. The set of possible modes, which is different from the image command, is given in the
table below. The \verb+volimage+ command produces files with extension \verb+.3D.mode.sw4img+, where
\verb+mode+ is one of \verb+ux, uy, uz, rho, lambda, mu, p, s, qp, qs+.

When topography is present, i.e., the top grid is curvilinear, each file also includes the
$z$-coordinates of the curvilinear grid. Note that the grid coordinates are only saved when the
input file contains a \verb+topography+ command.

The file format is described in Section~\ref{sec:volimage-format}.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf volimage command options}\\ \hline
{\bf Option} & {\bf Description}          & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
file        & file name header of image                          & string & none & volimage \\ \hline
mode        & specifies which field is written to the image file & string & none & rho \\  \hline
precision   & precision of image data on file (float/double)     & string & none & float \\ \hline
%% \end{tabular}
%% \end{center}
%% %
%% \begin{center}
%% \begin{tabular}{|l|p{8cm}|l|l|l|} \hline
%% \multicolumn{5}{|c|}{\bf volimage command options (part 2)}\\ \hline
%% {\bf Option} & {\bf Description}          & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline \hline
time          & simulation time to output image, will be closest depending on dt taken & real  & sec.  & none \\ \hline
timeInterval  & simulation time interval to output series of images                    & real  & sec.  & none \\ \hline
cycle         & time-step cycle to output image                                        & int   & none  & none \\ \hline
cycleInterval & time-step cycle interval to output a series of images                  & int   & none & none \\ \hline
startTime     & only output data after this time level (only used with {\bf cycleInterval} or {\bf
 timeInterval}) & real & s & -999.9 \\ \hline 
\end{tabular}
\end{center}
\index{volimage parameters!file, mode, precision}
\index{volimage parameters!timing - cycle, cycleInterval, time, timeInterval, startTime}
%
The \verb+mode+ keyword can have the following values:
%
\begin{center}
\begin{tabular}{|c|l|} \hline
\multicolumn{2}{|c|}{\bf volimage mode sub-options}\\ \hline
\bf{Value} & \bf{Description} \\ \hline  \hline
ux      & $x$-components of the solution (displacement) \\ \hline
uy      & $y$-components of the solution (displacement) \\ \hline
uz      & $z$-components of the solution (displacement) \\ \hline
rho     & density of material \\ \hline
p       & $C_p$ material velocity \\ \hline
s       & $C_s$ material velocity \\ \hline
lambda  & First Lam\'e parameter \\ \hline
mu      & Second Lam\'e parameter \\ \hline
qp      & $Q_p$ material attenuation factor \\ \hline
qs      & $Q_s$ material attenuation factor \\ \hline
\end{tabular}
\end{center}
\index{volimage parameters!modes - ux, uy, uz, rho, p, s, lambda, mu, qp, qs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SSI 3D output
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{ssioutput [optional]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{command!ssioutput}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{keyword:ssioutput}
\begin{flushleft}
\bf Syntax:\\ \tt
ssioutput file=... dumpInterval=... bufferInterval=... xmin=... xmax=... ymin=... ymax=... depth=... compression\_option=...\\
\bf Required parameter:\\
file, xmin, xmax, ymin, ymax, depth.
\end{flushleft}
%
The \verb+ssioutput+ command in \emph{SW4} allows you to save 3D volumetric
  data in a file for ESSI.
These files are in an HDF5 format that can be post-processed for ESSI input directly.
SW4 must be compiled with the {\tt hdf5=yes} option to enable this option,
  and tests are available in the {\tt examples/essi} directory.

Be aware that these files can be {\em very} large, depending on the
  x,y,z ranges (which could include the whole domain).
The option {\bf file=...} has the
  same meaning as the corresponding parameters in the image command.
The \verb+ssioutput+ command produces files with extension \verb+.ssi+.
To reduce the output size, we have enabled the support to utilize ZFP \url{https://github.com/LLNL/zfp} and SZ \url{https://github.com/szcompressor/SZ} lossy compression. They can reduce the output size without significant precision loss. We found setting \verb+zfp-accuracy=0.01+ can reduce the output size by a factor of 40. Note ZFP and H5Z-ZFP must be installed and linked with SW4 to use this option, see the Installation Guide for detailed installation instructions.


The option {\bf dumpInterval=...} affects the maximum 
number of time steps in a file, it allows down-sampling the data to reduce the overall output size. If omitted, the data is written after every time step of the simulation.

Note that when the \verb+checkpoint+ command is being used, it is best to have {\bf cycleInterval} divisible by  {\bf dumpInterval}. This is to guarantee that both the checkpoint and SSI files are written after the same time step.

Note that only data from the topmost grid can be output, which may or may
  not include topography and in the case of mesh refinement, will not
  span the whole vertical domain.
The {\bf depth=...} option will use the horizontal grid spacing to estimate a 
  fixed number of grid points to output in the {\emph k-}direction.
When topography is present, i.e., the top grid is curvilinear, each file also 
  includes the $z$-coordinates of the requested points in the curvilinear grid.
Note that the grid coordinates are only saved when the
  input file contains a \verb+topography+ command.

To imporve the I/O performance, {\bf bufferInterval} should be set. We found setting it 400 to 800 are good in large scale simulations.



The file format is described in Section~\ref{sec:ssioutput-format}.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf ssioutput command options}\\ \hline
{\bf Option} & {\bf Description}          & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline
\hline
file        & file name header of image                          & string & none
  & ssioutput \\ \hline
  dumpInterval & interval between file writes & string &  none & -1 \\ \hline
xmin     & starting $x$ location of requested SSI region & real & m & 0 \\ \hline
xmax     & ending $x$ location of requested SSI region & real & m & $x_{max}$ \\ \hline
ymin     & starting $y$ location of requested SSI region & real & m & 0 \\ \hline
ymax     & ending $y$ location of requested SSI region & real & m & $y_{max}$ \\ \hline
depth     & approx depth of output over requested SSI region & real & m & 0 \\ \hline
zfp-accuracy & use ZFP lossy compression accuracy mode & float & none & N/A \\ \hline
zfp-precision & use ZFP lossy compression precision mode & float &none &  N/A \\ \hline
zfp-rate & use ZFP lossy compression rate mode & float &none &  N/A \\ \hline
zfp-reversible & use ZFP lossless compression mode & int & none &  0 \\ \hline

\end{tabular}
\end{center}
\index{ssioutput parameters!file}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{gmt [optional]}
\index{command!gmt}
\label{keyword:gmt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt gmt file=...\\
\bf Required parameters:\\
\rm None.
\end{flushleft}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf gmt command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
file & name of output file for gmt c-shell commands & string & sw4.gmt.csh  \\ \hline
\end{tabular}
\end{center}
\index{gmt parameters!file}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{sfileoutput}
\index{command!sfileoutput}
\label{keyword:sfileoutput}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{flushleft}
\bf Syntax:\\ \tt 
sfileoutput file=... sampleFactor=...  sampleFactorH=... sampleFactorV=...  \\
\bf Required parameter:\\
\rm File name prefix: (file).
\end{flushleft}
%
The \verb+sfileoutput+ command in \emph{SW4} allows you to save 3D volumetric material data on a HDF5 file (sfile). These files
can be read by the python/Jupyter script in \verb+tools/plot_sfile.ipynb+. 
Be aware that these files can be {\em very} large if \verb+sampleFactor+ is not set properly. 
The output is written out at the end of SW4 run. The {\bf sampleFactor=...} option sets the sub-sampling factor to the output, a \verb+sampleFactor=n+ will result in approximately $1/n^3$ of the file size from \verb+sampleFactor=1+. 
Users can also set different sample factor in horizontal (\verb+sampleFactorH+) and vertical directions (\verb+sampleFactorV+). As the material data is often very sensitive on the vertical direction, it is advisable to set \verb+sampleFactorV+ to 1 and \verb+sampleFactorH+ to 2 or a larger value.
The \verb+sfileoutput+ command produces files with extension \verb+.sfile+.

The file format is described in Section~\ref{sec:sfile-format}.
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|l|} \hline
\multicolumn{5}{|c|}{\bf sfileoutput command options}\\ \hline
{\bf Option} & {\bf Description}          & {\bf Type} & {\bf Units} & {\bf Default} \\ \hline 
\hline
file        & file name of sfile                          & string & none & "sfileoutput" \\ \hline
sampleFactor  & specifies the sub-sampling factor for both horizontal and vertical directions & int & none & 1 \\  \hline
sampleFactorH  & specifies the sub-sampling factor in the horizontal direction & int & none & 1 \\  \hline
sampleFactorV  & specifies the sub-sampling factor in the vertical direction & int & none & 1 \\  \hline

\end{tabular}
\end{center}
\index{sfileoutput parameters!file, sampleFactor, sampleFactorH, sampleFactorV}
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{checkpoint [optional]}
\index{command!checkpoint}
\label{keyword:checkpoint}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
\bf Syntax:\\ \tt
checkpoint cycleInterval=... file=... restartpath=... \\ zfp-{accuracy/precision/rate/reversible}=...\\
checkpoint cycleInterval=... file=... restartpath=... restartfile=... \\
zfp-{accuracy/precision/rate/reversible}=...\\
\bf Required parameter:\\
\rm Time for output: (time, timeInterval, cycle, or cycleInterval).\\
\bf Notes:\\
\rm \verb+restartpath+. argument sets the path for the checkpoint
  (write) and restart files
\end{flushleft}
%
The \verb+checkpoint+ command in \emph{SW4} allows you to save
and restore the simulation using restart files.
These files can be created using the input:
\begin{verbatim}
checkpoint cycleInterval=50 restartpath=loh1-results-restart file=LOH1_restart
\end{verbatim}
The command above will create a checkpoint file in \verb+restartpath+:
\begin{verbatim}
loh1-results-restart/LOH1_restart.cycle=050.sw4checkpoint
\end{verbatim}
  where the file name format is {\tt [path]/[prefix].cycle=[XXX].sw4checkpoint},
  and the format of the cycle number depends on the total number
  of time steps in the simulation.
The checkpoint functions keep only the last 2 checkpoint files, and deletes
  all prior files.
To assure continuity of the time series data for the \verb+rec+ command,
  \verb+checkpoint+ forces those files to be written whenever the checkpoint
  file is written.
These are written to the directory specified by the \verb+fileio+ \verb+path+
  variable.

The simulation can be restarted with the input line:
\begin{verbatim}
checkpoint cycleInterval=5 restartfile=LOH1_restart.cycle=050.sw4checkpoint
    restartpath=loh1-results-restart file=LOH1_restart
\end{verbatim}
On restart, the simulation will read in the state, and attempt to
  read in all the \verb+rec+ USGS and SAC files specified in the
  input from the \verb+fileio+ \verb+path+ directory.
It will abort if it cannot find the checkpoint or \verb+rec+ files to read
  from the restart path.
The \verb+rec+ USGS and SAC files are read in, and continued from the
  checkpoint cycle, and \emph{overwritten} in the output 
  directory \verb+fileio+ \verb+path+.
{\bf Note:} Because SAC files are float (4 byte) instead of double (8 byte),
  there may be differences in the last (7th or higher) digits after restart.

\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf restart parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
file & file header name to be prepended on restart files. & string & `` ''  \\ 
\hline
cycleInterval & sets the interval for writing out restart files & int & 0 \\ 
\hline
restartfile & restart the code from this file & string & ``restart''  \\ \hline
restartpath & path to restart file & string & N/A \\ \hline
hdf5 & use HDF5 output format & string & ``no'' \\ \hline
zfp-accuracy & use ZFP lossy compression accuracy mode & float & N/A \\ \hline
zfp-precision & use ZFP lossy compression precision mode & float & N/A \\ \hline
zfp-rate & use ZFP lossy compression rate mode & float & N/A \\ \hline
zfp-reversible & use ZFP lossless compression mode & int & 0 \\ \hline

\end{tabular}
\end{center}
\index{checkpoint parameters!file, cycleInterval, restartfile, restartpath}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SW4 testing commands [optional]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{twilight}
\index{command!twilight}
\label{keyword:twilight}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The {\bf twilight} command runs \emph{SW4} in a testing mode where forcing functions are constructed to
create a known smooth analytical solution, see Appendix~\ref{sec:twilight} for details. 
\begin{flushleft}
\bf
Syntax:\\
\tt
twilight errorlog=... omega=... c=... phase=... momega=... mphase=... amprho=... ampmu=... amplambda=...
\\
\bf Required parameters:\\
\rm
None
\end{flushleft}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf twilight command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
errorlog & Outputs error log in file twilight\_errors.dat & int & 0 \\ \hline
omega & Wave number in exact solution                           & real & 1.0 \\ \hline
c & Phase speed in exact solution                         & real & 1.3 \\ \hline
phase & Solution phase coefficient                        & real & 0.0 \\ \hline
momega & Wave number in material                          & real & 1.0 \\ \hline
mphase & Material phase coefficient                       & real & 0.4 \\ \hline
amprho & Density amplitude                                & real & 1.0 \\ \hline
ampmu & Material $\mu$ amplitude                          & real & 1.0 \\ \hline
amplambda & Material $\lambda$ amplitude                  & real & 1.0 \\ \hline
\end{tabular}
\end{center}
\index{twilight parameters!errorlog, omega, c, phase, momega, mphase, amprho, ampmu, amplambda}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{testlamb}
\index{command!testlamb}
\label{keyword:testlamb}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The {\bf testlamb} command solves Lamb's problem, i.e., the displacement due to a vertical point
forcing on a flat free surface, see Appendix~\ref{sec:testlamb} for details. 
\begin{flushleft}
\bf
Syntax:\\
\tt
testlamb x=... y=... cp=... rho=... fz=...
\\
\bf Required parameters:\\
\rm Location of the forcing $(x, y)$.
\end{flushleft}
%
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf testlamb command  parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
x    & x-coordinate of point source & real & 0.0 \\ \hline
y    & y-coordinate of point source & real & 0.0 \\ \hline
cp   & P-wave velocity              & real & 1.0 \\ \hline
rho  & Density                      & real & 1.0 \\ \hline
fz   & Magnitude of the forcing     & real & 1.0 \\ \hline
\end{tabular}
\end{center}
\index{testlamb parameters!x, y, cp, rho, fz}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{testpointsource}
\index{command!testpointsource}
\label{keyword:pointsource}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The {\bf testpointsource} command calculates the displacement due to a point source in a homogeneous
whole space, and computes the error. The source properties are specified by a regular \verb+source+
command. However, there must be exactly one \verb+source+ command and, the time function must be
one of the types \verb+VerySmoothBump+, \verb+C6SmoothBump+, \verb+SmoothWave+, or \verb+Gaussian+.

Before the solution has reached the a boundary or the super-grid layers, this test evaluates the
discretization of the source term. If supergrid layers are used on all six boundaries, this test can
also be used to evaluate the accuracy of the supergrid far field layers.

By setting \verb+diractest=1+, \emph{SW4} checks the moment conditions of the source
discretization. See the source code for further details.
\begin{flushleft}
\bf
Syntax:\\
\tt
testpointsource
cp=... cs=... rho=... diractest=...
\\
\bf 
Required parameters:\\
\rm
None
\end{flushleft}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf testpointsource command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
cp   & P-wave velocity & real & $\sqrt{3}$ \\ \hline
cs   & S-wave velocity & real & 1 \\ \hline
rho  & Density & real & 1 \\ \hline
diractest & Test moment conditions (0 or 1) & int & 0 \\ \hline
\end{tabular}
\end{center}
\index{testpointsource parameters! cp, cs, rho, diractest}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{testrayleigh}
\index{command!testrayleigh}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
The {\tt testrayleigh} command runs a surface wave through the domain with periodic boundary conditions
in the horizontal plane. The file \verb+RayleighErr.txt+ with information about the error in the computation
after each time step is produced. The file has four columns where the first column is the time, the 
second column is the maximum norm of the error, the third column is the $L^2$ norm of the error, and the 
fourth column is the maximum norm of the solution.
\\
\bf
Syntax:\\
\tt
testrayleigh cp=... cs=... rho=... nwl=...
\\
\bf 
Required parameters:\\
\rm
None
\end{flushleft}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf testrayleigh command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
cp   & P-wave velocity & real & $\sqrt{3}$ \\ \hline
cs   & S-wave velocity & real & 1 \\ \hline
rho  & Density & real & 1 \\ \hline
nwl  & number of wave lengths in domain & int & 1 \\ \hline
\end{tabular}
\end{center}
\index{testrayleigh parameters! cp, cs, rho, nwl}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{testenergy}
\index{command!testenergy}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}
The numerical scheme used by \emph{SW4} can be proven to be energy conserving, see \cite{SjoPet-12}.
The {\tt testenergy} command verifies the implementation of the scheme by checking the energy
conservation.  Testenergy sets the material speeds, $C_P,C_S$, and the density to be completely
random (but positive). The initial data is also set to a random field.  By default the boundary
conditions are periodic in the $x$- and $y$-directions, with free-surface conditions at $z=0$ and
homogeneous Dirichlet conditions at $z=z_{max}$. The boundary conditions can be changed by the
keyword described in Section~\ref{keyword:boundary_conditions}.  The file \verb+energy.log+ is
produced, containing the energy after each time step.  \\ \bf Syntax:\\ \tt testenergy
cpcsratio=... seed=... writeEvery=... filename=...  \\ \bf Required parameters:\\ \rm None
\end{flushleft}
\begin{center}
\begin{tabular}{|l|p{8cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf testenergy command parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
cpcsratio   & P-wave velocity to S-wave velocity ratio & real & $\sqrt{3}$ \\ \hline
seed   & Pseudo-random number generator seed & int & 2934839 \\ \hline
writeEvery  & frequency for saving log file to disk & int & 1000 \\ \hline
filename  & name of log file & string & energy.log \\ \hline
\end{tabular}
\end{center}
\index{testenergy parameters! cpcsratio seed writeEvery filename}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Advanced simulation controls [optional]}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

WARNING! The commands in this section are only intended for advanced users who are intimately
familiar with the inner workings of \emph{SW4}. These commands might lead to unexpected side
effects. Only the source code gives a complete description of what these commands really do.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{boundary\_conditions [optional]}
\index{command!boundary\_conditions}
\label{keyword:boundary_conditions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{flushleft}\bf
Syntax:\\
\tt
boundary\_conditions lx=... hx=... ly=... hy=... lz=... hz=...
\\
\bf Required parameters:\\
\rm
None
\end{flushleft}
Note that the boundary condition values are different in \emph{SW4} and \emph{WPP}.
The stress-free boundary condition can only be used on the upper ($z=0$) and 
lower ($z=z_{max}$) sides. 
\begin{center}
\begin{tabular}{|l|p{10cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf Boundary conditions parameters}\\ \hline
\bf{Option} & \bf{Description} & \bf{Value} & \bf{Default} \\ \hline \hline
lx & Boundary condition at $x=0$      & int 0-3 & 2 \\ \hline
hx & Boundary condition at $x=x_{max}$ & int 0-3 & 2 \\ \hline 
ly & Boundary condition at $y=0$      & int 0-3 & 2 \\ \hline
hy & Boundary condition at $y=y_{max}$ & int 0-3 & 2 \\ \hline 
lz & Boundary condition at $depth=0 $ & int 0-3 & 0 \\ \hline 
hz & Boundary condition at $z=z_{max}$ & int 0-3 & 2 \\ \hline
\end{tabular}
\end{center}
\index{boundary\_conditions parameters!lx, hx, ly, hy, lz, hz}

\begin{center}
\begin{tabular}{|l|p{10cm}|} \hline
\multicolumn{2}{|c|}{\bf boundary condition values }\\ \hline
\bf{Value} & \bf{Type} \\ \hline \hline
0 & Stress-free boundary   \\ \hline
1 & Dirichlet boundary  \\ \hline
2 & Supergrid boundary         \\ \hline
3 & Periodic boundary         \\ \hline
\end{tabular}
\end{center}
\index{boundary\_conditions values! stress-free, dirichlet, supergrid, periodic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{developer [optional]}
\index{command!developer}
\label{keyword:developer}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Warning: you need to be intimately familiar with the inner workings of \emph{SW4} to use this
command. Look in the source code to get a full understanding of what this command really does.

\begin{flushleft}\bf
Syntax:\\
\tt
developer
cfl=... checkfornan=... \\
\bf Required parameters:\\
\rm
None
\end{flushleft}
By setting the \verb+checkfornan+ keyword to \verb+on+ or \verb+yes+, \emph{SW4} scans the solution
arrays for floating point exceptions and other erros resulting in NaN (Not a Number). The check is
performed after each time step.
\begin{center}
\begin{tabular}{|l|p{10cm}|l|l|} \hline
\multicolumn{4}{|c|}{\bf developer parameters}\\ \hline
\bf{Option}   & \bf{Description} & \bf{Type} & \bf{Default} \\ \hline \hline
cfl   & CFL number $(>0)$ & real &  1.3\\ \hline
checkfornan & Scan solution arrays for NaN & string & off
\\ \hline
\end{tabular}
\end{center}
\index{developer parameters! cfl, checkfornan}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{File formats}\label{chap:formats}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\index{fileformats}


\section{Discrete time function}\label{sec:discrete-time-function-format}
\index{fileformats!discrete time function} 

The discrete time function interpolates values on a uniform grid in time, $\tau_j = t_0 +
(j-1)\delta_t$, $j=1,2,\ldots,N_d$. The file is formatted. The first line of the file contains the
reference time $(t_0)$, time step $(\delta_t)$, and number of data points $(N_d)$. The subsequent
$N_d$ lines in the file should contain the function values $g_j = g(\tau_j)$. The file should follow
the following format:
\begin{center}
\begin{tabular}{llll}\hline
Line & Column 1& Column 2& Column 3\\ \hline
1 & $t_0$ (real) & $\delta_t$ (real) & $N_d$ (integer) \\ \hline
2 & $g_1$ (real) & & \\ \hline
3 & $g_2$ (real) & & \\ \hline
\vdots & \vdots & & \\ \hline
$N_d + 1$ & $g_{N_d}$ (real) & & \\ \hline
\end{tabular}
\end{center}
The time step must be positive, $\delta_t>0$, and at least seven data points must be given, $N_d\geq
7$.

\section{Topography}\label{sec:topo-file-format}
\index{fileformats!topography}

Topography is specified as elevation above mean sea level on a regular lattice in the horizontal
plane. There are two variants of the topography format: geographic or Cartesian. By default,
topography is specified as function of geographic coordinates in the horizontal
plane. Alternatively, the lattice can be specified in Cartesian coordinates. In both cases, the unit
for elevation is meters and the topography file must cover the entire horizontal extent of the
computational domain.

\subsection{Topography on a geographic lattice}
Latitude and longitude should be given in degrees. Let the elevation be known at longitudes
\[
\phi_i,\quad i=1,2,\ldots,N_{lon},
\]
and latitudes
\[
\theta_j,\quad j=1,2,\ldots,N_{lat},
\]
Note that the latitudes and the longitudes must either be strictly increasing or strictly
decreasing, but the step size may vary.

The elevation should be given on the regular lattice
\[
e_{i,j} = \mbox{elevation at longitude $\phi_i$, latitude $\theta_j$.}
\]
Bi-cubic interpolation is used to define the elevation in between the lattice points.

The topography file should be an ASCII text file with the following format. The first line of the
file holds the number of longitude and latitude data points:
\[
N_{lon}\quad N_{lat}
\]
On subsequent lines, longitude, latitude and elevation values are given in column first ordering:
\[
\begin{array}{c c c}
\phi_1 & \theta_1& e_{1,1}\\
\phi_2& \theta_1& e_{2,1}\\
\vdots&\vdots&\vdots\\
\phi_{Nlon}& \theta_1& e_{Nlon,1}\\
\vdots&\vdots&\vdots\\
\phi_1 & \theta_{Nlat}& e_{1,Nlat}\\
\phi_2& \theta_{Nlat}& e_{2,Nlat}\\
\vdots&\vdots&\vdots\\
\phi_{Nlon}& \theta_{Nlat}& e_{Nlon,Nlat}
\end{array}
\]

\subsection{Topography on a Cartesian lattice}
Cartesian coordinates should be given in meters ([{\tt m}]). Let the elevation be known at $x$-coordinates
\[
x_i,\quad i=1,2,\ldots,Nx,
\]
and $y$-coordinates
\[
y_j,\quad j=1,2,\ldots,Ny,
\]
Note that the coordinate vectors must either be strictly increasing or strictly
decreasing, but the step size may vary. Also note that the step size can be different from the step
size in the computational grid. To guarantee that the topography grid covers the entire horizontal
extent of the computational domain, we require
\[
\min_i x_i \leq 0,\quad \min_j y_j \leq 0,\\
\max_i x_i \geq x_{max},\quad \max_j y_j \geq y_{max},
\] 
where $x_{max}$ and $y_{max}$ are defined by Equation~\eqref{eq:domain}. Bi-cubic interpolation is
used to define the elevation in between the lattice points.

The elevation should be given on the regular lattice
\[
e_{i,j} = \mbox{elevation at Cartesian coordinate $(x,y)=(x_i, y_j)$.}
\]
The topography file should be an ASCII text file with the following format. The first line of the
file holds the number of data points in each direction:
\[
Nx\quad Ny
\]
On subsequent lines, $x$, $y$ and elevation values are given in column first ordering:
\[
\begin{array}{c c c}
x_1 & y_1& e_{1,1}\\
x_2& y_1& e_{2,1}\\
\vdots&\vdots&\vdots\\
x_{Nx}& y_1& e_{Nx,1}\\
\vdots&\vdots&\vdots\\
x_1 & y_{Ny}& e_{1,Ny}\\
x_2& y_{Ny}& e_{2,Ny}\\
\vdots&\vdots&\vdots\\
x_{Nx}& y_{Ny}& e_{Nx,Ny}
\end{array}
\]

\section{pfile}\label{sec:pfile-format}
\index{fileformats!pfile} 

There are two variants of the pfile format: geographic or Cartesian. By default, geographic
coordinates are used to specify the location of the depth profiles in the horizontal
plane. Alternatively, the lattice can be specified in Cartesian coordinates. Note that different
units are used in the two cases. Pfiles are ASCII text formated.

\subsection{pfile on a geographic lattice}
The header has 7 lines and follows the following format:
\begin{center}
\begin{tabular}{lllll}\hline
Line & Column 1& Column 2& Column 3& Column 4\\ \hline
1 & Name (string) & & & \\ \hline
2 & $\Delta$ [deg] (real) & & & \\ \hline
3 & $N_{lat}$ (integer) & $Lat_{min}$ [deg] (real) & $Lat_{max}$ [deg] (real) & \\ \hline
4 & $N_{lon}$ (integer) & $Lon_{min}$ [deg] (real) & $Lon_{max}$ [deg] (real) & \\ \hline
5 & $N_{dep}$ (integer) & $d_{min}$ [km] (real) & $d_{max}$ [km] (real) & \\ \hline
6 & $I_{sed}$ (integer) & $I_{MoHo}$ (integer) & $I_{410}$ (integer) & $I_{660}$ (integer) \\ \hline
7 & $Q$-available? (logical) \\ \hline
\end{tabular}
\end{center}
The first line holds the optional name of the material model. Line 2 contains the parameter
$\Delta$, which is used to average the material properties according to equation \eqref{eq:gaussian-average}.
Lines 3 and 4 contain the number of lattice points as well as the starting and ending angles in the
latitude and longitude direction, respectively. Line 5 contains the number of depth values in each
profile, followed by the minimum and maximum depth measured in km. Line 6 supplies optional
information about the index of some material discontinuities in each depth profile. Give -99 if not
known. Note that the index for each discontinuity (sediment, MoHo, 410, 660) indicates the row
number within each profile, for the material property just above the discontinuity. Hence, the
subsequent entry in each profile should have the same depth value and contain the material property
just below the same discontinuity. Line 7 should contain the single letter 'T' or 't' if the
subsequent data contains quality factors ($Q_P$ and $Q_S$); otherwise it should contain the single
letter 'F' or 'f'. The presence of quality factors may alternatively be indicated by using the
strings '.TRUE.', '.true.', '.FALSE.', or '.false.'. 

The first seven lines of a pfile can look like this:
\begin{verbatim}
Caucasus
0.25
7 38.00 39.50
19 44.50 49.00
30 0.00 161.00
-99 -99 -99 -99
.TRUE.
\end{verbatim}

The header is directly followed by $N_{lat}\times N_{lon}$ depth profiles, ordered such that the longitude
varies the fastest, that is, according to the pseudo-code:
\begin{flushleft}
\hspace{10mm}  for ($Lat_i= Lat_{min}$; $Lat_i <= Lat_{max}$; $Lat_i += \Delta_{lat}$)\\
\hspace{20mm}    for ($Lon_j= Lon_{min}$; $Lon_j <= Lon_{max}$; $Lon_j += \Delta_{lon}$)\\
\hspace{30mm}      (save depth profile for $Lat_i$, $Lon_j$)\\
\hspace{20mm}    end\\
\hspace{10mm}  end
\end{flushleft}
Here, $\Delta_{lat} = (Lat_{max} - Lat_{min})/(N_{lat}-1)$ and  $\Delta_{lon} = (Lon_{max} -
Lon_{min})/(N_{lon}-1)$. In general, $\Delta_{lat}\ne \Delta_{lon}\ne\Delta$.

The first line of each depth profile holds the latitude and longitude (in degrees as real
numbers), and the number of depth values, which must equal $N_{dep}$. For example a depth profile
for latitude 33.108, longitude -115.66, with $N_{dep}=19$ points in the depth direction starts with the line
\begin{verbatim}
33.108  -115.66  19
\end{verbatim}
The subsequent $N_{dep}$ lines have the following format:
\begin{center}
\begin{tabular}{lllllll}\hline
Index (int)& depth [km] & $C_p$ [km/s] &  $C_s$ [km/s] & $\rho$ [g/cm$^3$] & $Q_P$ & $Q_S$ \\ \hline
\end{tabular}
\end{center}
Note that $Q_P$ and $Q_S$ should only be present when indicated so by the $Q$-availability flag on
line 7 of the header. Also note that the units are different than in other parts of \emph{SW4}. In
particular, $C_P$ and $C_S$ should be given in km/s$=$ 1000 m/s, and density ($\rho$) should be
given in g/cm$^3=$ 1000 kg/m$^3$.

\subsection{pfile on a Cartesian lattice}
The header of the Cartesian grid pfile format consists of seven lines with the following information:
\begin{center}
\begin{tabular}{lllll}\hline
Line & Column 1& Column 2& Column 3& Column 4\\ \hline
1 & Name (string) & & & \\ \hline
2 & $h$ [m] (real) & & & \\ \hline
3 & $N_{x}$ (integer) & $x_{min}$ [m] (real) & $x_{max}$ [m] (real) & \\ \hline
4 & $N_{y}$ (integer) & $y_{min}$ [m] (real) & $y_{max}$ [m] (real) & \\ \hline
5 & $N_{dep}$ (integer) & $d_{min}$ [m] (real) & $d_{max}$ [m] (real) & \\ \hline
6 & $I_{sed}$ (integer) & $I_{MoHo}$ (integer) & $I_{410}$ (integer) & $I_{660}$ (integer) \\ \hline
7 & $Q$-available? (logical) \\ \hline
\end{tabular}
\end{center}
This is essentially the same header as for the geographic coordinate format, with the only
difference that information on lines 2, 3, and 4 is different. The spacing, $h$, of the grid of
depth profiles is given on line 2.  The number of depth profiles in the $x$-direction $N_x$ with
minimum and maximum coordinate values are given on line 3. The same quantities for the $y$-direction
are given on line 4. Note that all distances, including the depth information on line 5, must be
given in meters ({\tt [m]}).

The header is directly followed by $N_{x}\times N_{y}$ depth profiles, ordered such that the $x$-coordinate
varies the fastest, that is, according to the pseudo-code:
\begin{flushleft}
\hspace{10mm}  for ($y= y_{min}$; $y <= y_{max}$; $y += h$)\\
\hspace{20mm}    for ($x= x_{min}$; $x <= x_{max}$; $x += h$)\\
\hspace{30mm}      (save depth profile for $x$, $y$)\\
\hspace{20mm}    end\\
\hspace{10mm}  end
\end{flushleft}
The first line of each depth profile holds the $x$-coordinate and the $y$-coordinate (in meters as real
numbers), and the number of depth values, which must equal $N_{dep}$. For example a depth profile
for $x=100.4\,m$ and $y=30.6\,m$, with $N_{dep}=19$ points in the depth direction starts with the line
\begin{verbatim}
100.4  30.6  19
\end{verbatim}
The subsequent $N_{dep}$ lines have the following format:
\begin{center}
\begin{tabular}{lllllll}\hline
Index (int)& depth [m] & $C_p$ [m/s] &  $C_s$ [m/s] & $\rho$ [kg/m$^3$] & $Q_P$ & $Q_S$ \\ \hline
\end{tabular}
\end{center}
$Q_P$ and $Q_S$ can be left out when indicated not present by the $Q$-availability flag on line 7 of
the header.  Note that, unlike the pfiles on a geographic lattice, the units should here be
the standard MKS units, which normally are used in \emph{SW4}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{ifile}\label{sec:ifile-format}
\index{fileformats!ifile}

The material surface file (ifile) should be an ASCII text file with the following format. We start
by assuming the material surfaces are given as function of geographic coordinates
(\verb+input=geographic+). Modifications for the Cartesian case are described at the end of this
section.

The first line of the file holds the number of longitude and latitude data points, as well as the number
of material surfaces:
\[
N_{lon}\quad N_{lat}\quad N_{mat}
\]
On subsequent lines, longitude, latitude and $N_{mat}$ surface depth values are given in column
first ordering:
\[
\begin{array}{c c c c c}
Lon_1 & Lat_1          & d_{1,1,1} & \ldots & d_{N_{mat},1,1}\\
Lon_2& Lat_1           & d_{1,2,1} & \ldots & d_{N_{mat},2,1}\\
\vdots&\vdots&\vdots & & \vdots\\
Lon_{N_{lon}}& Lat_1      & d_{1,N_{lon},1} & \ldots & d_{N_{mat},N_{lon},1}\\
\vdots&\vdots&\vdots\\
Lon_1 & Lat_{N_{lat}}     & d_{1,1,N_{lat}} & \ldots & d_{N_{mat},1,N_{lat}}\\
Lon_2& Lat_{N_{lat}}      & d_{1,2,N_{lat}} & \ldots & d_{N_{mat},2,N_{lat}}\\
\vdots&\vdots&\vdots & & \vdots\\
Lon_{N_{lon}}& Lat_{N_{lat}} & d_{1,N_{lon},N_{lat}} & \ldots & d_{N_{mat},N_{lon},N_{lat}}
\end{array}
\]
It is required that $0\leq d_{q,i,j} \leq d_{q+1,i,j}$.

\subsection{Cartesian ifile}

When the material surfaces are given as function of Cartesian coordinates (\verb+input=cartesian+),
the first line of the file holds the number of data points in the ``x'' and ``y'' directions, as
well as the number of material surfaces:
\[
N_{x}\quad N_{y}\quad N_{mat}
\]
The subsequent lines have essentially the same format as in the geographic case. In the above
description, simply substitute ``longitude'' by ``x'' and ``latitude'' by ``y''.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{rfile}\label{sec:rfile-format}
\index{fileformats!rfile}

The {\tt rfile} starts with a header followed by a data section. The header has two parts. The first
part contains 5 integers (4 bytes each), 3 doubles (8 bytes each) and a character array with a
variable number of elements (1 byte each):
\begin{center}
\begin{tabular}{llll}\hline
Offset (bytes) & Name & Type & Bytes \\ \hline
0 & magic  & int & 4 \\ \hline
4 & prec   & int & 4 \\ \hline
8 & att    & int & 4 \\ \hline
12 & az     & double & 8 \\ \hline
20 & lon0   & double & 8 \\ \hline
28 & lat0   & double & 8 \\ \hline
36 & mlen   & int & 4 \\ \hline
40 & mercstr & char & mlen \\ \hline
40+mlen & $N_b$  & int & 4 \\ \hline
\end{tabular}
\end{center}
Here, {\tt magic}$=1$ is used to determine the byte ordering on the file, i.e., if it was written by
a machine using big- or little-endianess. {\tt prec} is the number of bytes per entry in the data
section, i.e., 4 for single precision and 8 for double precision. The flag {\tt att} can currently
be 0 or 1, and indicates whether the visco-elastic attenuation parameters $Q_P$ and $Q_S$ are
included in the data section. The grid azimuth {\tt az} gives the angle [deg] between North and the
positive $x$-axis. The geographical coordinates of the origin of the data in the horizontal plane is
({\tt lon0}, {\tt lat0}). The number of characters in the string {\tt mercstr} is {\tt mlen}, and
the number of blocks (patches) in the data section is given by $N_b$.

The second part of the header contains 40 bytes of grid size information for each of the $N_b$ grid
patches. The information is saved in the following format:
\begin{center}
\hspace{-35mm}{\tt for ($b=1$; $b\leq N_b$; $b$++) }\nopagebreak \\ 
\vspace{2mm}
\begin{tabular}{llll}\hline
Offset (bytes) & Name & Type & Bytes \\ \hline
$o_0 + 40(b - 1)$ & $hh_{b}$ & double & 8 \\ \hline
$o_0 + 8 + 40(b - 1)$ & $hv_{b}$ & double & 8 \\ \hline
$o_0 + 16 + 40(b - 1)$ & $z0_{b}$ & double & 8 \\ \hline
$o_0 + 24 + 40(b - 1)$ & $nc_{b}$ & int & 4 \\ \hline
$o_0 + 28 + 40(b - 1)$ & $ni_{b}$ & int & 4 \\ \hline
$o_0 + 32 + 40(b - 1)$ & $nj_{b}$ & int & 4 \\ \hline
$o_0 + 36 + 40(b - 1)$ & $nk_{b}$ & int & 4 \\ \hline
\end{tabular}\\
\end{center} 
Here, $o_0=44+${\tt mlen}, is the size (in bytes) of the first header section. $hh_b$ and $hv_b$ are
the grid sizes in the horizontal and vertical directions, respectively. $z0_b$ is the base $z$-level
for block $b$. The number of components in block $b$ is $nc_b$. Block number $b$ has $ni_b\times
nj_b\times nk_b$ grid points in the $(i,j,k)$ directions, respectively. Note that the first block is
assumed to hold the elevation of the topography/bathymetry, so $z0_1$ is not used. 

The Cartesian coordinates $(x_i, y_j, z_k)$ of grid point $(i,j,k)$ in patch $b$ satisfy
\[
x_i = hh_b(i-1),\quad y_j = hh_b(j-1),\quad z_k = z0_b + (k-1)hv_b.
\]
It it important to notice that the vertical coordinate $z_k$ is interpreted as the depth below {\em
  mean sea level}, i.e., it has the same meaning as the vertical coordinate of the computational
mesh. This means that some grid points in an {\tt rfile} will be located above the topography/bathymetry.

The data section holds the content of the four-dimensional arrays $a_b(nc_b,ni_b,nj_b,nk_b)$ for
each grid patch $1\leq b\leq N_b$. Depending on the value of {\tt prec}, each element is saved as a 4 byte
float, or an 8 byte double. To enable better parallel reading performance, the grid points are
traversed in ``C''-order. The data blocks can be read by the pseudo-C code
\begin{center}
\hspace{-35mm}{\tt for ($b=1$; $b\leq N_b$; $b$++) }\\ 
\hspace{-30mm}{\tt for ($i=1$; $i\leq ni_b$; $i$++) }\\ 
\hspace{-25mm}{\tt for ($j=1$; $j\leq nj_b$; $j$++) }\\ 
\hspace{-20mm}{\tt for ($k=1$; $k\leq nk_b$; $k$++) }\\ 
\hspace{-15mm}{\tt for ($c=1$; $c\leq nc_b$; $c$++) }\\
\hspace{-10mm}{\tt read $a_b(c,i,j,k)$}\\
\end{center}
The elevation of the topography/bathymetry is always stored in the first block. Note that it is
defined to be positive above mean sea level. For $b\geq 2$, the material properties are stored in
the following order,
\[
a_b(c,i,j,k) = \begin{cases}
\rho,&c=1,\\
V_P,& c=2,\\
V_S,& c=3,\\
Q_P,& c=4 \mbox{ (if {\tt att}$=1$)},\\
Q_S,& c=5 \mbox{ (if {\tt att}$=1$)},\\
\end{cases}\quad b\geq 2.
\]
If a grid point is above the topography (i.e., in the air), you should set $\rho=V_p=V_s=-999$, and
$Q_P=Q_S=-999$ (if {\tt att}$=1$). If a grid point is above the bathymetry (i.e. in water), you
should set $V_S=-999$, but give physical values to $V_P$ and $\rho$. Note that wave propagation in
water is currently not modeled by \emph{SW4} so those values are not currently used. However,
setting correct density and compressional wave speeds in water will allow the same material model to be
used when such modeling becomes available. It is also consistent with how water is handled in
USGS's model of the San Francisco bay area.

A Matlab/octave reader of material models in the {\tt rfile} format, called {\tt readmat.m}, is
provided in the {\tt tools} directory. A sample {\tt rfile} model is included in the {\tt
  examples/rfile} directory.

\paragraph{Restrictions and assumptions.}
\begin{itemize}
\item The azimuth in the {\tt rfile} must agree with the azimuth given in the {\tt grid} command.
\item The origin of the {\tt rfile} does {\em not} have to agree with the origin of the
  computational grid. In fact, the setup of a simulation is less prone to errors if the {\tt rfile}
  domain is at least a few percent larger than the extent of the computational domain.)

\item The first block holds the elevation of the topography/bathymetry, so $nc_1=1$. The following blocks
must have either 3 or 5 components, i.e.,
\[
nc_b=\begin{cases}
1,& b=1,\\
3,& \mbox{{\tt att}$=0$ and $b\geq 2$},\\
5,& \mbox{{\tt att}$=1$ and $b\geq 2$}.
\end{cases}
\]

\item Because the topography/bathymetry is a function of the horizontal coordinates, the first block must have
$nk_1=1$.

\item All patches must have the same horizontal extent, i.e.,
\[
(ni_b -1)hh_b = \mbox{const.},\quad (nj_b - 1)hh_b = \mbox{const.},\quad b\geq 1,
\]
and the $z$-coordinate of the last grid point in one block must match the first one of the next
block,
\[
z0_b+(nk_b-1)hv_b = z0_{b+1},\quad b=2,3,\ldots,N_b-1.
\]
However, neither $z0_1$ nor $hv_1$ are used when parsing the {\tt rfile}. 

\item It is assumed that the horizontal grid size for the topography/bathymetry is the same as the
  first material block,
\[
hh_1 = hh_2,\quad ni_1=ni_2,\quad nj_1=nj_2.
\]
\end{itemize}

\section{sfile}\label{sec:sfile-format}
\index{fileformats!sfile}

The \verb+sfile+ command provides material data and topography, 
  similar  to the \verb+rfile+, but with materials defined on
  a curvilinear mesh with refinement boundaries.
Each grid of material data has corresponding top and bottom interfaces
  that defines the vertical distribution of grids points, which is constant
  grid spacing across {\em nz} total points (including end points).
This layout, along with the coarsest horizontal grid spacing, {\em hh}, defines
  the ({\em x,y,z}) point location relative to the origin ({\em lon,lat,azim})
  for every point.

The \verb+sfile+ files are self-describing in HDF5 format, with
  the following fields:
\begin{center}
\begin{tabular}{lll}\hline
Name & Type & Size \\ \hline
  ``Origin longitude, latitude, azimuth'' & H5T\_IEEE\_F64LE & 3 \\ \hline
  ``Coarsest horizontal grid spacing'' & H5T\_IEEE\_F64LE & 1 \\ \hline
  ``Attenuation'' & H5T\_STD\_I32LE & 1 \\ \hline
  ``ngrids'' & H5T\_STD\_I32LE & 1 \\ \hline
  ``Min, max depth'' & H5T\_IEEE\_F64LE & 2 \\ \hline
%  ``grid nz'' & H5T\_STD\_I32LE & ngrids, \{$0,...,ng-1$\} \\ \hline
Group /Z\_interfaces \\ \hline
  ``z\_interface\_\{0...ngrids\}'' & H5T\_IEEE\_F32LE & {\em (nx,ny)[ng]}  \\ \hline
Group /Material\_model \\ \hline
  ``grid\_\{0...ngrids-1\}/\{mat\}'' & H5T\_IEEE\_F32LE & {\em (nx,ny,nz)[ng]} \\ \hline
\end{tabular}
\end{center}

The output of {\tt h5dump -A} header and metadata is below (lightly edited):

\begin{verbatim}
HDF5 "berkeley.sfile" {
GROUP "/" {
   ATTRIBUTE "Attenuation" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SCALAR
      DATA {
      (0): 1
      }
   }
   ATTRIBUTE "Coarsest horizontal grid spacing" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SCALAR
      DATA {
      (0): 100
      }
   }
   ATTRIBUTE "Min, max depth" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }
      DATA {
      (0): -557.6, 6387.5
      }
   }
   ATTRIBUTE "Origin longitude, latitude, azimuth" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SIMPLE { ( 3 ) / ( 3 ) }
      DATA {
      (0): -122.25, 37.93, 143.638
      }
   }
   ATTRIBUTE "ngrids" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SCALAR
      DATA {
      (0): 3
      }
   }
   GROUP "Material_model" {
      GROUP "grid_0" { ... }
      GROUP "grid_1" { ... }
      GROUP "grid_2" {
         ATTRIBUTE "Horizontal grid size" {
            DATATYPE  H5T_IEEE_F64LE
            DATASPACE  SCALAR
            DATA {
            (0): 400
            }
         }
         ATTRIBUTE "Number of components" {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
            DATA {
            (0): 5
            }
         }
         DATASET "Cp" {
            DATATYPE  H5T_IEEE_F32LE
            DATASPACE  SIMPLE { ( 31, 31, 34 ) / ( 31, 31, 34 ) }
         }
         DATASET "Cs" { ... }
         DATASET "Qp" { ... }
         DATASET "Qs" { ... }
         DATASET "Rho" { ... }
      }
   }
   GROUP "Z_interfaces" {
      DATASET "z_values_0" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 121, 121 ) / ( 121, 121 ) }
      }
      DATASET "z_values_1" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 121, 121 ) / ( 121, 121 ) }
      }
      DATASET "z_values_2" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 61, 61 ) / ( 61, 61 ) }
      }
      DATASET "z_values_3" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 31, 31 ) / ( 31, 31 ) }
      }
   }
}
}
\end{verbatim}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SRF-HDF5}\label{sec:rupturehdf5-format}
\index{fileformats!rupturehdf5}
Based on the SRF (Standard Rupture Format), we have created the SRF-HDF5 format, which stores
the same amount of information in a more compact HDF5 file that is smaller in size and can be read faster.

To convert an existing SRF file into HDF5 format, we have provided a python script under {\tt tools/srf2hdf5.py} in the sw4 repository. 
The script requires two command line parameters to specify the input SRF file and the output SRF-HDF5 file, e.g. {\tt python srf2hdf5.py rupture.srf rupture.h5}.

The output of {\tt h5dump -A} header and metadata is below, the ``PLANE'' and ``VERSION'' attributes 
store the header block of the SRF file, with the number of plane segments implicitly implied in the 
dataspace of the ``PLANE'' attribute.

The ``POINTS'' and ``SR1'' datasets store the data block of the SRF file. Different from the SRF format,
where the slip rate at each time step for a direction follows immediately after each point source, 
we concatenate all slip rates and put them in a single 1D dataset, which is optimized for data read.
To access the slip rates of a particular point source, one needs to accumulate the number of rates
before the desired one and calculate its offset in the ``SR1'' dataset. 

Only ``SR1'' is converted in the SRF-HDF5 format as others (SR2 and SR3) are ignored by sw4.

\begin{verbatim}
HDF5 "m6.5-20.0x13.0.s500.v5.1.srf.h5" {
GROUP "/" {
   ATTRIBUTE "PLANE" {
      DATATYPE  H5T_COMPOUND {
         H5T_IEEE_F32LE "ELON";
         H5T_IEEE_F32LE "ELAT";
         H5T_STD_I32LE "NSTK";
         H5T_STD_I32LE "NDIP";
         H5T_IEEE_F32LE "LEN";
         H5T_IEEE_F32LE "WID";
         H5T_IEEE_F32LE "STK";
         H5T_IEEE_F32LE "DIP";
         H5T_IEEE_F32LE "DTOP";
         H5T_IEEE_F32LE "SHYP";
         H5T_IEEE_F32LE "DHYP";
      }
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      DATA {
      (0): {
            -122.218,
            37.8433,
            100,
            65,
            20,
            13,
            144,
            90,
            3,
            -5,
            8
         }
      }
   }
   ATTRIBUTE "VERSION" {
      DATATYPE  H5T_IEEE_F32LE
      DATASPACE  SCALAR
      DATA {
      (0): 2
      }
   }
   DATASET "POINTS" {
      DATATYPE  H5T_COMPOUND {
         H5T_IEEE_F32LE "LON";
         H5T_IEEE_F32LE "LAT";
         H5T_IEEE_F32LE "DEP";
         H5T_IEEE_F32LE "STK";
         H5T_IEEE_F32LE "DIP";
         H5T_IEEE_F32LE "AREA";
         H5T_IEEE_F32LE "TINIT";
         H5T_IEEE_F32LE "DT";
         H5T_IEEE_F32LE "VS";
         H5T_IEEE_F32LE "DEN";
         H5T_IEEE_F32LE "RAKE";
         H5T_IEEE_F32LE "SLIP1";
         H5T_STD_I32LE "NT1";
         H5T_IEEE_F32LE "SLIP2";
         H5T_STD_I32LE "NT2";
         H5T_IEEE_F32LE "SLIP3";
         H5T_STD_I32LE "NT3";
      }
      DATASPACE  SIMPLE { ( 6500 ) / ( 6500 ) }
   }
   DATASET "SR1" {
      DATATYPE  H5T_IEEE_F32LE
      DATASPACE  SIMPLE { ( 144616 ) / ( 144616 ) }
   }
}
}

\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sac}\label{sec:sac-format}
\index{fileformats!sac}

SAC files hold the time history of one component of the solution at a fixed point in space.  A
detailed description of the SAC format can be found at {\tt
http://www.iris.edu/manuals/sac/manual.html}, and we refer to that web page for a detailed
description of the file format.

We provide a simplified Matlab/octave reader of SAC files called {\tt readsac.m} in the {\tt tools}
directory. Note that only a subset of the header information is parsed by this reader.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{sachdf5}\label{sec:sachdf5-format}
\index{fileformats!sachdf5}

The HDF5 format holds the time history of all components of the solution at a fixed point in space.
There are 4 global attributes in the root group of the file, including {\tt DATETIME}, a time string
(in UTC) recording the start of the simulation; {\tt UNIT}, the unit for the data (``m'', ``m/s'', etc.);
{\tt DELTA}, the sample interval; and {\tt ORIGINTIME}, the origin time in seconds, relative to the start time 
of SW4 calculation and seismogram of the earliest source.

Then the time-series data of each station in separate groups, using the station name as the group name.
Inside each group, there is the number of valid points stored in the data array, the station location
in both xyz coordiate in SW4 domain (m) and latitude, longitude, depth. In the case when the surface grids are too sparse, we also store the actual location and the distance between the actual and user-specified location in {\tt ACTUALSTLA,STLO,STDP}, {\tt ACTUALSTX,STY,STZ}, and  {\tt DISTFROMACTUAL}.  The data array may be named with 
{\tt X, Y, Z, or EW, NS, UP} depending on the {\tt isnsew=} option specified in the rec/sac command. For each of 
these component, there are also {\tt *CMPAZ and} {\tt *CMINC} (e.g. {\tt XCMPAZ, XCMPINC}) recording its azimuth and inclination.

Note that the dataspace of the data array is pre-allocated to hold the entire timeseries data of the simulation,
when the SW4 is terminate early (i.e. in case of checkpoint/restart), only a portion of the data in the array
is valid, with the size recorded in the {\tt NPTS} field. When reading the data, it is recommended to read the 
{\tt NPTS} value first and only use the first {\tt NPTS} values from the data array.

The HDF5 file stores data in an self-describing way, with the following fields:

\begin{center}
\begin{tabular}{lll}\hline
Name & Type & Size \\ \hline
  DATETIME & H5T\_STRING & string\_len \\ \hline
  UNIT & H5T\_STRING & string\_len \\ \hline
  DELTA & H5T\_STD\_F32LE & 1 \\ \hline
  ORIGINTIME & H5T\_STD\_F32LE & 1 \\ \hline
Group /BK.BDM (station name) \\ \hline
  ISNSEW & H5T\_IEEE\_I32LE & 1  \\ \hline
  LOC & H5T\_IEEE\_I32LE & 1  \\ \hline
  NPTS & H5T\_IEEE\_I32LE & 1  \\ \hline
  STLA,STLO,STDP & H5T\_STD\_F32LE & 3 \\ \hline
  ACTUALSTLA,STLO,STDP & H5T\_STD\_F32LE & 3 \\ \hline
  STX,STY,STZ & H5T\_STD\_F32LE & 3 \\ \hline
  ACTUALSTX,STY,STZ & H5T\_STD\_F32LE & 3 \\ \hline
  DISTFROMACTUAL & H5T\_STD\_F32LE & 1\\ \hline
  X or EW & H5T\_STD\_F32LE & NPTS \\ \hline
  XCMPAZ or EWCMPAZ & H5T\_STD\_F32LE & 1\\ \hline
  XCMPINC or EWCMPINC & H5T\_STD\_F32LE & 1\\ \hline
  Y or NS & H5T\_STD\_F32LE & NPTS \\ \hline
  YCMPAZ or NSCMPAZ & H5T\_STD\_F32LE & 1\\ \hline
  YCMPINC or NSCMPINC & H5T\_STD\_F32LE & 1\\ \hline
  Z or UP & H5T\_STD\_F32LE & NPTS \\ \hline
  ZCMPAZ or UPCMPAZ & H5T\_STD\_F32LE & 1\\ \hline
  ZCMPINC or UPCMPINC & H5T\_STD\_F32LE & 1\\ \hline
\end{tabular}
\end{center}

The output of {\tt h5dump -A} header and metadata is below (lightly edited):

\begin{verbatim}
HDF5 "sta.hdf5" {
GROUP "/" {
   ATTRIBUTE "DATETIME" {
      DATATYPE  H5T_STRING {
         STRSIZE 27;
         STRPAD H5T_STR_NULLTERM;
         CSET H5T_CSET_ASCII;
         CTYPE H5T_C_S1;
      }
      DATASPACE  SCALAR
      DATA {
      (0): "2019-10-02T02:18:58.000000"
      }
   }
   ATTRIBUTE "UNIT" {
      DATATYPE  H5T_STRING {
         STRSIZE 2;
         STRPAD H5T_STR_NULLTERM;
         CSET H5T_CSET_ASCII;
         CTYPE H5T_C_S1;
      }
      DATASPACE  SCALAR
      DATA {
      (0): "m"
      }
   }
   DATASET "DELTA" {
      DATATYPE  H5T_IEEE_F32LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   DATASET "ORIGINTIME" {
      DATATYPE  H5T_IEEE_F32LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   GROUP "BK.BDM" {
      DATASET "LOC" {
         DATATYPE  H5T_STD_I32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
      DATASET "NPTS" {
         DATATYPE  H5T_STD_I32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
      DATASET "STLA,STLO,STDP" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 3 ) / ( 3 ) }
      }
      DATASET "STX,STY,STZ" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 3 ) / ( 3 ) }
      }
      DATASET "X" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 2209 ) / ( 2209 ) }
      }
      DATASET "XCMPAZ" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
      DATASET "XCMPINC" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
      DATASET "Y" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 2209 ) / ( 2209 ) }
      }
      DATASET "YCMPAZ" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
      DATASET "YCMPINC" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
      DATASET "Z" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 2209 ) / ( 2209 ) }
      }
      DATASET "ZCMPAZ" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
      DATASET "ZCMPINC" {
         DATATYPE  H5T_IEEE_F32LE
         DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
      }
   }
   GROUP "BK.BKS" {
   ...
   }
}

\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{image}\label{sec:image-format}
\index{fileformats!image}

\paragraph{Important note:} The image file format used by \emph{SW4} is different from that used by
\emph{WPP}. To emphasize the change in format, all \emph{SW4} image files have extension {\tt
  .sw4img}. A reader for image files is provided in the matlab/octave function \verb+readimage.m+ in
the \verb+tools+ directory.

Images files hold cross-sectional data on a composite grid and are written in a binary format. The
image file starts with a header followed by a data section, which contains a two-dimensional grid
function for each grid patch in the composite grid. The header has two parts. The first part
contains 5 integers (4 bytes each), 2 doubles (8 bytes each) and a character array with 25 elements
(1 byte each), i.e., 61 bytes of data:
\begin{center}
\begin{tabular}{llll}\hline
Offset (bytes) & Name & Type & Bytes \\ \hline
0 & prec   & int & 4 \\ \hline
4 & $N_p$  & int & 4 \\ \hline
8 & $t$    & double & 8 \\ \hline
16 & plane & int & 4 \\ \hline
20 & $\xi$ & double & 8 \\ \hline
28 & mode  & int & 4 \\ \hline
32 & grdinfo & int & 4 \\ \hline
36 & creation-time & char[25] & 25 \\ \hline
\end{tabular}
\end{center}
Here, {\tt prec} is the number of bytes per entry in the data section, i.e., 4 for single precision
and 8 for double precision. The positive number of data patches is stored in $N_p$, and $t\geq 0$ is the
simulation time at which the image was saved. The {\tt plane} variable indicates the orientation of
the plane. It is 0 for a constant $x$-plane, 1 for a constant $y$-plane, and 2 for a constant
$z$-plane. The coordinate value is stored in $\xi$. For example, if {\tt plane}=0, the data is saved
along $x=\xi$. The type of data is saved in {\tt mode}. The following 32 different types of data can
be saved on an image file,
\begin{flushleft}
\begin{tabular}{l||l|l|l|l|l|l|l|l|l|l|l|l|l}\hline
{\tt mode} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13\\ \hline
Data & $u^{(x)}$ & $u^{(y)}$ & $u^{(z)}$ & $\rho$ & $\lambda$ & $\mu$ & $C_p$ & $C_s$ & $u_{ex}^{(x)}$
& $u_{ex}^{(y)}$ & $u_{ez}^{(z)}$ & div$(\ub)$ & $|\mbox{curl($\ub$)}|$ \\ \hline
\end{tabular}\\
\medskip
\begin{tabular}{l||l|l|l|l|l|l|l|l|l|l|l}\hline
{\tt mode}  & 14 & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 \\ \hline\hline
Data & div$(\ub_t)$ & $|\mbox{curl($\ub_t$)}|$ & lat & lon &
topo & $x$ & $y$ & $z$ & $u_{error}^{(x)}$ & $u_{error}^{(y)}$ & $u_{error}^{(z)}$  \\ \hline
\end{tabular}\\
\medskip
\begin{tabular}{l||l|l|l|lllllll}\hline
{\tt mode} & 25 & 26 & 27 & 28 \\ \hline
Data & $|\ub_t|$ & $\sqrt{(u_t^{(x)})^2+(u_t^{(y)})^2}$ & $\max_t\sqrt{(u_t^{(x)})^2+(u_t^{(y)})^2}$
& $\max_t \left| u^{(z)}_t \right|$ 
\\ \hline
\end{tabular}\\
\medskip
\begin{tabular}{l||l|l|l|lllll}\hline
{\tt mode} & 29 & 30 & 31 & 32 \\ \hline
Data & $|\ub|$ & $\sqrt{(u^{(x)})^2+(u^{(y)})^2}$ & $\max_t\sqrt{(u^{(x)})^2+(u^{(y)})^2}$ & $\max_t
\left| u^{(z)} \right|$ \\ \hline 
\end{tabular}
\end{flushleft}
Here, $|{\bf a}|$ denotes the magnitude of the vector ${\bf a}\in\Re^3$ and $\ub_{ex}$ denotes the
exact solution, which also is needed to calculate the error in the solution, $\ub_{error}$. Note
that image modes 9, 10, 11, 22, 23, and 24, only are available when the exact solution is known,
i.e., when \emph{SW4} is run in one of its test modes. Also note that image modes 19-21 store the
coordinates of the grid in the data section of the image file. These modes provide an alternative
way of saving the grid when it is curvilinear.

The {\tt grdinfo} variable can have values 0 or 1. No grid information is saved on the image file if
{\tt grdinfo}=0. In this case all data patches are on a Cartesian grid, which can be reconstructed
from the information in the header of the image file (see below). If {\tt grdinfo}=1, the
$z$-coordinates of the curvilinear grid are saved in an additional grid patch, following
the last data patch. The final field in the first part of the header is a character array with 25
elements. It holds the creation time of the image file, as obtained from the C++ function {\tt
  localtime()}. On a Mac running OSX, the time has the format ``Thu Feb 28 14:24:07 2013''. Exactly
25 characters are saved and the string is truncated if it is longer than that.

The second part of the header contains grid size information (32 bytes)
for each of the $N_p$ data patches. The information is saved in the following format:
{\samepage
\begin{center}
\hspace{-35mm}{\tt for ($p=1$; $p\leq N_p$; $p$++)}\nopagebreak \\ 
\vspace{2mm}
\begin{tabular}{llll}\hline
Offset (bytes) & Name & Type & Bytes \\ \hline
61 + $32(p - 1)$ & $h_{p}$ & double & 8 \\ \hline
69 + $32(p - 1)$ & $zmin_{p}$ & double & 8 \\ \hline
77 + $32(p - 1)$ & $ib_{p}$ & int & 4 \\ \hline
81 + $32(p - 1)$ & $ni_{p}$ & int & 4 \\ \hline
85 + $32(p - 1)$ & $jb_{p}$ & int & 4 \\ \hline
89 + $32(p - 1)$ & $nj_{p}$ & int & 4 \\ \hline
\end{tabular}\\
\end{center}
}
Here $h_p$ is the grid size and $zmin_p$ is the starting value of the $z$-coordinate in patch
$p$. There are $ni_p$ by $nj_p$ data points on patch $p$ with starting indices $ib_p$ and
$jb_p$. Currently, $ib_p=1$ and $jb_p=1$. The Cartesian grid can be constructed from the
grid size information,
\[
\mbox{{\tt plane}=0:}\ \begin{cases}
x^{(p)}_{i,j} = \xi,\\
y^{(p)}_{i,j} = h_p(i-1),& ib_p\leq i\leq ib_p+ni_p-1,\\
z^{(p)}_{i,j} = zmin_p + h_p(j-1),& jb_p\leq j\leq jb_p+nj_p-1,
\end{cases}
\]
\[
\mbox{{\tt plane}=1:}\ \begin{cases}
x^{(p)}_{i,j} = h_p(i-1),& ib_p\leq i\leq ib_p+ni_p-1,\\
y^{(p)}_{i,j} = \xi,\\
z^{(p)}_{i,j} = zmin_p + h_p(j-1),& jb_p\leq j\leq jb_p+nj_p-1,
\end{cases}
\]
\[
\mbox{{\tt plane}=2:}\ \begin{cases}
x^{(p)}_{i,j} = h_p(i-1),& \qquad \qquad ib_p\leq i\leq ib_p+ni_p-1, \\
y^{(p)}_{i,j} = h_p(j-1),& \qquad \qquad jb_p\leq j\leq jb_p+nj_p-1, \\
z^{(p)}_{i,j} = \xi.
\end{cases}
\]

The header is followed by grid function data on each of the $N_p$ patches. The data is saved as
floats ({\tt prec}=4), or doubles ({\tt prec}=8). Each patch of the data is stored as in a
two-dimensional array, $u^{(p)}(i,j)$, where $ib_p\leq i \leq ib_p+ni_p-1$ and $jb_p\leq j \leq
jb_p+nj_p-1$. The data can be read as outlined by the following pseudo code:
\begin{flushleft}
{\tt for ($p=1$; $p\leq N_p$; $p$++)\{\\
\hspace{5mm}for ($j=1$; $j\leq nj_p$; $j$++)\{\\
\hspace{10mm}for ($i=1$; $i\leq ni_p$; $i$++)\{\\
\hspace{15mm}read $u^{(p)}(i-1+ib_p, j-1+jb_p)$\\
\hspace{10mm}\}\\
\hspace{5mm}\}\\
\}}
\end{flushleft}
If {\tt grdinfo}=0, there is no additional information on the image file.

If {\tt grdinfo}=1, the $z$-coordinates of the curvilinear grid are also saved on the image file
(as floats or doubles depending on that value of {\tt prec}). Note that the curvilinear data always
corresponds to patch number $p=N_p$. The $z$-coordinates corresponding to the data are stored as an
additional patch, which can be read using the pseudo code:
\begin{flushleft}
{\tt $p=N_p$;\\
for ($j=1$; $j\leq nj_p$; $j$++)\{\\
\hspace{5mm}for ($i=1$; $i\leq ni_p$; $i$++)\{\\
\hspace{10mm}read $z^{(p)}(i-1+ib_p, j-1+jb_p)$\\
\hspace{5mm}\}\\
\}}
\end{flushleft}
The dimensions of the arrays $u^{(N_p)}$ and $z^{(N_p)}$ are always the same.  When {\tt grdinfo}=1,
the $z^{(N_p)}_{i,j}$ coordinates replace the above definition of the grid for the cases {\tt
  plane}=0 and {\tt plane}=1. For {\tt plane}=2, the grid is defined by the $(x,y)$ coordinates,
which currently remains Cartesian also for a curvilinear grid.

%% If {\tt grdinfo}=2, the coordinates of the curvilinear grid are saved on a separate image
%% file. In this case, only the name of the file is saved as a character array {\tt gname} of length
%% $n_s$, and the last $4+n_s$ bytes of the image file follow the format:
%% \begin{center}
%% \begin{tabular}{llll}\hline
%% Name & Type & Bytes \\ \hline
%% $n_s$ & integer & 4 \\ \hline
%% {\tt gname} & char[$n_s$] & $n_s$ \\ \hline
%% \end{tabular}
%% \end{center}



\section{imagehdf5}\label{sec:imagehdf5-format}
\index{fileformats!imagehdf5}

The image files in HDF5 format hold identical data as in the image file, but are stored as HDF5 attributes and datasets. To improve the I/O efficiency, the header data and the patch data are stored in arrays instead of individually in the binary format (i.e. all the {\tt ni} values of multiple patches are stored in the same HDF5 dataset, with its length equal to the number of patches).

The output of \verb+h5dump -A imagehdf5.file+  is below:

\begin{verbatim}
HDF5 "image.cycle=0.y=40000.p.sw4img.h5" {
GROUP "/" {
   ATTRIBUTE "creationtime" {
      DATATYPE  H5T_STRING {
         STRSIZE 25;
         STRPAD H5T_STR_NULLTERM;
         CSET H5T_CSET_ASCII;
         CTYPE H5T_C_S1;
      }
      DATASPACE  SCALAR
      DATA {
      (0): "Fri Jan 24 14:15:23 2020"
      }
   }
   DATASET "coordinate" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   DATASET "grid" {
      DATATYPE  H5T_IEEE_F32LE
      DATASPACE  SIMPLE { ( 31031 ) / ( 31031 ) }
   }
   DATASET "grid_size" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }
   }
   DATASET "gridinfo" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   DATASET "mode" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   DATASET "ni" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }
   }
   DATASET "nj" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }
   }
   DATASET "npatch" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   DATASET "patches" {
      DATATYPE  H5T_IEEE_F32LE
      DATASPACE  SIMPLE { ( 307307 ) / ( 307307 ) }
   }
   DATASET "plane" {
      DATATYPE  H5T_STD_I32LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   DATASET "time" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
   }
   DATASET "zmin" {
      DATATYPE  H5T_IEEE_F64LE
      DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }
   }
}
}
\end{verbatim}


\section{volimage}\label{sec:volimage-format}
\index{fileformats!volimage}

The \verb+volimage+ command generates (often very large) binary files holding three-dimensional
volumetric data. A reader for \verb+volimage+ files is provided in the matlab/octave script
\verb+readimage3d.m+ in the \verb+tools+ directory.  Alternatively, users might want to visualize
the data in these files with the open source {\em VisIt} post processor. \verb+volimage+ files can
also be used to define the material properties in \emph{SW4}, using the \verb+vimaterial+
command. \emph{SW4} \verb+volimage+ files have extension \verb+.3D.mode.sw4img+, where \verb+mode+ is one
of \verb+ux, uy, uz, rho, lambda, mu, p, s, qp, qs+.

The format of the \verb+volimage+ files is essentially the same as the format of image files, with the
exception that the sizes of the data patches are specified by six integers in the \verb+volimage+ files,
instead of four in the image file format.  The first 61 bytes of the header of the \verb+volimage+ format is
identical to the image format given in the previous section, i.e.,
\begin{center}
\begin{tabular}{llll}\hline
Offset (bytes) & Name & Type & Bytes \\ \hline
0 & prec   & int & 4 \\ \hline
4 & $N_p$  & int & 4 \\ \hline
8 & $t$    & double & 8 \\ \hline
16 & plane & int & 4 \\ \hline
20 & $\xi$ & double & 8 \\ \hline
28 & mode  & int & 4 \\ \hline
32 & grdinfo & int & 4 \\ \hline
36 & creation-time & char[25] & 25 \\ \hline
\end{tabular}
\end{center}
The \verb+plane+ and coordinate ($\xi$) variables are not needed for three-dimensional data. They are both
set to -1 in a \verb+volimage+ file.  The number of possible variables to save is more restricted
than for the image command. The volume image format stores one of the following variables with
corresponding integer code for the \verb+mode+ variable in the file header:
\begin{center}
\begin{tabular}{l||l|l|l|l|l|l|l|l|l|l}\hline
{\tt mode} & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 14 & 15 \\ \hline
Data & $u^{(x)}$ & $u^{(y)}$ & $u^{(z)}$ & $\rho$ & $\lambda$ & $\mu$ & $C_p$ & $C_s$ & $Q_p$ & $Q_s$ \\ \hline 
\end{tabular}
\end{center}
After the 61 byte header follows the dimensional information for the patches stored on
the file in the following order:
{\samepage
\begin{flushleft}
{\tt for ($p=1$; $p\leq N_p$; $p$++) \{}\nopagebreak \\ 
\hspace{5mm}
\begin{tabular}{llll}\hline
Offset (bytes) & Name & Type & Bytes \\ \hline
61 + $40(p - 1)$ & $h_{p}$ & double & 8 \\ \hline
69 + $40(p - 1)$ & $zmin_{p}$ & double & 8 \\ \hline
77 + $40(p - 1)$ & $ib_{p}$ & int & 4 \\ \hline
81 + $40(p - 1)$ & $ni_{p}$ & int & 4 \\ \hline
85 + $40(p - 1)$ & $jb_{p}$ & int & 4 \\ \hline
89 + $40(p - 1)$ & $nj_{p}$ & int & 4 \\ \hline
93 + $40(p - 1)$ & $kb_{p}$ & int & 4 \\ \hline
97 + $40(p - 1)$ & $nk_{p}$ & int & 4 \\ \hline
\end{tabular}\\
\}
\end{flushleft}
}
Next, the data patches are stored as 4 or 8 byte floats, as indicated by the \verb+prec+ entry 
in the header. These can be read as a one-dimensional sequence of bytes in the order 
\begin{flushleft}
{\tt for ($p=1$; $p\leq N_p$; $p$++)\{\\
\hspace{5mm}for ($k=1$; $k\leq nk_p$; $k$++)\{\\
\hspace{10mm}for ($j=1$; $j\leq nj_p$; $j$++)\{\\
\hspace{15mm}for ($i=1$; $i\leq ni_p$; $i$++)\{\\
\hspace{20mm}read $u^{(p)}(i-1+ib_p, j-1+jb_p,k-1+kb_p)$\\
\hspace{15mm}\}\\
\hspace{10mm}\}\\
\hspace{5mm}\}\\
\}}
\end{flushleft}
If {\tt grdinfo}=0, there is no additional information on the \verb+volimage+ file.
If {\tt grdinfo}=1, the $z$-coordinates of the curvilinear grid are also saved on the \verb+volimage+ file
(as floats or doubles depending on {\tt prec}). Note that the curvilinear grid always
corresponds to the last patch, $p=N_p$. The grid coordinate can be read in the same way as
the data patches:
\begin{flushleft}
{\tt $p=N_p$;\\
for ($k=1$; $k\leq nk_p$; $k$++)\{\\
\hspace{5mm}for ($j=1$; $j\leq nj_p$; $j$++)\{\\
\hspace{10mm}for ($i=1$; $i\leq ni_p$; $i$++)\{\\
\hspace{15mm}read $z^{(p)}(i-1+ib_p, j-1+jb_p,k-1+kb_p)$\\
\hspace{10mm}\}\\
\hspace{5mm}\}\\
\}}
\end{flushleft}
The $x$- and $y-$ coordinates are uniformly distributed, also for the curvilinear grid, and can therefore always be
reconstructed from the grid size $h$, and the index bounds. The $z$-coordinate on other patches, when present, will
always be uniform, and can be reconstructed from $h$ and the $zmin$ variable.

\section{ssioutput}\label{sec:ssioutput-format}
\index{fileformats!ssioutput}

The \verb+ssiouput+ command generates (potentially very large) binary HDF5
  files holding three-dimensional volumetric data for the ESSI application.

The format of the \verb+ssioutput+ files is self-describing in HDF5
  (use {\tt h5dump -A} to see header metadata):
\begin{center}
\begin{tabular}{lll}\hline
Name & Type & Size \\ \hline
  ``ESSI xyz grid spacing'' & H5T\_IEEE\_F64LE & 1 \\ \hline
  ``ESSI xyz origin'' & H5T\_IEEE\_F64LE & 3 \\ \hline
  ``Grid azimuth'' & H5T\_IEEE\_F64LE & 1 \\ \hline
  ``Grid lon-lat origin'' & H5T\_IEEE\_F64LE & 2 \\ \hline
  ``cycle start, end'' & H5T\_STD\_I32LE & 2 \\ \hline
  ``time start'' & H5T\_IEEE\_F64LE & 1 \\ \hline
  ``timestep'' & H5T\_IEEE\_F64LE & 1 \\ \hline
  ``vel\_\{0,1,2\} ijk layout'' & H5T\_IEEE\_F64LE & cycle X 3D size \\ \hline
  ``z coordinates'' & H5T\_IEEE\_F64LE & (optional) 3D size \\ \hline
\end{tabular}
\end{center}


%% For this reason, we will not describe the binary format here. If you really want to
%% know the details of the format, we suggest you look in the source code for the plug-in (in the
%% \verb+wpp/tools/visit/volimage+ directory).

%% Starting with version 2.4 of {\em VisIt}, the {\tt volimage} plug-in for reading
%% these files should be included with the official release of {\em VisIt}. If you see the {\tt
%%   volimage} format in the drop-down file format menu in {\em VisIt}, there is no need to build a
%% local version of the plug-in.

%% In this section, we provide instructions on how to build the {\tt volimage} plug-in in case it is
%% not available in your version of {\em VisIt}. The source code for the plug-in is included with the
%% {\em SW4} source code distribution in the directory {\tt tools/visit/volimage}. On the Livermore
%% Computing (LC) machines, the source code can be found in the directory
%% \verb+/usr/apps/wpp/tools/visit/volimage+. In order to use this plug-in on the LC machines, you must
%% first copy the source code to a local directory where you have write privileges.

%% To build the volimage plugin, you do the following:
%% \begin{enumerate}
%% \item Add \emph{VisIt} to your search path by editing the \verb+PATH+ environmental variable. For
%%   example, if you are using C-shell on one of the LC machines, you should edit your \verb+~/.cshrc+
%%   file and add the directory \verb+/usr/gapps/visit/bin+ to \verb+PATH+. Next time you open a shell,
%%   verify that you have {\em VisIt} in your search path by issuing the command \verb+which visit+.

%% \item Make sure you have access to the \verb+cmake+ command, version $\geq 2.8$. Do
%%   \verb+cmake --help+ to check the version. On LC, newer versions of cmake can be found under
%%   \verb+/usr/gapps/visit/cmake+.

%% \item If you don't have write privileges on {\tt tools/visit/volimage}, copy
%%   \verb+tools/visit/volimage+ to a local directory (edit \verb+MYDIR+). Then go to that directory:
%% \begin{verbatim}
%%    cp ..../tools/visit/volimage/* MYDIR/.
%%    cd MYDIR/volimage
%% \end{verbatim}
%% You build the plug-in using the following commands:
%% \item \verb+xml2cmake -clobber volimage.xml+
%% \item \verb+cmake .+  (note the '.')
%% \item \verb+make+
%% \end{enumerate}

%% The "make" step will compile the plugin libraries and put them into the directory
%% \begin{verbatim}
%%      ~/.visit/<platform>/plugins/databases
%% \end{verbatim}

%% To use the {\tt volimage} plugin, you first need to run {\em SW4} to create a volimage data
%% file. Sample input files for \emph{SW4} can be found in the \verb+wpp/examples/volimage+
%% directory. On LC, these files are in the directory \verb+/usr/apps/wpp/examples/volimage+. Once a
%% \verb+volimage+ file has been generated, you can visualize it by running \emph{VisIt} and open the
%% data file using the \verb+volimage+ format, which should be available from the file format pull-down
%% menu.

\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Testing \emph{SW4}}\label{cha:testing-sw4}
\index{testing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Once \emph{SW4} has been installed on your system, it is a good idea to verify that the code is
working properly. For this purpose, the \emph{SW4} source code distribution includes a python(3)
script for running several tests and checking the solutions against previously verified
results. Here we describe the procedure when \emph{SW4} is built with {\tt make}. The tests can also
be performed when \emph{SW4} is built with CMake, see the \emph{SW4} installation
guide~\cite{SW4-install} for details.

After \emph{SW4} has been built with \verb+make+, go to the \verb+pytest+ directory and run
\verb+test_sw4.py+. If the \verb+sw4+ executable resides in the \verb+optimize+ directory, you can
run the basic tests by doing:
\begin{verbatim}
shell> cd pytest
shell> ./test_sw4.py
\end{verbatim}
If all goes well, you should see the following output:
\begin{verbatim}
>shell test_sw4.py
Running all tests for level 0 ...
Starting test # 1 in directory: meshrefine with input file: refine-el-1.in
Test # 1 Input file: refine-el-1.in PASSED
Starting test # 2 in directory: meshrefine with input file: refine-att-1.in
Test # 2 Input file: refine-att-1.in PASSED
...
Starting test # 12 in directory: lamb with input file: lamb-1.in
Test # 12 Input file: lamb-1.in PASSED
Out of 12 tests, 12 passed and 0 failed.
\end{verbatim}
Some aspects of the testing can be modified by providing command line arguments to
\verb+test_sw4.py+. For a complete list of options do \verb+test_sw4.py --help+, which currently
give the output:
\begin{verbatim}
shell> ./test_sw4.py --help
usage: test_sw4.py [-h] [-v] [-l {0,1,2}] [-m MPITASKS] [-d SW4_EXE_DIR]

optional arguments:
  -h, --help            show this help message and exit
  -v, --verbose         increase output verbosity
  -l {0,1,2}, --level {0,1,2}
                        testing level
  -m MPITASKS, --mpitasks MPITASKS
                        number of mpi tasks
  -d SW4_EXE_DIR, --sw4_exe_dir SW4_EXE_DIR
                        name of directory for sw4 executable
\end{verbatim}
Note  that the directory name for the \verb+sw4+ executable should be given relative to the main
\verb+sw4+ directory.

NOTE: On some systems, it is necessary to start an MPI daemon before any parallel programs can be
executed. This is often done by issuing the command
\begin{verbatim}
mpd &
\end{verbatim}
Ask your local system administrator if you have problems running \verb+sw4+ in parallel.

\section{Method of manufactured solutions}\label{sec:twilight}
\index{testing!twilight}

The method of manufactured solutions provides a general way of testing the accuracy of numerical
solutions of partial differential equations, including effects of heterogeneous material properties
and various boundary conditions on complex geometries. The test scripts can be found in the
directory
\begin{verbatim}
.../sw4/examples/twilight
\end{verbatim}
In these tests, we take the material properties to be
\begin{alignat*}{2}
\rho(x,y,z) &= A_\rho \left( 2 + \sin(\omega_m x + \theta_m) \cos(\omega_m y + \theta_m)
\sin(\omega_m z + \theta_m) \right),\\ 
\mu(x,y,z) &=  A_\mu \left( 3 + \cos(\omega_m x + \theta_m) \sin(\omega_m y + \theta_m)
\sin(\omega_m z + \theta_m) \right),\\ 
\lambda(x,y,z) &=  A_\lambda \left( 2 + \sin(\omega_m x + \theta_m) \sin(\omega_m y + \theta_m)
\cos(\omega_m z + \theta_m) \right).
\end{alignat*}
The internal forcing, boundary forcing and initial conditions are chosen such that the exact
(manufactured) solution becomes\footnote{A contour plot of these functions could help explain why we
  call it twilight zone testing.}
\begin{alignat*}{2}
u_e(x,y,z,t) &= \sin(\omega(x-c_e t)) \sin(\omega y + \theta) \sin(\omega z + \theta), \\
v_e(x,y,z,t) &= \sin(\omega x + \theta) \sin(\omega( y - c_e t)) \sin(\omega z + \theta), \\
w_e(x,y,z,t) &= \sin(\omega x + \theta) \sin(\omega y + \theta) \sin(\omega( z - c_e t)). 
\end{alignat*}
The values of the material parameters ($\omega_m$, $\theta_m$, $A_\rho$, $A_\lambda$, $A_\mu$) and
the solution parameters ($\omega$, $\theta$, $c_e$), can be modified in the input script. Since the
exact solution is know, it is possible to evaluate the error in the numerical solution. By repeating
the same test on several grid sizes, it is possible to establish the convergence rate of the
numerical method.

The basic twilight tests use a single grid, a flat topography, and use the unit cube
$(x,y,z)\in[0,1]^3$ as the computational domain. The numerical solution is simulated up to time
$t=0.8$ on a grid with $31^3$, $61^3$, $121^3$, and $241^3$ grid points, respectively. These cases
are provided in the four input scripts:
\begin{verbatim}
flat-twi-1.in  flat-twi-2.in  flat-twi-3.in  flat-twi-4.in
\end{verbatim}
The first three cases are small enough to be run on a single or dual core laptop computer. The
fourth case uses about 14 million grid points and needs to be executed on a slightly larger
machine. Assuming \verb+openmpirun+ is used to execute parallel programs, you run the first of these
cases on 2 processes with the command
\begin{verbatim}
cd examples/twilight
openmpirun -np 2 ../../optimize/sw4 flat-twi-1.in
\end{verbatim}
The results for the four cases are given in the output files
\begin{verbatim}
flat-twi-1.out  flat-twi-2.out  flat-twi-3.out  flat-twi-4.out
\end{verbatim}
The errors in max and $L_2$ norm in the numerical solution are reported near the bottom of the
output files. Some of these numbers are summarized in Table~\ref{tab:twi-err}.
\begin{table}
\begin{center}
\begin{tabular}{| c | c | c | c | c  | c | }
\hline
input file & $N_x$ & $h$ & $e_h=\| \ub - \ub_{ex}\|_\infty$ & ratio$_\infty$ & rate$_\infty$ \\ \hline
flat-twi-1.in & $31$  & $3.333\cdot 10^{-2}$  & $6.85\cdot 10^{-4}$ & --   & --   \\ \hline
flat-twi-2.in & $61$  & $1.667\cdot 10^{-2}$  & $3.99\cdot 10^{-5}$ &17.16 & 4.10 \\ \hline
flat-twi-3.in & $121$ & $8.333\cdot 10^{-3}$  & $2.01\cdot 10^{-6}$ &19.85 & 4.31 \\ \hline
flat-twi-4.in & $241$ & $4.167\cdot 10^{-3}$  & $1.40\cdot 10^{-7}$ &14.36 & 3.84 \\ \hline
\end{tabular}
\caption{Max norm errors in the displacement at time $t=0.8$, when the free
  surface is flat. The convergence rate is calculated as $\log_2(e_{2h}/e_h)$.}
\label{tab:twi-err}
\end{center}
\end{table}

The case of a non-planar free surface is tested by the scripts
\begin{verbatim}
gauss-twi-1.in  gauss-twi-2.in  gauss-twi-3.in  gauss-twi-4.in  gauss-twi-5.in
\end{verbatim}
Here, the computational domain is basically a cube with side 1, where the top surface is shaped as a
Gaussian hill. Let the shape of the top surface be described by $z=\tau(x,y)$. Because the $z$-axis
is directed downwards, and the Gaussian hill has amplitude 0.05, the function $\tau$ satisfies
$-0.05\leq \tau\leq 0$. The keyword {\tt zmax=0.25} in the {\tt topography} command tells
\emph{SW4} to build the curvilinear grid between $z=\tau(x,y)$ and $z=0.25$. A Cartesian grid is
used to cover the rest of the computational domain, i.e., for $0.25\leq z\leq 1$. The numerical
solution is calculated up to time $t=0.8$ on grids with grid size $h=1/30$, $1/60$, $1/120$,
and $1/240$, respectively. The three first cases are relatively small and can be run on a
single or dual core laptop computer. The number of grid point is increased by a factor of eight
between each grid refinement, and the number of time steps is doubled.
%However, the fourth case has a grid with about 14 million grid points and should be
%run on a machine with at least 8-16 cores.
The results of the simulations are given in the four output files
\begin{verbatim}
gauss-twi-1.out gauss-twi-2.out gauss-twi-3.out gauss-twi-4.out
\end{verbatim}
The errors in max norm are summarized in Table~\ref{tab:twi-gauss-err}.
\begin{table}
\begin{center}
\begin{tabular}{| c | c | c | c | c | c  | c | }
\hline
input file & $N_x$ & $h$ & $e_h=\| \ub - \ub_{ex}\|_\infty$  & ratio$_\infty$ & rate$_\infty$ \\ \hline
gauss-twi-1.in & $31$  & $3.333\cdot 10^{-2}$  & $1.74\cdot 10^{-3}$ & --   & --   \\ \hline
gauss-twi-2.in & $61$  & $1.667\cdot 10^{-2}$  & $1.93\cdot 10^{-4}$ & 9.01 & 3.17 \\ \hline
gauss-twi-3.in & $121$ & $8.333\cdot 10^{-3}$  & $9.11\cdot 10^{-6}$ & 21.1 & 4.40 \\ \hline
gauss-twi-4.in & $241$ & $4.167\cdot 10^{-3}$  & $5.83\cdot 10^{-7}$ & 15.6 & 3.96 \\ \hline
\end{tabular}
\caption{Max norm errors in the displacement at time $t=0.8$, with a Gaussian hill topography. The
  number of grid points and the grid size refer to the Cartesian grid. The convergence rate is
  calculated as $\log_2(e_{2h}/e_h)$. }
\label{tab:twi-gauss-err}
\end{center}
\end{table}

Note that some image files are generated by these scripts. They are placed in the sub-directories
\verb+gauss_31+, \verb+gauss_61+, etc. We encourage the reader to look at these image files, for
example by reading them into matlab/octave using the script \verb+tools/readimage.m+. An example is
given in Figure~\ref{fig:ux}.
\begin{figure}
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/ux.png}
\caption{Contour plot of the $u^{(x)}$ component of the solution along the plane $x=0.5$. The image
  file was written with the script {\tt gauss-twi-3.in}. The solid black line shows the shape of the
  top surface. The dashed black line indicates the interface between the curvilinear and Cartesian
  grids.}
\label{fig:ux}
\end{center}
\end{figure}


\section{Lamb's problem}\label{sec:testlamb}
\index{testing!lambs}

In this section we use the {\tt testlamb} command to evaluate the accuracy of the numerical
solution of Lamb's problem. An introduction to Lamb's problem is given in Section~\ref{sec:lamb}.

% 1st example
We consider an elastic half-space with shear speed $C_s=1$ m/s, compressional speed
$C_p=\sqrt{3}$ m/s and density $\rho=1$ kg/m$^3$. The setup can be found in {\tt
  examples/lamb/lamb-1.in},
\begin{verbatim}
fileio path=lamb-h0p04
grid x=12 y=12 z=6 h=0.04
time t=15.0
supergrid gp=50
testlamb rho=1 cp=1.732050807568877
source x=6 y=6 z=0 fx=0 fy=0 fz=1 t0=0 freq=1 type=C6SmoothBump
rec x=10.0 y=6.0 z=0 file=sg1 usgsformat=1 sacformat=0
rec x=10.0 y=10.0 z=0 file=sg2 usgsformat=1 sacformat=0
\end{verbatim}
The super-grid far-field layer is 50 grid points wide, corresponding to the width $\ell=2$.  The
error is evaluated along the free surface $z=0$, inside of the supergrid layers, i.e., $2\leq (x,y) \leq 10$, and is
saved on the file \verb+lamb-h0p04/LambErr.txt+. Each line of this file has four columns
corresponding to the time, max error, $L_2$ error, max norm of solution. Since the surface waves
propagate with speed $C_r\approx 0.92$ and the source time function is zero after $t=1$, the exact
solution becomes identically zero along the surface after time $t\approx 1 + 4\sqrt{2}/0.92 \approx
7.15$. After this time, the error in the numerical solution is due to artificial reflections from
the super-grid layers. In Figure~\ref{fig:lamb-err} we plot the $L_2$ norm of the error as function of time for
grid sizes $h=0.04$ and $h=0.02$. Here, the case with grid size $h=0.02$ can be found in {\tt
  examples/lamb/lamb-2.in}. Note that the error converges to zero as ${\cal O}(h^4)$ for $t>1$,
i.e., after the singular point force has stopped acting.
\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.7\textwidth]{figures/lamb-err.png}
\caption{The $L_2$ norm of the error in the solution of Lamb's problem, as function of time. The blue
and green lines correspond to $h=0.04$ and $h=0.02$, respectively.}
\label{fig:lamb-err}
\end{center}
\end{figure}
Another way of assessing the quality of the super-grid layers is by inspecting the solution in the
vicinity of the super-grid layers. The two \verb+rec+ commands save the solution at $(x,y,z)=(6,10,0)$
and $(x,y,z)=(10,10,0)$. We can use the \verb+plotusgs+ matlab/octave script to inspect the
numerical solution, see Figure~\ref{fig:sg2}.
\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.7\textwidth]{figures/sg2.png}
\caption{The $x$, $y$, and $z$-components of the solution of Lamb's problem at $(x,y,z)=(10,10,0)$.}
\label{fig:sg2}
\end{center}
\end{figure}
We conclude that there are no visible artifacts due to the truncation of the computational domain.

%% Here we provide input files with four different grid sizes, with $116^2\times 59$, $231^2 \times
%% 116$, $461^2\times 231$, and $921^2\times 461$ grid points, respectively. Be aware that the finest
%% grid uses about 391 Million grid points and can only be run on a sufficiently large machine. The
%% corresponding output files are given in
%% \begin{verbatim}
%% Lambtest1.out  Lambtest2.out  Lambtest3.out  Lambtest4.out
%% \end{verbatim}
%% Note that the most important information is near the end of these files, where the error in the numerical
%% solution is reported. 

\section{Point source test}\label{sec:testpointsource}
\index{testing!pointsource}

There is an analytical solution of the elastic wave equation when the forcing is a point source
term, and the domain is unbounded. The forcing can either be a point force or a point moment tensor
source. In both these cases, the analytical solution is singular (i.e. infinite) at the point source,
while the point source is acting. For time functions that are identically zero for $t\geq t_1$, the
analytical solution becomes bounded for $t>t_1$. The smoothness of the solution is determined by the
smoothness of the source time function.

The accuracy of the numerical solution can be evaluated by comparing it to the analytical solution
using the \verb+testpointsource+ command. As before we refine the grid by halving the grid size to
evaluate the convergence rate of the numerical solution. Since we previously tested the point force
discretization by solving Lamb's problem, we will here focus on the point moment tensor source
discretization. Example input files are given in the files \verb+ps-dir1.in+, \verb+ps-dir2.in+,
and \verb+ps-dir3.in+ in the \verb+tools/pointsource+ directory. Each input file has a corresponding
\verb+.out+ file with the results we obtained while running these cases.

The source properties are specified by exactly one regular \verb+source+ command. In this case the
time function is a \verb+C6SmoothBump+. The coarsest grid is setup in the file \verb+ps-dir1.in+,
\begin{verbatim}
fileio path=dir-h0p04
grid x=8 y=8 z=8 h=0.04
time t=2.5

# dirichlet conditions on all sides
boundary_conditions lx=1 hx=1 ly=1 hy=1 lz=1 hz=1

# testing point sources
testpointsource rho=1 cp=1.6 cs=0.8

# source
source x=4.0 y=4.0 z=4.0 Mxx=1 Myy=1 Mzz=1 Mxy=0 Mxz=0 Myz=0 t0=0 freq=1 type=C6SmoothBump
\end{verbatim}

The source is located in the center of a cube with side 8, so the shortest distance from the source
to a boundary is 4.  The solution satisfies homogeneous Dirichlet boundary conditions on all
boundaries. The fastest wave speed is 1.6, so the solution on the boundary is identically zero until
time $t=4/1.6 = 2.5$. There can therefore not be any reflections from the boundaries for $t\leq
2.5$, and the analytical solution is reliable up to this point in time. The error in the numerical
solution at $t=2.5$ (the end of the simulation) is reported at the end of each run. These numbers
are summarized in Table~\ref{tab:point-source}. Since the convergence rate tends to 4 as the grid is
refined, we conclude that the numerical solution is a fourth order accurate approximation of the
analytical solution.
\begin{table}
\begin{center}
\begin{tabular}{| c | c | c | c  | c | }
\hline
input file & $h$ & $e_h=\| \ub - \ub_{ex}\|_\infty$  & ratio$_\infty$ & rate$_\infty$ \\ \hline
ps-dir1.in & $0.04$  & $2.09\cdot 10^{-3}$  &  --   & --   \\ \hline
ps-dir2.in & $0.02$  & $1.41\cdot 10^{-4}$  &  14.82 & 3.88 \\ \hline
ps-dir3.in & $0.01$  & $8.94\cdot 10^{-6}$  &  15.77 & 3.97 \\ \hline
\end{tabular}
\caption{Max norm errors in the displacement at time $t=2.5$. The convergence rate is calculated as
  $\log_2(e_{2h}/e_h)$. }
\label{tab:point-source}
\end{center}
\end{table}

More detailed information of the error in the numerical solution is saved in the file
\verb+PointSourceErr.txt+, which is written in the output directory that is specified by the
\verb+fileio+ command. Each line in this file has 4 entries: time, max-error, $L_2$-error, and
max-norm of the solution. In Figure~\ref{fig:point-error}, we plot the max-error as function of time
for the three grid sizes. The source time function is identically zero for $t\geq 1$. Before $t=1$,
the analytical solution is unbounded at the point source. For this reason, a few points around the
point source are excluded from the calculation of the error in the numerical solution. For $t>1$, we
see that the error in the numerical solution is reduced by a factor $\approx 16$ each time the grid
size is halved.
\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.7\textwidth]{figures/ps-err.png}
\caption{The max norm of the error in the point source test. The blue, green, and red lines
  correspond to $h=0.04$, $h=0.02$, and $h=0.01$, respectively.}
\label{fig:point-error}
\end{center}
\end{figure}

We remark that the \verb+testpointsource+ command can also be used to evaluate the accuracy of the
supergrid far field layers. In this case, the Dirichlet boundary conditions should be replaced by
supergrid conditions on all six boundaries of the computational domain. Such an experiment is set up
in the input files \verb+pointsource-sg1.in+, \verb+pointsource-sg2.in+, and
\verb+pointsource-sg3.in+ in the \verb+tools/pointsource+ directory. Each input file has a
corresponding \verb+.out+ file that holds the output from these cases. As before, the errors for
each case are reported in the file \verb+PointSourceErr.txt+ in the sub-directories
\verb+pointsource-h0p04++, \verb+pointsource-h0p02++, and \verb+pointsource-h0p01++. The $L_2$ norm
of the error is shown in Figure~\ref{fig:sg-error}. The reader is enouraged to study these results,
experiment with the duration of the simulation, and the width of the super grid layers.
\begin{figure}[ht]
\begin{center}
\includegraphics[width=0.7\textwidth]{figures/sg-ps-err.png}
\caption{The $L_2$-norm of the error in the point source test. This simulation was run to time $t=5$
  and the errors after time $t\approx 3$ are due to artificial reflections from the super-grid
  layers. The blue, green, and red lines 
  correspond to $h=0.04$, $h=0.02$, and $h=0.01$, respectively.}
\label{fig:sg-error}
\end{center}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Run time and memory requirements }\label{sec:performance}
\index{performance}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Run time}

The execution times shown in Table \ref{tab:cputime-usage} were obtained by running \emph{SW4} on
problems with approximately $2.8\times 10^5$ to $3.3\times 10^5$ grid points per processor. Timings
were measured on 16 processors of Cab, a parallel supercomputer at LLNL, in August of 2013. The
\emph{SW4} executable was compiled with Intel compilers at optimization level -O. The execution
times are given in seconds per grid point and time step.  While the absolute numbers in Table
\ref{tab:cputime-usage} are machine dependent and destined to change in the future, the relative
cost of various solver configurations is likely to stay more or less constant. Note that the
visco-elastic cases used 3 mechanisms. For the case with topography, about 31\% of the grid points
were in the curvilinear grid.

We note that solving the visco-elastic wave equations with $m=3$, requires around 3 times more CPU
time than the purely elastic case. Using topography requires about 1.5 times more CPU time when 31\%
of the domain is discretized on a curvilinear grid. By extrapolation, if all grid points were in the
curvilinear grid, the increase in CPU time would have been about a factor 2.7.  The strong scaling
properties are not perfect. Hence, the performance might be degraded when the number of processors
is increased while keeping the number of grid points fixed. However, the total computational time
always decreases with increasing number of processors. More experimentation is needed to better
evaluate the strong scaling properties of \emph{SW4}.
\begin{table}
\begin{center}
\begin{tabular}{|l|l|r|r|}\hline
Configuration              & Solver        & Execution time [s] & Relative factor \\ \hline\hline
Cartesian   & elastic       & $2.62\cdot 10^{-8}$ & 1 \\ \hline
Topography  & elastic       & $4.05\cdot 10^{-8}$ & 1.5 \\ \hline
Cartesian   & visco-elastic & $7.96\cdot 10^{-8}$ & 3.0\\ \hline
Topography  & visco-elastic & $1.37\cdot 10^{-7}$ & 5.2\\ \hline
\end{tabular}
\end{center}
\caption{Execution time per time step and grid point for different configurations, both for
  solving the elastic and the visco-elastic wave equations. The relative factor is the execution time
   relative to the Cartesian case for the elastic wave equation.}\label{tab:cputime-usage}
 \end{table}

\section{Memory usage}

The memory usage in Table~\ref{tab:mem-usage} was obtained by running \emph{SW4} on a single processor
using 4 million grid points. By inspection of the source code, we found the following number of 3-D
arrays holding double precision (8 bytes) floating point variables:
21 for Cartesian grids, another
8 for topography (coordinates and metric coefficients in the curvilinear grid), and an additional
$2+11*m$ for a $m$-mechanism visco-elastic material. These numbers correspond to the asymptotic memory
 requirements presented in the right column of Table \ref{tab:mem-usage}, which agree reasonably well with the
 observed memory usage, shown in column three. The observed numbers tend to the theoretical asymptotic 
numbers as the problem size increases. For the computations with topography, the curvilinear grid holds about 31\%
of the grid points. This fraction is taken into account in the asymptotic estimate.
 \begin{table}
 \begin{center}
 \begin{tabular}{|l|l|r|r|}\hline
 Configuration   &  solver       & Memory [bytes/grid point]  & Asymp. [bytes/grid point] \\ \hline\hline
 Cartesian grid  & elastic       & 188   & 168       \\ \hline
 Topography      & elastic       & 208   &  200      \\ \hline 
 Cartesian grid  & visco-elastic $(m=3)$ & 475 & 448 \\ \hline 
 Topography      & visco-elastic $(m=3)$ & 500 & 468 \\ \hline 
 \end{tabular}
 \end{center}
 \caption{Observed memory usage (third column) and theoretical asymptotic limit (fourth column) for different 
   grid and solver configurations. The visco-elastic case has 3 mechanisms and the case with topography 
   has 31\% of the grid point in the curvilinear grid.}\label{tab:mem-usage}
 \end{table}

%% As expected, the observed memory usage closely follows the linear relation
%% \[
%%  M=k*N+m, 
%% \]
%% where M is memory usage and N is the number of grid points. 
For parallel runs, the memory per grid point will be somewhat higher, because of duplicated 
ghost points at the processor boundaries. Here we only report the memory usage for a single processor run. 
Note that the volimage command saves a copy of the image variable over the full 3D volume. This adds (at single
precision) 4 bytes per grid point and per volume image command. 

\bibliographystyle{plain}

\bibliography{refs} 

\printindex

\end{document}
